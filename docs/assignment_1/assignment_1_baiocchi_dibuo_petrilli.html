<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Francesco Baiocchi">
<meta name="author" content="Christian Di Buò">
<meta name="author" content="Leonardo Petrilli">
<meta name="dcterms.date" content="2025-01-14">

<title>Sexism Detection – NLP Assignments</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">NLP Assignments</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../assignment_1/assignment_1_baiocchi_dibuo_petrilli.html" aria-current="page"> 
<span class="menu-text">Assignment 1</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../assignment_2/assignment_2_baiocchi_dibuo_petrilli.html"> 
<span class="menu-text">Assignment 2</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#assignment-1" id="toc-assignment-1" class="nav-link active" data-scroll-target="#assignment-1">Assignment 1</a></li>
  <li><a href="#contact" id="toc-contact" class="nav-link" data-scroll-target="#contact">Contact</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#problem-definition" id="toc-problem-definition" class="nav-link" data-scroll-target="#problem-definition">Problem Definition</a></li>
  </ul></li>
  <li><a href="#task2---0.5-points-data-cleaning" id="toc-task2---0.5-points-data-cleaning" class="nav-link" data-scroll-target="#task2---0.5-points-data-cleaning">[Task2 - 0.5 points] Data Cleaning</a></li>
  <li><a href="#task-3---0.5-points-text-encoding" id="toc-task-3---0.5-points-text-encoding" class="nav-link" data-scroll-target="#task-3---0.5-points-text-encoding">[Task 3 - 0.5 points] Text Encoding</a></li>
  <li><a href="#task-4---1.0-points-model-definition" id="toc-task-4---1.0-points-model-definition" class="nav-link" data-scroll-target="#task-4---1.0-points-model-definition">[Task 4 - 1.0 points] Model definition</a></li>
  <li><a href="#task-5---1.0-points-training-and-evaluation" id="toc-task-5---1.0-points-training-and-evaluation" class="nav-link" data-scroll-target="#task-5---1.0-points-training-and-evaluation">[Task 5 - 1.0 points] Training and Evaluation</a></li>
  <li><a href="#task-6---1.0-points-transformers" id="toc-task-6---1.0-points-transformers" class="nav-link" data-scroll-target="#task-6---1.0-points-transformers">[Task 6 - 1.0 points] Transformers</a></li>
  <li><a href="#task-7---0.5-points-error-analysis" id="toc-task-7---0.5-points-error-analysis" class="nav-link" data-scroll-target="#task-7---0.5-points-error-analysis">[Task 7 - 0.5 points] Error Analysis</a>
  <ul class="collapse">
  <li><a href="#performances" id="toc-performances" class="nav-link" data-scroll-target="#performances">Performances</a></li>
  <li><a href="#dataset-imbalance" id="toc-dataset-imbalance" class="nav-link" data-scroll-target="#dataset-imbalance">Dataset Imbalance</a></li>
  <li><a href="#sentence-level-analysis" id="toc-sentence-level-analysis" class="nav-link" data-scroll-target="#sentence-level-analysis">Sentence-level analysis</a></li>
  <li><a href="#word-level-analysis" id="toc-word-level-analysis" class="nav-link" data-scroll-target="#word-level-analysis">Word-level analysis</a></li>
  <li><a href="#mulitilingual-model" id="toc-mulitilingual-model" class="nav-link" data-scroll-target="#mulitilingual-model">Mulitilingual Model</a></li>
  </ul></li>
  <li><a href="#task-8---0.5-points-report" id="toc-task-8---0.5-points-report" class="nav-link" data-scroll-target="#task-8---0.5-points-report">[Task 8 - 0.5 points] Report</a></li>
  <li><a href="#submission" id="toc-submission" class="nav-link" data-scroll-target="#submission">Submission</a></li>
  <li><a href="#faq" id="toc-faq" class="nav-link" data-scroll-target="#faq">FAQ</a></li>
  <li><a href="#the-end" id="toc-the-end" class="nav-link" data-scroll-target="#the-end">The End</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Sexism Detection</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Francesco Baiocchi </p>
             <p>Christian Di Buò </p>
             <p>Leonardo Petrilli </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 14, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="assignment-1" class="level1">
<h1>Assignment 1</h1>
<p><strong>Credits</strong>: Federico Ruggeri, Eleonora Mancini, Paolo Torroni</p>
<p><strong>Keywords</strong>: Sexism Detection, Multi-class Classification, RNNs, Transformers, Huggingface</p>
</section>
<section id="contact" class="level1">
<h1>Contact</h1>
<p>For any doubt, question, issue or help, you can always contact us at the following email addresses:</p>
<p>Teaching Assistants:</p>
<ul>
<li>Federico Ruggeri -&gt; federico.ruggeri6@unibo.it</li>
<li>Eleonora Mancini -&gt; e.mancini@unibo.it</li>
</ul>
<p>Professor: - Paolo Torroni -&gt; p.torroni@unibo.it</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>You are asked to address the <a href="https://clef2023.clef-initiative.eu/index.php?page=Pages/labs.html#EXIST">EXIST 2023 Task 1</a> on sexism detection.</p>
<section id="problem-definition" class="level2">
<h2 class="anchored" data-anchor-id="problem-definition">Problem Definition</h2>
<p>The systems have to decide whether or not a given tweet contains or describes sexist expressions or behaviors (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behavior).</p>
<section id="examples" class="level3">
<h3 class="anchored" data-anchor-id="examples">Examples:</h3>
<p><strong>Text</strong>: <em>Can’t go a day without women womening</em></p>
<p><strong>Label</strong>: Sexist</p>
<p><strong>Text</strong>: <em>‘’Society’s set norms! Happy men’s day though!#weareequal’’</em></p>
<p><strong>Label</strong>: Not sexist</p>
<p>#[Task 1 - 1.0 points] Corpus</p>
<p>We have preparared a small version of EXIST dataset in our dedicated <a href="https://github.com/lt-nlp-lab-unibo/nlp-course-material/tree/main/2024-2025/Assignment%201/data">Github repository</a>.</p>
<p>Check the <code>A1/data</code> folder. It contains 3 <code>.json</code> files representing <code>training</code>, <code>validation</code> and <code>test</code> sets.</p>
<p>The three sets are slightly unbalanced, with a bias toward the <code>Non-sexist</code> class.</p>
</section>
<section id="dataset-description" class="level3">
<h3 class="anchored" data-anchor-id="dataset-description">Dataset Description</h3>
<ul>
<li>The dataset contains tweets in both English and Spanish.</li>
<li>There are labels for multiple tasks, but we are focusing on <strong>Task 1</strong>.</li>
<li>For Task 1, soft labels are assigned by six annotators.</li>
<li>The labels for Task 1 represent whether the tweet is sexist (“YES”) or not (“NO”).</li>
</ul>
</section>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<pre><code>"203260": {
    "id_EXIST": "203260",
    "lang": "en",
    "tweet": "ik when mandy says “you look like a whore” i look cute as FUCK",
    "number_annotators": 6,
    "annotators": ["Annotator_473", "Annotator_474", "Annotator_475", "Annotator_476", "Annotator_477", "Annotator_27"],
    "gender_annotators": ["F", "F", "M", "M", "M", "F"],
    "age_annotators": ["18-22", "23-45", "18-22", "23-45", "46+", "46+"],
    "labels_task1": ["YES", "YES", "YES", "NO", "YES", "YES"],
    "labels_task2": ["DIRECT", "DIRECT", "REPORTED", "-", "JUDGEMENTAL", "REPORTED"],
    "labels_task3": [
      ["STEREOTYPING-DOMINANCE"],
      ["OBJECTIFICATION"],
      ["SEXUAL-VIOLENCE"],
      ["-"],
      ["STEREOTYPING-DOMINANCE", "OBJECTIFICATION"],
      ["OBJECTIFICATION"]
    ],
    "split": "TRAIN_EN"
  }
}</code></pre>
</section>
<section id="instructions" class="level3">
<h3 class="anchored" data-anchor-id="instructions">Instructions</h3>
<ol type="1">
<li><strong>Download</strong> the <code>A1/data</code> folder.</li>
<li><strong>Load</strong> the three JSON files and encode them as pandas dataframes.</li>
<li><strong>Generate hard labels</strong> for Task 1 using majority voting and store them in a new dataframe column called <code>hard_label_task1</code>. Items without a clear majority will be removed from the dataset.</li>
<li><strong>Filter the DataFrame</strong> to keep only rows where the <code>lang</code> column is <code>'en'</code>.</li>
<li><strong>Remove unwanted columns</strong>: Keep only <code>id_EXIST</code>, <code>lang</code>, <code>tweet</code>, and <code>hard_label_task1</code>.</li>
<li><strong>Encode the <code>hard_label_task1</code> column</strong>: Use 1 to represent “YES” and 0 to represent “NO”.</li>
</ol>
<div id="cell-9" class="cell" data-outputid="8aae8cf4-53d5-42c0-e960-b1d3c86bf833">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install datasets <span class="op">--</span>quiet</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install evaluate <span class="op">--</span>quiet</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install simplejson <span class="op">--</span>quiet</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>python <span class="op">-</span>m spacy download es_core_news_sm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Collecting es-core-news-sm==3.7.0
  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.9/12.9 MB 68.1 MB/s eta 0:00:00
Requirement already satisfied: spacy&lt;3.8.0,&gt;=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)
Requirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (3.0.12)
Requirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (1.0.5)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (1.0.11)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (2.0.10)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (3.0.9)
Requirement already satisfied: thinc&lt;8.3.0,&gt;=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (8.2.5)
Requirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (1.1.3)
Requirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (2.5.0)
Requirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (2.0.10)
Requirement already satisfied: weasel&lt;0.5.0,&gt;=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (0.4.1)
Requirement already satisfied: typer&lt;1.0.0,&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (0.15.1)
Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (4.67.1)
Requirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (2.32.3)
Requirement already satisfied: pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (2.10.3)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (3.1.4)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (75.1.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (24.2)
Requirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (3.5.0)
Requirement already satisfied: numpy&gt;=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (1.26.4)
Requirement already satisfied: language-data&gt;=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (1.3.0)
Requirement already satisfied: annotated-types&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (0.7.0)
Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (2.27.1)
Requirement already satisfied: typing-extensions&gt;=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (4.12.2)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (3.4.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (3.10)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (2.2.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (2024.12.14)
Requirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (0.7.11)
Requirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (0.1.5)
Requirement already satisfied: click&gt;=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (8.1.7)
Requirement already satisfied: shellingham&gt;=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (1.5.4)
Requirement already satisfied: rich&gt;=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (13.9.4)
Requirement already satisfied: cloudpathlib&lt;1.0.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (0.20.0)
Requirement already satisfied: smart-open&lt;8.0.0,&gt;=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (7.1.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (3.0.2)
Requirement already satisfied: marisa-trie&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data&gt;=1.2-&gt;langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (1.2.1)
Requirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (3.0.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (2.18.0)
Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open&lt;8.0.0,&gt;=5.2.1-&gt;weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (1.17.0)
Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.0-&gt;es-core-news-sm==3.7.0) (0.1.2)
✔ Download and installation successful
You can now load the package via spacy.load('es_core_news_sm')
⚠ Restart to reload dependencies
If you are in a Jupyter or Colab notebook, you may need to restart Python in
order to load all the package's dependencies. You can do this by selecting the
'Restart kernel' or 'Restart runtime' option.</code></pre>
</div>
</div>
<div id="cell-10" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> simplejson <span class="im">as</span> sj</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> <span class="bu">reduce</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, List, Callable, Tuple, Optional</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.ticker <span class="im">import</span> MaxNLocator</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> softmax</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk <span class="im">import</span> pos_tag</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim.downloader <span class="im">as</span> gloader</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    classification_report,</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    confusion_matrix,</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    ConfusionMatrixDisplay,</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    f1_score,</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Input, Embedding, Bidirectional, LSTM, Dense</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.metrics <span class="im">import</span> F1Score, Precision, Recall</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> plot_model</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    AutoModelForSequenceClassification,</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    TFAutoModelForSequenceClassification,</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    TrainingArguments,</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    DataCollatorWithPadding,</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    Trainer,</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    EarlyStoppingCallback,</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datasets</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score, accuracy_score, roc_curve, roc_auc_score, precision_recall_curve, PrecisionRecallDisplay, auc</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-11" class="cell" data-outputid="aa18ea90-106d-4925-f961-dc71aee0e5f5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">"punkt_tab"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">"wordnet"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">"averaged_perceptron_tagger_eng"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">"stopwords"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package punkt_tab to /root/nltk_data...
[nltk_data]   Package punkt_tab is already up-to-date!
[nltk_data] Downloading package wordnet to /root/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger_eng to
[nltk_data]     /root/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-
[nltk_data]       date!
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>True</code></pre>
</div>
</div>
<div id="cell-12" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_reproducibility(seed: <span class="bu">int</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Fixes any possible source of randomness.</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param seed: seed to ensure reproducibility (int)</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    keras.utils.set_random_seed(seed)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    os.environ[<span class="st">"PYTHONHASHSEED"</span>] <span class="op">=</span> <span class="bu">str</span>(seed)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    tf.config.experimental.enable_op_determinism()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    os.environ[<span class="st">"TF_DETERMINISTIC_OPS"</span>] <span class="op">=</span> <span class="st">"1"</span>  <span class="co">### can make training slower</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>set_reproducibility(seed<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol type="1">
<li><strong>Download</strong> the <code>A1/data</code> folder.</li>
<li><strong>Load</strong> the three JSON files and encode them as pandas dataframes.</li>
</ol>
<div id="cell-14" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/main/2024-2025/Assignment%201/data/"</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.read_json(url <span class="op">+</span> <span class="st">"training.json"</span>).T</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>validation_df <span class="op">=</span> pd.read_json(url <span class="op">+</span> <span class="st">"validation.json"</span>).T</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.read_json(url <span class="op">+</span> <span class="st">"test.json"</span>).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-15" class="cell" data-outputid="268c8377-d4d2-49a1-edb8-f2923e957269">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set shape: </span><span class="sc">{</span>train_df<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation set shape: </span><span class="sc">{</span>validation_df<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test set shape: </span><span class="sc">{</span>test_df<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training set shape: (6920, 11)
Validation set shape: (726, 11)
Test set shape: (312, 11)</code></pre>
</div>
</div>
<ol start="3" type="1">
<li><strong>Generate hard labels</strong> for Task 1 using majority voting and store them in a new dataframe column called <code>hard_label_task1</code>. Items without a clear majority will be removed from the dataset.</li>
<li><strong>Filter the DataFrame</strong> to keep only rows where the <code>lang</code> column is <code>'en'</code>.</li>
<li><strong>Remove unwanted columns</strong>: Keep only <code>id_EXIST</code>, <code>lang</code>, <code>tweet</code>, and <code>hard_label_task1</code>.</li>
<li><strong>Encode the <code>hard_label_task1</code> column</strong>: Use 1 to represent “YES” and 0 to represent “NO”.</li>
</ol>
<div id="cell-17" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> determine_label(row: pd.Series) <span class="op">-&gt;</span> Optional[<span class="bu">str</span>]:</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Converts soft labels into hard labels (strings).</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param row: row of the dataset to convert (pd.Series)</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - string representing the hard label</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    num_yes <span class="op">=</span> row[<span class="st">"labels_task1"</span>].count(<span class="st">"YES"</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    num_no <span class="op">=</span> row[<span class="st">"labels_task1"</span>].count(<span class="st">"NO"</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> num_yes <span class="op">==</span> num_no:</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"YES"</span> <span class="cf">if</span> num_yes <span class="op">&gt;</span> num_no <span class="cf">else</span> <span class="st">"NO"</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> corpus(df: pd.DataFrame, multilingual:<span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co">    Converts soft labels into hard labels (int) and drops irrelevant rows/columns.</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co">    :param df: dataset split to convert (pd.DataFrame)</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="co">    :param multilingual: whether to keep spanish tweets (bool)</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="co">        - refined dataset</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">"hard_label_task1"</span>] <span class="op">=</span> df.<span class="bu">apply</span>(determine_label, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">"hard_label_task1"</span>])</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> multilingual:</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>      df <span class="op">=</span> df[df[<span class="st">"lang"</span>] <span class="op">!=</span> <span class="st">"es"</span>]</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df[[<span class="st">"id_EXIST"</span>, <span class="st">"lang"</span>, <span class="st">"tweet"</span>, <span class="st">"hard_label_task1"</span>]]</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>    df.loc[df[<span class="st">"hard_label_task1"</span>] <span class="op">==</span> <span class="st">"YES"</span>, <span class="st">"hard_label_task1"</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    df.loc[df[<span class="st">"hard_label_task1"</span>] <span class="op">==</span> <span class="st">"NO"</span>, <span class="st">"hard_label_task1"</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    df.reset_index(drop<span class="op">=</span><span class="va">True</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-18" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> corpus(train_df)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>validation_df <span class="op">=</span> corpus(validation_df)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> corpus(test_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-19" class="cell" data-outputid="1e676dd1-3122-4610-950a-6a6d0b211f9f">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>validation_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">

  <div id="df-4d6d7799-d6fa-4b85-968e-1171db413490" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id_EXIST</th>
<th data-quarto-table-cell-role="th">lang</th>
<th data-quarto-table-cell-role="th">tweet</th>
<th data-quarto-table-cell-role="th">hard_label_task1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>400001</td>
<td>en</td>
<td>@Mike_Fabricant “You should smile more, love. ...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>400002</td>
<td>en</td>
<td>@BBCWomansHour @LabWomenDec @EverydaySexism Sh...</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>400003</td>
<td>en</td>
<td>#everydaysexism Some man moving my suitcase in...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>400004</td>
<td>en</td>
<td>@KolHue @OliverJia1014 lol gamergate the go to...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>400005</td>
<td>en</td>
<td>@ShelfStoriesGBL To me this has the same negat...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">153</td>
<td>400172</td>
<td>en</td>
<td>@leesu44 @elishabroadway @markbann57 @SeaeyesT...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">154</td>
<td>400174</td>
<td>en</td>
<td>It is is impossible for a man to become a woma...</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">155</td>
<td>400175</td>
<td>en</td>
<td>If Gaga decided to sing 18 versions of Free Wo...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">156</td>
<td>400176</td>
<td>en</td>
<td>This is your reminder that you can be child-fr...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">157</td>
<td>400177</td>
<td>en</td>
<td>just completed my last final, i’m officially a...</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>158 rows × 4 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-4d6d7799-d6fa-4b85-968e-1171db413490')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-4d6d7799-d6fa-4b85-968e-1171db413490 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-4d6d7799-d6fa-4b85-968e-1171db413490');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-a50a28f7-7793-4135-a577-1867891d1475">
  <button class="colab-df-quickchart" onclick="quickchart('df-a50a28f7-7793-4135-a577-1867891d1475')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-a50a28f7-7793-4135-a577-1867891d1475 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_027ac75e-3b8b-4ff9-9d25-7eb43ebab8a3">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('validation_df')" title="Generate code using this dataframe." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"></path>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_027ac75e-3b8b-4ff9-9d25-7eb43ebab8a3 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('validation_df');
      }
      })();
    </script>
  </div>

    </div>
  </div>
</div>
</div>
</section>
</section>
</section>
<section id="task2---0.5-points-data-cleaning" class="level1">
<h1>[Task2 - 0.5 points] Data Cleaning</h1>
<p>In the context of tweets, we have noisy and informal data that often includes unnecessary elements like emojis, hashtags, mentions, and URLs. These elements may interfere with the text analysis.</p>
<section id="instructions-1" class="level3">
<h3 class="anchored" data-anchor-id="instructions-1">Instructions</h3>
<ul>
<li><strong>Remove emojis</strong> from the tweets.</li>
<li><strong>Remove hashtags</strong> (e.g., <code>#example</code>).</li>
<li><strong>Remove mentions</strong> such as <code>@user</code>.</li>
<li><strong>Remove URLs</strong> from the tweets.</li>
<li><strong>Remove special characters and symbols</strong>.</li>
<li><strong>Remove specific quote characters</strong> (e.g., curly quotes).</li>
<li><strong>Perform lemmatization</strong> to reduce words to their base form.</li>
</ul>
<p>In order to filter out emojis we used an up-to-date list of emoji data from Github.</p>
<div id="cell-23" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> (</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://raw.githubusercontent.com/muan/unicode-emoji-json/main/data-by-emoji.json"</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(url)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>json_data <span class="op">=</span> response.json()</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>emoji_list <span class="op">=</span> <span class="bu">list</span>(json_data.keys())</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>regex_pattern <span class="op">=</span> <span class="st">"|"</span>.join(re.escape(word) <span class="cf">for</span> word <span class="kw">in</span> emoji_list)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>EMOJI_RE <span class="op">=</span> re.<span class="bu">compile</span>(regex_pattern)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>HASHTAG_RE <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r"\B\@(\w)+"</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>MENTIONS_RE <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r"\B\#(\w)+"</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>URLS_RE <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r"https?://\S*"</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>SPECIAL_CHAR_RE <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r"[^a-zA-Z]"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-24" class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_emojis(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Removes emojis from the given text.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param text: text to be filtered (str)</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - cleaned text</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> EMOJI_RE.sub(<span class="st">" "</span>, text)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_hashtags(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Removes hashtags from the given text.</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co">    :param text: text to be filtered (str)</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co">        - cleaned text</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> HASHTAG_RE.sub(<span class="st">" "</span>, text)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_mentions(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="co">    Removes mentions from the given text.</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="co">    :param text: text to be filtered (str)</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a><span class="co">        - cleaned text</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> MENTIONS_RE.sub(<span class="st">" "</span>, text)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_urls(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a><span class="co">    Removes URLs from the given text.</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="co">    :param text: text to be filtered (str)</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a><span class="co">        - cleaned text</span></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> URLS_RE.sub(<span class="st">" "</span>, text)</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_special_chars(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a><span class="co">    Removes special chars from the given text.</span></span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a><span class="co">    :param text: text to be filtered (str)</span></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a><span class="co">        - cleaned text</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> SPECIAL_CHAR_RE.sub(<span class="st">" "</span>, text)</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lower(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a><span class="co">    Transforms given text to lower case.</span></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a><span class="co">    :param text: text to be filtered (str)</span></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a><span class="co">        - cleaned text</span></span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text.lower()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Pipeline for the preprocessing of text.</p>
<div id="cell-26" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>PREPROCESSING_PIPELINE <span class="op">=</span> [</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    remove_emojis,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    remove_hashtags,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    remove_mentions,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    remove_urls,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    remove_special_chars,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    lower,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> text_prepare(text: <span class="bu">str</span>, filter_methods: Optional[List[Callable[[<span class="bu">str</span>], <span class="bu">str</span>]]] <span class="op">=</span> <span class="va">None</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Applies a list of pre-processing functions in sequence (reduce).</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co">    :param text: text to be processed (str)</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co">    :param filter_methods: list of functions to apply (list)</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co">        - pre-processed text</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    filter_methods <span class="op">=</span> (</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        filter_methods <span class="cf">if</span> filter_methods <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> PREPROCESSING_PIPELINE</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">reduce</span>(<span class="kw">lambda</span> txt, f: f(txt), filter_methods, text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sanity check on preprocessing pipeline.</p>
<div id="cell-28" class="cell" data-outputid="0df77c25-d1b1-4e9d-f2e5-b77839756716">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Pre-processing text..."</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">[Debug] Before:</span><span class="ch">\n</span><span class="sc">{</span>train_df[<span class="st">'tweet'</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace each sentence with its pre-processed version</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"tweet"</span>] <span class="op">=</span> train_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> txt: text_prepare(txt))</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[Debug] After:</span><span class="ch">\n</span><span class="sc">{</span>train_df[<span class="st">'tweet'</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Pre-processing completed!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Pre-processing text...

[Debug] Before:
Writing a uni essay in my local pub with a coffee. Random old man keeps asking me drunk questions when I'm trying to concentrate &amp;amp; ends with "good luck, but you'll just end up getting married and not use it anyway". #EverydaySexism is alive and well 🙃

[Debug] After:
writing a uni essay in my local pub with a coffee  random old man keeps asking me drunk questions when i m trying to concentrate  amp  ends with  good luck  but you ll just end up getting married and not use it anyway     is alive and well  

Pre-processing completed!</code></pre>
</div>
</div>
<p>We stored a copy of train, validation and test that we used later in the Transformer section.</p>
<div id="cell-30" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>validation_df[<span class="st">"tweet"</span>] <span class="op">=</span> validation_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> txt: text_prepare(txt))</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"tweet"</span>] <span class="op">=</span> test_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> txt: text_prepare(txt))</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>train_df.to_csv(<span class="st">"train_cleaned.csv"</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>validation_df.to_csv(<span class="st">"validation_cleaned.csv"</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>test_df.to_csv(<span class="st">"test_cleaned.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><strong>Perform lemmatization</strong> to reduce words to their base form.</li>
</ul>
<div id="cell-32" class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_wordnet_key(pos_tag: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Converts pos_tag to the correct format.</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param pos_tag: tag to be converted (str)</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - formatted tag</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pos_tag.startswith(<span class="st">"J"</span>):</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> wordnet.ADJ</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> pos_tag.startswith(<span class="st">"V"</span>):</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> wordnet.VERB</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> pos_tag.startswith(<span class="st">"N"</span>):</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> wordnet.NOUN</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> pos_tag.startswith(<span class="st">"R"</span>):</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> wordnet.ADV</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"n"</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_tweet(tweet: <span class="bu">str</span>) <span class="op">-&gt;</span> List[<span class="bu">str</span>]:</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="co">    Applies tokenization and lemmatization to the given text.</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="co">    :param tweet: text to be tokenized (str)</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="co">        - tokenized and lemmatized tweet</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>    lemmatizer <span class="op">=</span> WordNetLemmatizer()</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> word_tokenize(tweet)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> pos_tag(tweet)</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> [lemmatizer.lemmatize(word, get_wordnet_key(tag)) <span class="cf">for</span> word, tag <span class="kw">in</span> tweet]</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tweet</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-33" class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"tweet"</span>] <span class="op">=</span> test_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(tokenize_tweet)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>validation_df[<span class="st">"tweet"</span>] <span class="op">=</span> validation_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(tokenize_tweet)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sanity check on tokenizer.</p>
<div id="cell-35" class="cell" data-outputid="d2ff04c7-5f45-42ee-b594-373307fa747d">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tokenizing text..."</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">[Debug] Before:</span><span class="ch">\n</span><span class="sc">{</span>train_df[<span class="st">'tweet'</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Lemmatize and tokenize each sentence</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"tweet"</span>] <span class="op">=</span> train_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(tokenize_tweet)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[Debug] After:</span><span class="ch">\n</span><span class="sc">{</span>train_df[<span class="st">'tweet'</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tokenization completed!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tokenizing text...

[Debug] Before:
writing a uni essay in my local pub with a coffee  random old man keeps asking me drunk questions when i m trying to concentrate  amp  ends with  good luck  but you ll just end up getting married and not use it anyway     is alive and well  

[Debug] After:
['write', 'a', 'uni', 'essay', 'in', 'my', 'local', 'pub', 'with', 'a', 'coffee', 'random', 'old', 'man', 'keep', 'ask', 'me', 'drunk', 'question', 'when', 'i', 'm', 'try', 'to', 'concentrate', 'amp', 'end', 'with', 'good', 'luck', 'but', 'you', 'll', 'just', 'end', 'up', 'get', 'married', 'and', 'not', 'use', 'it', 'anyway', 'be', 'alive', 'and', 'well']

Tokenization completed!</code></pre>
</div>
</div>
</section>
</section>
<section id="task-3---0.5-points-text-encoding" class="level1">
<h1>[Task 3 - 0.5 points] Text Encoding</h1>
<p>To train a neural sexism classifier, you first need to encode text into numerical format.</p>
<section id="instructions-2" class="level3">
<h3 class="anchored" data-anchor-id="instructions-2">Instructions</h3>
<ul>
<li>Embed words using <strong>GloVe embeddings</strong>.</li>
<li>You are <strong>free</strong> to pick any embedding dimension.</li>
</ul>
</section>
<section id="note-what-about-oov-tokens" class="level3">
<h3 class="anchored" data-anchor-id="note-what-about-oov-tokens">Note : What about OOV tokens?</h3>
<ul>
<li>All the tokens in the <strong>training</strong> set that are not in GloVe <strong>must</strong> be added to the vocabulary.</li>
<li>For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a <strong>special token</strong> (e.g., [UNK]) and a <strong>static</strong> embedding.</li>
<li>You are <strong>free</strong> to define the static embedding using any strategy (e.g., random, neighbourhood, etc…)</li>
</ul>
</section>
<section id="more-about-oov" class="level3">
<h3 class="anchored" data-anchor-id="more-about-oov">More about OOV</h3>
<p>For a given token:</p>
<ul>
<li><strong>If in train set</strong>: add to vocabulary and assign an embedding (use GloVe if token in GloVe, custom embedding otherwise).</li>
<li><strong>If in val/test set</strong>: assign special token if not in vocabulary and assign custom embedding.</li>
</ul>
<p>Your vocabulary <strong>should</strong>:</p>
<ul>
<li>Contain all tokens in train set; or</li>
<li>Union of tokens in train set and in GloVe <span class="math inline">\(\rightarrow\)</span> we make use of existing knowledge!</li>
</ul>
<div id="cell-40" class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_vocabulary(df: pd.DataFrame) <span class="op">-&gt;</span> Tuple[Dict[<span class="bu">int</span>, <span class="bu">str</span>], Dict[<span class="bu">str</span>, <span class="bu">int</span>], List[<span class="bu">str</span>]]:</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Given a dataset, builds the corresponding word vocabulary.</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param df: dataset from which we want to build the word vocabulary (pandas.DataFrame)</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co">    :return:</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co">      - word vocabulary: vocabulary index to word</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">      - inverse word vocabulary: word to vocabulary index</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">      - word listing: set of unique terms that build up the vocabulary</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    idx_to_word <span class="op">=</span> {}</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>    word_to_idx <span class="op">=</span> {}</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    word_to_idx[<span class="st">"PAD"</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    idx_to_word[<span class="dv">0</span>] <span class="op">=</span> <span class="st">"PAD"</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>    word_to_idx[<span class="st">"UNK"</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    idx_to_word[<span class="dv">1</span>] <span class="op">=</span> <span class="st">"UNK"</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    curr_idx <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sentence <span class="kw">in</span> tqdm(df[<span class="st">"tweet"</span>].values):</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> token <span class="kw">in</span> sentence:</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> token <span class="kw">not</span> <span class="kw">in</span> word_to_idx:</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>                word_to_idx[token] <span class="op">=</span> curr_idx</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>                idx_to_word[curr_idx] <span class="op">=</span> token</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>                curr_idx <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>    word_listing <span class="op">=</span> <span class="bu">list</span>(idx_to_word.values())</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> idx_to_word, word_to_idx, word_listing</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-41" class="cell" data-outputid="cc3015e0-b9d4-46e8-853e-14acff3b400f">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>idx_to_word, word_to_idx, word_listing <span class="op">=</span> build_vocabulary(train_df)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">[Debug] Index -&gt; Word vocabulary size: </span><span class="sc">{</span><span class="bu">len</span>(idx_to_word)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[Debug] Word -&gt; Index vocabulary size: </span><span class="sc">{</span><span class="bu">len</span>(word_to_idx)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[Debug] Some words: </span><span class="sc">{</span>[(idx_to_word[idx], idx) <span class="cf">for</span> idx <span class="kw">in</span> np.arange(<span class="dv">20</span>)]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 2870/2870 [00:00&lt;00:00, 146534.38it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
[Debug] Index -&gt; Word vocabulary size: 8872
[Debug] Word -&gt; Index vocabulary size: 8872
[Debug] Some words: [('PAD', 0), ('UNK', 1), ('write', 2), ('a', 3), ('uni', 4), ('essay', 5), ('in', 6), ('my', 7), ('local', 8), ('pub', 9), ('with', 10), ('coffee', 11), ('random', 12), ('old', 13), ('man', 14), ('keep', 15), ('ask', 16), ('me', 17), ('drunk', 18), ('question', 19)]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<div id="cell-42" class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_vocabulary(</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    idx_to_word: Dict[<span class="bu">int</span>, <span class="bu">str</span>],</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    word_to_idx: Dict[<span class="bu">str</span>, <span class="bu">int</span>],</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    word_listing: List[<span class="bu">str</span>],</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    df: pd.DataFrame</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Performs sanity checks on the vocabularies.</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co">    :param idx_to_word: word vocabulary to test (dict)</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co">    :param word_to_idx: inverse word vocabulary to test (dict)</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co">    :param word_listing: set of unique words to test (list)</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co">    :param df: dataset to test (pd.DataFrame)</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"[Vocabulary Evaluation] Size checking..."</span>)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">len</span>(idx_to_word) <span class="op">==</span> <span class="bu">len</span>(word_to_idx)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">len</span>(idx_to_word) <span class="op">==</span> <span class="bu">len</span>(word_listing)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"[Vocabulary Evaluation] Content checking..."</span>)</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(idx_to_word))):</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> idx_to_word[i] <span class="kw">in</span> word_to_idx</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> word_to_idx[idx_to_word[i]] <span class="op">==</span> i</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"[Vocabulary Evaluation] Consistency checking..."</span>)</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    _, _, first_word_listing <span class="op">=</span> build_vocabulary(df)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    _, _, second_word_listing <span class="op">=</span> build_vocabulary(df)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> first_word_listing <span class="op">==</span> second_word_listing</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"[Vocabulary Evaluation] Word_listing checking..."</span>)</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>    _, _, assert_word_listing <span class="op">=</span> build_vocabulary(train_df)</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>    assert_valid_vocabulary <span class="op">=</span> <span class="bu">set</span>(</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>        [token <span class="cf">for</span> tweet <span class="kw">in</span> train_df.tweet.values <span class="cf">for</span> token <span class="kw">in</span> tweet]</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>    assert_valid_vocabulary.update([<span class="st">"PAD"</span>, <span class="st">"UNK"</span>])</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">set</span>(assert_word_listing) <span class="op">==</span> assert_valid_vocabulary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sanity check on vocabulary.</p>
<div id="cell-44" class="cell" data-outputid="32a76107-8f04-4e70-d6f8-54262c834628">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Vocabulary evaluation..."</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>evaluate_vocabulary(idx_to_word, word_to_idx, word_listing, train_df)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Evaluation completed!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Vocabulary evaluation...
[Vocabulary Evaluation] Size checking...
[Vocabulary Evaluation] Content checking...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 8872/8872 [00:00&lt;00:00, 830343.97it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Vocabulary Evaluation] Consistency checking...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 2870/2870 [00:00&lt;00:00, 83462.08it/s]
100%|██████████| 2870/2870 [00:00&lt;00:00, 66044.78it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Vocabulary Evaluation] Word_listing checking...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 2870/2870 [00:00&lt;00:00, 25423.03it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Evaluation completed!</code></pre>
</div>
</div>
<div id="cell-45" class="cell" data-outputid="717a16ba-e3aa-4700-f33b-d02141aed4b6">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>vocab_path <span class="op">=</span> Path.cwd().joinpath(<span class="st">"vocab.json"</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Saving vocabulary to </span><span class="sc">{</span>vocab_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> vocab_path.<span class="bu">open</span>(mode<span class="op">=</span><span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    sj.dump(word_to_idx, f, indent<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Saving completed!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Saving vocabulary to /content/vocab.json
Saving completed!</code></pre>
</div>
</div>
<p>We chose <strong>glove-wiki-gigaword</strong> as a word embedding with a dimension of 300. This <code>embedding_dimension</code> ensures rich semantic representation without heavily increasing the computational cost.</p>
<div id="cell-47" class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>embedding_dimension <span class="op">=</span> <span class="dv">300</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> gloader.load(<span class="ss">f"glove-wiki-gigaword-</span><span class="sc">{</span>embedding_dimension<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-48" class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_OOV_terms(</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    embedding_model: gensim.models.keyedvectors.KeyedVectors, word_listing: List[<span class="bu">str</span>]</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> List[<span class="bu">str</span>]:</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Checks differences between pre-trained embedding model vocabulary</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co">    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co">    :param embedding_model: pre-trained word embedding model (gensim wrapper)</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co">    :param word_listing: dataset specific vocabulary (list)</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="co">        - list of OOV terms</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>    embedding_vocabulary <span class="op">=</span> <span class="bu">set</span>(embedding_model.key_to_index.keys())</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    oov <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>(word_listing).difference(embedding_vocabulary))</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    oov.remove(<span class="st">'UNK'</span>)</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> oov</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-49" class="cell" data-outputid="431abef7-ca90-4267-a0d3-384a54287e4e">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>oov_terms <span class="op">=</span> check_OOV_terms(embedding_model, word_listing)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>oov_percentage <span class="op">=</span> <span class="bu">float</span>(<span class="bu">len</span>(oov_terms)) <span class="op">*</span> <span class="dv">100</span> <span class="op">/</span> <span class="bu">len</span>(word_listing)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total OOV terms: </span><span class="sc">{</span><span class="bu">len</span>(oov_terms)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>oov_percentage<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total OOV terms: 906 (10.21%)</code></pre>
</div>
</div>
<p>After the tokenization process, we stored a copy of validation and test split used in the Error Analysis section.</p>
<div id="cell-51" class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>validation_tokenized <span class="op">=</span> copy.deepcopy(validation_df[<span class="st">'tweet'</span>])</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>test_tokenized <span class="op">=</span> copy.deepcopy(test_df[<span class="st">'tweet'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-52" class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> put_unk(tweet: List[<span class="bu">str</span>]) <span class="op">-&gt;</span> List[<span class="bu">str</span>]:</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Replaces tokens not present in the vocabulary with the "UNK" token.</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param tweet: list of strings, where each string is a token from the tweet (list)</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co">       - list of strings, where tokens not in the vocabulary have been replaced by "UNK"</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> [token <span class="cf">if</span> token <span class="kw">in</span> word_to_idx <span class="cf">else</span> <span class="st">"UNK"</span> <span class="cf">for</span> token <span class="kw">in</span> tweet]</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tweet</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-53" class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>validation_df[<span class="st">"tweet"</span>] <span class="op">=</span> validation_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(put_unk)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"tweet"</span>] <span class="op">=</span> test_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(put_unk)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We assigned a zero vector as the embedding of the PAD token since, in this way, it will be masked out by the embedding layer of the model.</p>
<div id="cell-55" class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_embedding_matrix(</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    embedding_model: gensim.models.keyedvectors.KeyedVectors,</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    embedding_dimension: <span class="bu">int</span>,</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    word_to_idx: Dict[<span class="bu">str</span>, <span class="bu">int</span>],</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    vocab_size: <span class="bu">int</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model.</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="co">    :param embedding_model: pre-trained word embedding model (gensim wrapper)</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="co">    :param embedding_dimension: dimension of the embedding space (int)</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="co">    :param word_to_idx: vocabulary map (word -&gt; index) (dict)</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="co">    :param vocab_size: size of the vocabulary</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="co">        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>    embedding_matrix <span class="op">=</span> np.zeros((vocab_size, embedding_dimension), dtype<span class="op">=</span>np.float32)</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word, idx <span class="kw">in</span> tqdm(word_to_idx.items()):</span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> word <span class="op">==</span> <span class="st">"PAD"</span>:</span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>                embedding_vector <span class="op">=</span> embedding_model[word]</span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> (<span class="pp">KeyError</span>, <span class="pp">TypeError</span>):</span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a>                embedding_vector <span class="op">=</span> np.random.uniform(</span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a>                    low<span class="op">=-</span><span class="fl">0.05</span>, high<span class="op">=</span><span class="fl">0.05</span>, size<span class="op">=</span>embedding_dimension</span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-30"><a href="#cb48-30" aria-hidden="true" tabindex="-1"></a>        embedding_matrix[idx] <span class="op">=</span> embedding_vector</span>
<span id="cb48-31"><a href="#cb48-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-32"><a href="#cb48-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> embedding_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Check of the embedding matrix shape.</p>
<div id="cell-57" class="cell" data-outputid="9c2777cc-8b08-4fea-82f0-463fb5c195ae">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>embedding_dimension <span class="op">=</span> <span class="dv">300</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>embedding_matrix <span class="op">=</span> build_embedding_matrix(</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>    embedding_model, embedding_dimension, word_to_idx, <span class="bu">len</span>(word_to_idx)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Embedding matrix shape: </span><span class="sc">{</span>embedding_matrix<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 8872/8872 [00:00&lt;00:00, 258821.94it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Embedding matrix shape: (8872, 300)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<div id="cell-58" class="cell" data-outputid="b12add8a-0be0-42f3-8522-dc4f302e2d59">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>max_train_length <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(tweet) <span class="cf">for</span> tweet <span class="kw">in</span> train_df[<span class="st">"tweet"</span>])</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>max_validation_length <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(tweet) <span class="cf">for</span> tweet <span class="kw">in</span> validation_df[<span class="st">"tweet"</span>])</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>max_test_length <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(tweet) <span class="cf">for</span> tweet <span class="kw">in</span> test_df[<span class="st">"tweet"</span>])</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>max_sequence_lenght <span class="op">=</span> <span class="bu">max</span>(max_train_length, max_validation_length, max_test_length)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max sequence lenght in train set: </span><span class="sc">{</span>max_train_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max sequence lenght in validation set: </span><span class="sc">{</span>max_validation_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max sequence lenght in test set: </span><span class="sc">{</span>max_test_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max sequence lenght: </span><span class="sc">{</span>max_sequence_lenght<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Max sequence lenght in train set: 62
Max sequence lenght in validation set: 55
Max sequence lenght in test set: 61
Max sequence lenght: 62</code></pre>
</div>
</div>
<div id="cell-59" class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pad_tweet(tweet: List[<span class="bu">str</span>]) <span class="op">-&gt;</span> List[<span class="bu">str</span>]:</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Pads a tweet to a fixed length.</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param tweet: tweet to be padded (list)</span></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - padded tweet</span></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="bu">len</span>(tweet)</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i <span class="op">&lt;</span> max_sequence_lenght:</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>        tweet.append(idx_to_word[<span class="dv">0</span>])</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> i <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tweet</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-60" class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"tweet"</span>] <span class="op">=</span> train_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(pad_tweet)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>validation_df[<span class="st">"tweet"</span>] <span class="op">=</span> validation_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(pad_tweet)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"tweet"</span>] <span class="op">=</span> test_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(pad_tweet)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sanity check on padded text.</p>
<div id="cell-62" class="cell" data-outputid="aa3335db-dc81-45e2-f5df-441562b53789">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> assert_padding(df: pd.DataFrame) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Ensures that the padding has been applied correctly.</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param df: dataset to test (pd.DataFrame)</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"[Debug] Padding checking..."</span>)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tweet <span class="kw">in</span> df[<span class="st">"tweet"</span>]:</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> <span class="bu">len</span>(tweet) <span class="op">==</span> max_sequence_lenght</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Padding checked!"</span>)</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>assert_padding(train_df)</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>assert_padding(validation_df)</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>assert_padding(test_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Debug] Padding checking...
Padding checked!
[Debug] Padding checking...
Padding checked!
[Debug] Padding checking...
Padding checked!</code></pre>
</div>
</div>
<p>Numerical conversion of tokens to feed them to the model.</p>
<div id="cell-64" class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> word_to_num(tweet: List[<span class="bu">str</span>]) <span class="op">-&gt;</span> List[<span class="bu">int</span>]:</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Converts words in a tweet to their corresponding indices.</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param tweet: list of words to convert (List[str])</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - converted tweet</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> [word_to_idx[word] <span class="cf">for</span> word <span class="kw">in</span> tweet]</span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tweet</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-65" class="cell" data-outputid="5bff50bd-9280-420c-ed19-464ebd95db39">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"tweet"</span>] <span class="op">=</span> train_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(word_to_num)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>validation_df[<span class="st">"tweet"</span>] <span class="op">=</span> validation_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(word_to_num)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"tweet"</span>] <span class="op">=</span> test_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(word_to_num)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>train_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">

  <div id="df-67d0a998-8a37-4937-9cd9-4b65e9074da9" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id_EXIST</th>
<th data-quarto-table-cell-role="th">lang</th>
<th data-quarto-table-cell-role="th">tweet</th>
<th data-quarto-table-cell-role="th">hard_label_task1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>200002</td>
<td>en</td>
<td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 11, 12, 13, 14...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>200003</td>
<td>en</td>
<td>[40, 42, 38, 21, 45, 46, 47, 48, 49, 50, 51, 5...</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>200006</td>
<td>en</td>
<td>[63, 24, 3, 64, 21, 65, 66, 67, 68, 24, 69, 70...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>200007</td>
<td>en</td>
<td>[83, 84, 85, 86, 87, 88, 30, 89, 31, 90, 91, 3...</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>200008</td>
<td>en</td>
<td>[95, 24, 58, 96, 97, 98, 56, 99, 24, 100, 101,...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2865</td>
<td>203256</td>
<td>en</td>
<td>[975, 207, 1120, 125, 334, 597, 65, 1150, 53, ...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2866</td>
<td>203257</td>
<td>en</td>
<td>[97, 65, 42, 3, 326, 67, 350, 3491, 10, 251, 2...</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2867</td>
<td>203258</td>
<td>en</td>
<td>[693, 17, 427, 38, 777, 31, 35, 243, 42, 1217,...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2868</td>
<td>203259</td>
<td>en</td>
<td>[207, 133, 31, 56, 77, 3, 2275, 8870, 0, 0, 0,...</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2869</td>
<td>203260</td>
<td>en</td>
<td>[5149, 20, 8871, 436, 31, 56, 77, 3, 2275, 21,...</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>2870 rows × 4 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-67d0a998-8a37-4937-9cd9-4b65e9074da9')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-67d0a998-8a37-4937-9cd9-4b65e9074da9 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-67d0a998-8a37-4937-9cd9-4b65e9074da9');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-cefe6f47-cf5f-4b6e-b2ff-1f5dee9db395">
  <button class="colab-df-quickchart" onclick="quickchart('df-cefe6f47-cf5f-4b6e-b2ff-1f5dee9db395')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-cefe6f47-cf5f-4b6e-b2ff-1f5dee9db395 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_e4d5eb4c-38c8-4f1c-8f95-7f81057ad8c8">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('train_df')" title="Generate code using this dataframe." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"></path>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_e4d5eb4c-38c8-4f1c-8f95-7f81057ad8c8 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('train_df');
      }
      })();
    </script>
  </div>

    </div>
  </div>
</div>
</div>
</section>
</section>
<section id="task-4---1.0-points-model-definition" class="level1">
<h1>[Task 4 - 1.0 points] Model definition</h1>
<p>You are now tasked to define your sexism classifier.</p>
<section id="instructions-3" class="level3">
<h3 class="anchored" data-anchor-id="instructions-3">Instructions</h3>
<ul>
<li><p><strong>Baseline</strong>: implement a Bidirectional LSTM with a Dense layer on top.</p></li>
<li><p>You are <strong>free</strong> to experiment with hyper-parameters to define the baseline model.</p></li>
<li><p><strong>Model 1</strong>: add an additional LSTM layer to the Baseline model.</p></li>
</ul>
</section>
<section id="token-to-embedding-mapping" class="level3">
<h3 class="anchored" data-anchor-id="token-to-embedding-mapping">Token to embedding mapping</h3>
<p>You can follow two approaches for encoding tokens in your classifier.</p>
</section>
<section id="work-directly-with-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="work-directly-with-embeddings">Work directly with embeddings</h3>
<ul>
<li>Compute the embedding of each input token</li>
<li>Feed the mini-batches of shape (batch_size, # tokens, embedding_dim) to your model</li>
</ul>
</section>
<section id="work-with-embedding-layer" class="level3">
<h3 class="anchored" data-anchor-id="work-with-embedding-layer">Work with Embedding layer</h3>
<ul>
<li>Encode input tokens to token ids</li>
<li>Define a Embedding layer as the first layer of your model</li>
<li>Compute the embedding matrix of all known tokens (i.e., tokens in your vocabulary)</li>
<li>Initialize the Embedding layer with the computed embedding matrix</li>
<li>You are <strong>free</strong> to set the Embedding layer trainable or not</li>
</ul>
<p>We prepared the data by converting everything to a NumPy array as required by the Keras fit function.</p>
<div id="cell-70" class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_data(</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    sentences: pd.Series,</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>    labels: pd.Series</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[np.ndarray, np.ndarray]:</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Reshapes and casts sentences and labels.</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co">    :param sentences: sentences to be casted (pd.Series)</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="co">    :param labels: labels to be casted and reshaped (pd.Series)</span></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a><span class="co">        - sentences casted to np.ndarray</span></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a><span class="co">        - labels casted to np.ndarray and reshaped to (-1, 1)</span></span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>    sentences <span class="op">=</span> np.array(<span class="bu">list</span>(sentences))</span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> np.array(<span class="bu">list</span>(labels))</span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> np.expand_dims(labels, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sentences, labels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-71" class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>train_sentences, train_labels <span class="op">=</span> format_data(</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>    train_df[<span class="st">"tweet"</span>], train_df[<span class="st">"hard_label_task1"</span>]</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>validation_sentences, validation_labels <span class="op">=</span> format_data(</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>    validation_df[<span class="st">"tweet"</span>], validation_df[<span class="st">"hard_label_task1"</span>]</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>test_sentences, test_labels <span class="op">=</span> format_data(test_df[<span class="st">"tweet"</span>], test_df[<span class="st">"hard_label_task1"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We used <code>to_categorical</code> to convert train and validation labels into one-hot encoded format because we used Softmax as the last layer of our model. This conversion was necessary to compute macro metrics during training. Without this step, using a single-neuron output with a sigmoid activation function, Keras would have computed the metrics only for the positive class.</p>
<div id="cell-73" class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>categorical_train_labels <span class="op">=</span> tf.keras.utils.to_categorical(train_labels, num_classes<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>categorical_validation_labels <span class="op">=</span> tf.keras.utils.to_categorical(</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>    validation_labels, num_classes<span class="op">=</span><span class="dv">2</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The function below builds a Bidirectional LSTM model with an optional additional LSTM layer. The <code>add_lstm</code> parameter is a boolean flag that acts as the following:</p>
<ul>
<li>if <code>add_lstm=False</code>, only the first Bidirectional LSTM layer is used, making the model simpler. (<strong>Baseline</strong>)</li>
<li>if <code>add_lstm=True</code>, a second Bidirectional LSTM layer is added after the first, providing a deeper model. (<strong>Model 1</strong>)</li>
</ul>
<p>Since the pre-trained embeddings already capture semantic relationships well, we adopted frozen embeddings by setting <code>trainable=False</code>, drastically reducing the number of trainable parameters and so preventing overfitting.</p>
<div id="cell-75" class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_model(lstm_units: <span class="bu">int</span> <span class="op">=</span> <span class="dv">64</span>, add_lstm: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>, vocab_size: <span class="bu">int</span> <span class="op">=</span> <span class="bu">len</span>(word_listing)) <span class="op">-&gt;</span> keras.Model:</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Builds a Bidirectional LSTM model layer by layer.</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param lstm_units: number of LSMT cells (int)</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="co">    :param add_lstm: whether or not to put an additional LSTM layer (bool)</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :param vocab_size: size of the vocabulary (int)</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a><span class="co">        - Bidirectional LSTM model</span></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> Input(shape<span class="op">=</span>(max_sequence_lenght,))</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>    embedding_layer <span class="op">=</span> Embedding(</span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>        input_dim<span class="op">=</span>vocab_size,</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>        output_dim<span class="op">=</span>embedding_dimension,</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>        weights<span class="op">=</span>[embedding_matrix],</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>        mask_zero<span class="op">=</span><span class="va">True</span>,  <span class="co"># automatically masks padding tokens</span></span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>        name<span class="op">=</span><span class="st">"encoder_embedding"</span>,</span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>        trainable<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>    embedding <span class="op">=</span> embedding_layer(<span class="bu">input</span>)</span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a>    bi_lstm <span class="op">=</span> Bidirectional(LSTM(lstm_units, return_sequences<span class="op">=</span>add_lstm))(embedding)</span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>    bi_lstm2 <span class="op">=</span> (</span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>        Bidirectional(LSTM(lstm_units, return_sequences<span class="op">=</span><span class="va">False</span>))(bi_lstm)</span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> add_lstm</span>
<span id="cb64-27"><a href="#cb64-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span> bi_lstm</span>
<span id="cb64-28"><a href="#cb64-28" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb64-29"><a href="#cb64-29" aria-hidden="true" tabindex="-1"></a>    dense_output <span class="op">=</span> Dense(units<span class="op">=</span><span class="dv">2</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)(bi_lstm2)</span>
<span id="cb64-30"><a href="#cb64-30" aria-hidden="true" tabindex="-1"></a>    model_name <span class="op">=</span> <span class="st">"Model_1"</span> <span class="cf">if</span> add_lstm <span class="cf">else</span> <span class="st">"Baseline"</span></span>
<span id="cb64-31"><a href="#cb64-31" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(<span class="bu">input</span>, dense_output, name<span class="op">=</span>model_name)</span>
<span id="cb64-32"><a href="#cb64-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-33"><a href="#cb64-33" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb64-34"><a href="#cb64-34" aria-hidden="true" tabindex="-1"></a>        loss<span class="op">=</span>keras.losses.CategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb64-35"><a href="#cb64-35" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>keras.optimizers.AdamW(learning_rate<span class="op">=</span><span class="fl">0.001</span>, weight_decay<span class="op">=</span><span class="fl">0.01</span>),</span>
<span id="cb64-36"><a href="#cb64-36" aria-hidden="true" tabindex="-1"></a>        metrics<span class="op">=</span>[</span>
<span id="cb64-37"><a href="#cb64-37" aria-hidden="true" tabindex="-1"></a>            F1Score(average<span class="op">=</span><span class="st">"macro"</span>, threshold<span class="op">=</span><span class="fl">0.5</span>),</span>
<span id="cb64-38"><a href="#cb64-38" aria-hidden="true" tabindex="-1"></a>            Precision(name<span class="op">=</span><span class="st">"precision_zero"</span>, thresholds<span class="op">=</span><span class="fl">0.5</span>, class_id<span class="op">=</span><span class="dv">0</span>),</span>
<span id="cb64-39"><a href="#cb64-39" aria-hidden="true" tabindex="-1"></a>            Precision(name<span class="op">=</span><span class="st">"precision_one"</span>, thresholds<span class="op">=</span><span class="fl">0.5</span>, class_id<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb64-40"><a href="#cb64-40" aria-hidden="true" tabindex="-1"></a>            Recall(name<span class="op">=</span><span class="st">"recall_zero"</span>, thresholds<span class="op">=</span><span class="fl">0.5</span>, class_id<span class="op">=</span><span class="dv">0</span>),</span>
<span id="cb64-41"><a href="#cb64-41" aria-hidden="true" tabindex="-1"></a>            Recall(name<span class="op">=</span><span class="st">"recall_one"</span>, thresholds<span class="op">=</span><span class="fl">0.5</span>, class_id<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb64-42"><a href="#cb64-42" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb64-43"><a href="#cb64-43" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb64-44"><a href="#cb64-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-76" class="cell" data-outputid="cdaaf839-13e2-4eec-ef23-9aa3dd57db21">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>baseline <span class="op">=</span> get_model()</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>plot_model(</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    baseline, to_file<span class="op">=</span><span class="st">"baseline_summary.png"</span>, show_shapes<span class="op">=</span><span class="va">True</span>, dpi<span class="op">=</span><span class="dv">60</span>, show_dtype<span class="op">=</span><span class="va">True</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>baseline.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "Baseline"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)              </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">        Param # </span>┃<span style="font-weight: bold"> Connected to           </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">62</span>)             │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ -                      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ encoder_embedding         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">62</span>, <span style="color: #00af00; text-decoration-color: #00af00">300</span>)        │      <span style="color: #00af00; text-decoration-color: #00af00">2,661,600</span> │ input_layer[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]      │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">Embedding</span>)               │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ not_equal (<span style="color: #0087ff; text-decoration-color: #0087ff">NotEqual</span>)      │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">62</span>)             │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ input_layer[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ bidirectional             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">186,880</span> │ encoder_embedding[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">…</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">Bidirectional</span>)           │                        │                │ not_equal[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ dense (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">258</span> │ bidirectional[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]    │
└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,848,738</span> (10.87 MB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">187,138</span> (731.01 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,661,600</span> (10.15 MB)
</pre>
</div>
</div>
<div id="cell-77" class="cell" data-outputid="452aa3b6-1803-438e-8de7-5fe4dc26df97">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>model_1 <span class="op">=</span> get_model(add_lstm<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>plot_model(</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>    model_1, to_file<span class="op">=</span><span class="st">"model_1_summary.png"</span>, show_shapes<span class="op">=</span><span class="va">True</span>, dpi<span class="op">=</span><span class="dv">60</span>, show_dtype<span class="op">=</span><span class="va">True</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>model_1.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "Model_1"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)              </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">        Param # </span>┃<span style="font-weight: bold"> Connected to           </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer_1             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">62</span>)             │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ -                      │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)              │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ encoder_embedding         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">62</span>, <span style="color: #00af00; text-decoration-color: #00af00">300</span>)        │      <span style="color: #00af00; text-decoration-color: #00af00">2,661,600</span> │ input_layer_1[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]    │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">Embedding</span>)               │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ not_equal_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">NotEqual</span>)    │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">62</span>)             │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ input_layer_1[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ bidirectional_1           │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">62</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)        │        <span style="color: #00af00; text-decoration-color: #00af00">186,880</span> │ encoder_embedding[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">…</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">Bidirectional</span>)           │                        │                │ not_equal_1[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ bidirectional_2           │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │         <span style="color: #00af00; text-decoration-color: #00af00">98,816</span> │ bidirectional_1[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>], │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">Bidirectional</span>)           │                        │                │ not_equal_1[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ dense_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)           │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">258</span> │ bidirectional_2[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]  │
└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,947,554</span> (11.24 MB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">285,954</span> (1.09 MB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,661,600</span> (10.15 MB)
</pre>
</div>
</div>
</section>
<section id="padding" class="level3">
<h3 class="anchored" data-anchor-id="padding">Padding</h3>
<p>Pay attention to padding tokens!</p>
<p>Your model <strong>should not</strong> be penalized on those tokens.</p>
<section id="how-to" class="level4">
<h4 class="anchored" data-anchor-id="how-to">How to?</h4>
<p>There are two main ways.</p>
<p>However, their implementation depends on the neural library you are using.</p>
<ul>
<li>Embedding layer</li>
<li>Custom loss to compute average cross-entropy on non-padding tokens only</li>
</ul>
<p><strong>Note</strong>: This is a <strong>recommendation</strong>, but we <strong>do not penalize</strong> for missing workarounds.</p>
</section>
</section>
</section>
<section id="task-5---1.0-points-training-and-evaluation" class="level1">
<h1>[Task 5 - 1.0 points] Training and Evaluation</h1>
<p>You are now tasked to train and evaluate the Baseline and Model 1.</p>
<section id="instructions-4" class="level3">
<h3 class="anchored" data-anchor-id="instructions-4">Instructions</h3>
<ul>
<li>Train <strong>all</strong> models on the train set.</li>
<li>Evaluate <strong>all</strong> models on the validation set.</li>
<li>Compute metrics on the validation set.</li>
<li>Pick <strong>at least</strong> three seeds for robust estimation.</li>
<li>Pick the <strong>best</strong> performing model according to the observed validation set performance.</li>
<li>Evaluate your models using macro F1-score.</li>
</ul>
</section>
<section id="train-all-models-on-the-train-set." class="level3">
<h3 class="anchored" data-anchor-id="train-all-models-on-the-train-set.">Train <strong>all</strong> models on the train set.</h3>
<div id="cell-82" class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_loop(</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    model: keras.Model,</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">32</span>,</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    epochs: <span class="bu">int</span> <span class="op">=</span> <span class="dv">50</span>,</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>    patience: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>    sample_weights: Optional[List[<span class="bu">float</span>]] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[keras.Model, <span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>, List[<span class="bu">float</span>]]:</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Performs training and computes metrics on the validation set.</span></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model: model to train (keras.Model)</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a><span class="co">    :param batch_size: size of batches (int)</span></span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a><span class="co">    :param epochs: number of epochs (int)</span></span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a><span class="co">    :param patience: patience for early stopping (int)</span></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a><span class="co">    :param sample_weights: weights for the samples (list)</span></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a><span class="co">        - trained model (keras.Model)</span></span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a><span class="co">        - best macro f1 score on validation (float)</span></span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a><span class="co">        - best macro precision on validation (float)</span></span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a><span class="co">        - best macro recall on validation(float)</span></span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a><span class="co">        - loss history (list)</span></span>
<span id="cb67-23"><a href="#cb67-23" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb67-24"><a href="#cb67-24" aria-hidden="true" tabindex="-1"></a>    early_stopping <span class="op">=</span> EarlyStopping(</span>
<span id="cb67-25"><a href="#cb67-25" aria-hidden="true" tabindex="-1"></a>        monitor<span class="op">=</span><span class="st">"val_loss"</span>, patience<span class="op">=</span>patience, verbose<span class="op">=</span><span class="dv">0</span>, restore_best_weights<span class="op">=</span><span class="va">True</span></span>
<span id="cb67-26"><a href="#cb67-26" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb67-27"><a href="#cb67-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-28"><a href="#cb67-28" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> model.fit(</span>
<span id="cb67-29"><a href="#cb67-29" aria-hidden="true" tabindex="-1"></a>        train_sentences,</span>
<span id="cb67-30"><a href="#cb67-30" aria-hidden="true" tabindex="-1"></a>        categorical_train_labels,</span>
<span id="cb67-31"><a href="#cb67-31" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span>batch_size,</span>
<span id="cb67-32"><a href="#cb67-32" aria-hidden="true" tabindex="-1"></a>        epochs<span class="op">=</span>epochs,</span>
<span id="cb67-33"><a href="#cb67-33" aria-hidden="true" tabindex="-1"></a>        validation_data<span class="op">=</span>(validation_sentences, categorical_validation_labels),</span>
<span id="cb67-34"><a href="#cb67-34" aria-hidden="true" tabindex="-1"></a>        callbacks<span class="op">=</span>[early_stopping],</span>
<span id="cb67-35"><a href="#cb67-35" aria-hidden="true" tabindex="-1"></a>        sample_weight<span class="op">=</span>sample_weights,</span>
<span id="cb67-36"><a href="#cb67-36" aria-hidden="true" tabindex="-1"></a>        verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb67-37"><a href="#cb67-37" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb67-38"><a href="#cb67-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-39"><a href="#cb67-39" aria-hidden="true" tabindex="-1"></a>    best_epoch <span class="op">=</span> np.argmin(history.history[<span class="st">"val_loss"</span>])</span>
<span id="cb67-40"><a href="#cb67-40" aria-hidden="true" tabindex="-1"></a>    best_f1 <span class="op">=</span> history.history[<span class="st">"val_f1_score"</span>][best_epoch]</span>
<span id="cb67-41"><a href="#cb67-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-42"><a href="#cb67-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute macro averages (precision and recall)</span></span>
<span id="cb67-43"><a href="#cb67-43" aria-hidden="true" tabindex="-1"></a>    best_precision <span class="op">=</span> (</span>
<span id="cb67-44"><a href="#cb67-44" aria-hidden="true" tabindex="-1"></a>        history.history[<span class="st">"val_precision_zero"</span>][best_epoch]</span>
<span id="cb67-45"><a href="#cb67-45" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> history.history[<span class="st">"val_precision_one"</span>][best_epoch]</span>
<span id="cb67-46"><a href="#cb67-46" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb67-47"><a href="#cb67-47" aria-hidden="true" tabindex="-1"></a>    best_recall <span class="op">=</span> (</span>
<span id="cb67-48"><a href="#cb67-48" aria-hidden="true" tabindex="-1"></a>        history.history[<span class="st">"val_recall_zero"</span>][best_epoch]</span>
<span id="cb67-49"><a href="#cb67-49" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> history.history[<span class="st">"val_recall_one"</span>][best_epoch]</span>
<span id="cb67-50"><a href="#cb67-50" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb67-51"><a href="#cb67-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-52"><a href="#cb67-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model, best_f1, best_precision, best_recall, history.history[<span class="st">"loss"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The choice between Baseline and Model 1 is performed by averaging the validation F1-score over three seeds. Then we chose as <code>best_model</code> the one with the highest performance.</p>
<div id="cell-84" class="cell" data-outputid="a0110201-7b7f-41a8-a793-ffdac270fc08">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># train loop on 3 seeds</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>seeds <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>baseline_models <span class="op">=</span> {}</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>model1_models <span class="op">=</span> {}</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> seed <span class="kw">in</span> seeds:</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Seed: </span><span class="sc">{</span>seed<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>    set_reproducibility(seed)</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>    baseline_model <span class="op">=</span> get_model(add_lstm<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>    baseline_model, best_f1, best_precision, best_recall, loss_bsl <span class="op">=</span> train_loop(</span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>        baseline_model</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a>    baseline_models[best_f1] <span class="op">=</span> (baseline_model, seed, loss_bsl)</span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="ch">\t</span><span class="ss">Baseline f1_score: </span><span class="sc">{</span>best_f1<span class="sc">:.3f}</span><span class="ss">, precision </span><span class="sc">{</span>best_precision<span class="sc">:.3f}</span><span class="ss">, recall </span><span class="sc">{</span>best_recall<span class="sc">:.3f}</span><span class="ss">"</span></span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-19"><a href="#cb68-19" aria-hidden="true" tabindex="-1"></a>    model_1 <span class="op">=</span> get_model(add_lstm<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb68-20"><a href="#cb68-20" aria-hidden="true" tabindex="-1"></a>    model_1, best_f1, best_precision, best_recall, loss_m1 <span class="op">=</span> train_loop(model_1)</span>
<span id="cb68-21"><a href="#cb68-21" aria-hidden="true" tabindex="-1"></a>    model1_models[best_f1] <span class="op">=</span> (model_1, seed, loss_m1)</span>
<span id="cb68-22"><a href="#cb68-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb68-23"><a href="#cb68-23" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="ch">\n\t</span><span class="ss">Model_1 f1_score: </span><span class="sc">{</span>best_f1<span class="sc">:.3f}</span><span class="ss">, precision </span><span class="sc">{</span>best_precision<span class="sc">:.3f}</span><span class="ss">, recall </span><span class="sc">{</span>best_recall<span class="sc">:.3f}</span><span class="ss">"</span></span>
<span id="cb68-24"><a href="#cb68-24" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-25"><a href="#cb68-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">80</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Seed: 1
    Baseline f1_score: 0.804, precision 0.809, recall 0.801

    Model_1 f1_score: 0.800, precision 0.800, recall 0.799
================================================================================
Seed: 2
    Baseline f1_score: 0.842, precision 0.852, recall 0.838

    Model_1 f1_score: 0.829, precision 0.838, recall 0.825
================================================================================
Seed: 3
    Baseline f1_score: 0.793, precision 0.794, recall 0.792

    Model_1 f1_score: 0.785, precision 0.789, recall 0.783
================================================================================</code></pre>
</div>
</div>
<p>After the training we plotted the validation losses to explore the model’s variability over three seeds.</p>
<div id="cell-86" class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss(loss: List[<span class="bu">float</span>], name: <span class="bu">str</span>, ax: matplotlib.axes.Axes) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Plots loss curves over three seeds.</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param loss: losses to plot (list)</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="co">    :param name: name of the model to be displayed (str)</span></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :param ax: axis to plot on (matplotlib.axes.Axes)</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(loss)):</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>        ax.plot(loss[i], label<span class="op">=</span><span class="ss">f"seed </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"Model </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">"epoch"</span>)</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"loss"</span>)</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As we can see from the plots below the training is pretty stable, meaning that the choice of the seed seems to not affect so much model’s performance.</p>
<div id="cell-88" class="cell" data-outputid="829bd417-636b-4c0e-dbc9-47e875238286">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>model_1_losses <span class="op">=</span> [el[<span class="dv">2</span>] <span class="cf">for</span> el <span class="kw">in</span> model1_models.values()]</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>baseline_losses <span class="op">=</span> [el[<span class="dv">2</span>] <span class="cf">for</span> el <span class="kw">in</span> baseline_models.values()]</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>plot_loss(baseline_losses, <span class="st">"baseline"</span>, ax[<span class="dv">0</span>])</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>plot_loss(model_1_losses, <span class="st">"model_1"</span>, ax[<span class="dv">1</span>])</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-47-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-89" class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_results(model_dict: Dict[<span class="bu">float</span>, Tuple[keras.Model, <span class="bu">int</span>, List[<span class="bu">float</span>]]]) <span class="op">-&gt;</span> Tuple[<span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>]:</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Shows the results of a model as the average over the three seeds.</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_dict: dictionary of models' performances (dict)</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - best f1 score on the validation set (float)</span></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a><span class="co">        - average f1 score (float)</span></span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a><span class="co">        - f1 score on the test set (float)</span></span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>    average_f1 <span class="op">=</span> np.mean([f1 <span class="cf">for</span> f1 <span class="kw">in</span> model_dict.keys()])</span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>    best_f1 <span class="op">=</span> <span class="bu">max</span>(model_dict.keys())</span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>    average_f1 <span class="op">=</span> np.mean(<span class="bu">list</span>(model_dict.keys()))</span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a>    std_f1 <span class="op">=</span> np.std(<span class="bu">list</span>(model_dict.keys()))</span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>model_dict[best_f1][<span class="dv">0</span>]<span class="sc">.</span>name<span class="sc">}</span><span class="ss"> validation average f1_score: </span><span class="sc">{</span>average_f1<span class="sc">:.3f}</span><span class="ss">, std </span><span class="sc">{</span>std_f1<span class="sc">:.3f}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb72-20"><a href="#cb72-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-21"><a href="#cb72-21" aria-hidden="true" tabindex="-1"></a>    test_pred <span class="op">=</span> model_dict[best_f1][<span class="dv">0</span>].predict(test_sentences, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb72-22"><a href="#cb72-22" aria-hidden="true" tabindex="-1"></a>    f1_test <span class="op">=</span> f1_score(np.argmax(test_pred, axis<span class="op">=</span><span class="dv">1</span>), test_labels, average<span class="op">=</span><span class="st">"macro"</span>)</span>
<span id="cb72-23"><a href="#cb72-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-24"><a href="#cb72-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best </span><span class="sc">{</span>model_dict[best_f1][<span class="dv">0</span>]<span class="sc">.</span>name<span class="sc">}</span><span class="ss"> test f1_score: </span><span class="sc">{</span>f1_test<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb72-25"><a href="#cb72-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">80</span>, <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb72-26"><a href="#cb72-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-27"><a href="#cb72-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_f1, average_f1, f1_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="pick-the-best-performing-model-according-to-the-observed-validation-set-performance" class="level3">
<h3 class="anchored" data-anchor-id="pick-the-best-performing-model-according-to-the-observed-validation-set-performance">Pick the best performing model according to the observed validation set performance</h3>
<div id="cell-91" class="cell" data-outputid="3589bc58-46a2-417c-fd2c-c71393e08784">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>best_f1_baseline, average_f1_baseline, f1_test_baseline <span class="op">=</span> show_results(baseline_models)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>best_f1_model_1, average_f1_model_1, f1_test_model_1 <span class="op">=</span> show_results(model1_models)</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> average_f1_baseline <span class="op">&gt;</span> average_f1_model_1:</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>    best_model, best_seed, _ <span class="op">=</span> baseline_models[best_f1_baseline]</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>    best_f1_validation <span class="op">=</span> best_f1_baseline</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>    best_f1_test <span class="op">=</span> f1_test_baseline</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>    best_model, best_seed, _ <span class="op">=</span> model1_models[best_f1_model_1]</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>    best_f1_validation <span class="op">=</span> best_f1_model_1</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>    best_f1_test <span class="op">=</span> f1_test_model_1</span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best model: </span><span class="sc">{</span>best_model<span class="sc">.</span>name<span class="sc">}</span><span class="ss">, validation f1_score: </span><span class="sc">{</span>best_f1_validation<span class="sc">:.3f}</span><span class="ss">, test f1_score: </span><span class="sc">{</span>best_f1_test<span class="sc">:.3f}</span><span class="ss">, seed: </span><span class="sc">{</span>best_seed<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Baseline validation average f1_score: 0.813, std 0.021

Best Baseline test f1_score: 0.748
================================================================================ 

Model_1 validation average f1_score: 0.805, std 0.018

Best Model_1 test f1_score: 0.763
================================================================================ 

Best model: Baseline, validation f1_score: 0.842, test f1_score: 0.748, seed: 2</code></pre>
</div>
</div>
</section>
</section>
<section id="task-6---1.0-points-transformers" class="level1">
<h1>[Task 6 - 1.0 points] Transformers</h1>
<p>In this section, you will use a transformer model specifically trained for hate speech detection, namely <a href="https://huggingface.co/cardiffnlp/twitter-roberta-base-hate">Twitter-roBERTa-base for Hate Speech Detection</a>.</p>
<section id="relevant-material" class="level3">
<h3 class="anchored" data-anchor-id="relevant-material">Relevant Material</h3>
<ul>
<li>Tutorial 3</li>
</ul>
</section>
<section id="instructions-5" class="level3">
<h3 class="anchored" data-anchor-id="instructions-5">Instructions</h3>
<ol type="1">
<li><p><strong>Load the Tokenizer and Model</strong></p></li>
<li><p><strong>Preprocess the Dataset</strong>: You will need to preprocess your dataset to prepare it for input into the model. Tokenize your text data using the appropriate tokenizer and ensure it is formatted correctly.</p>
<p><strong>Note</strong>: You have to use the plain text of the dataset and not the version that you tokenized before, as you need to tokenize the cleaned text obtained after the initial cleaning process.</p></li>
<li><p><strong>Train the Model</strong>: Use the <code>Trainer</code> to train the model on your training data.</p></li>
<li><p><strong>Evaluate the Model on the Test Set</strong> using F1-macro.</p></li>
<li><p><strong>Load the Tokenizer and Model</strong></p></li>
</ol>
<div id="cell-96" class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"cardiffnlp/twitter-roberta-base-hate"</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_name)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-97" class="cell" data-outputid="a069bd6f-dec1-4320-a77f-1acc131842de">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> datasets.load_dataset(</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"csv"</span>,</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>    data_files<span class="op">=</span>{</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train"</span>: <span class="st">"train_cleaned.csv"</span>,</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"validation"</span>: <span class="st">"validation_cleaned.csv"</span>,</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"test"</span>: <span class="st">"test_cleaned.csv"</span>,</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"496ace0897b7495a970bb74543656c9b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"284f544f9aa14a42b9fc35b093f0c500","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c767cd22070d48308ef34ca8448779d9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<ol start="2" type="1">
<li><p><strong>Preprocess the Dataset</strong>: You will need to preprocess your dataset to prepare it for input into the model. Tokenize your text data using the appropriate tokenizer and ensure it is formatted correctly.</p>
<p><strong>Note</strong>: You have to use the plain text of the dataset and not the version that you tokenized before, as you need to tokenize the cleaned text obtained after the initial cleaning process.</p></li>
</ol>
<div id="cell-99" class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_text(texts: datasets.formatting.formatting.LazyBatch) <span class="op">-&gt;</span> transformers.tokenization_utils_base.BatchEncoding:</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Applies tokenization to the given dataset.</span></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param texts: dataset to tokenize (LazyBatch)</span></span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - tokenized dataset (BatchEncoding)</span></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(texts[<span class="st">"tweet"</span>], truncation<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-100" class="cell" data-outputid="5440d869-823c-498b-8ecd-a2bdbbca9df2">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tokenizing text..."</span>)</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">[Debug] Before:</span><span class="ch">\n</span><span class="sc">{</span>data[<span class="st">'train'</span>][<span class="st">'tweet'</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Lemmatize and tokenize each sentence</span></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.<span class="bu">map</span>(preprocess_text, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">[Debug] After:</span><span class="ch">\n</span><span class="sc">{</span>data[<span class="st">'train'</span>][<span class="dv">0</span>][<span class="st">'input_ids'</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokenizer.decode(data[<span class="st">"train"</span>][<span class="dv">0</span>][<span class="st">"input_ids"</span>]))</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Tokenization completed!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tokenizing text...

[Debug] Before:
writing a uni essay in my local pub with a coffee  random old man keeps asking me drunk questions when i m trying to concentrate  amp  ends with  good luck  but you ll just end up getting married and not use it anyway     is alive and well  
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dce9a66cc113483997ccb21052af2f53","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"31f02a08ea424a2cb81d4549ebf6dce8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cd394c99ffc34984b38d1e7fb32d4b80","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
[Debug] After:
[0, 13293, 10, 542, 118, 14700, 11, 127, 400, 8881, 19, 10, 3895, 1437, 9624, 793, 313, 4719, 1996, 162, 10789, 1142, 77, 939, 475, 667, 7, 14410, 1437, 28127, 1437, 3587, 19, 1437, 205, 6620, 1437, 53, 47, 19385, 95, 253, 62, 562, 2997, 8, 45, 304, 24, 6992, 1437, 1437, 1437, 1437, 16, 4299, 8, 157, 1437, 1437, 2]

&lt;s&gt;writing a uni essay in my local pub with a coffee  random old man keeps asking me drunk questions when i m trying to concentrate  amp  ends with  good luck  but you ll just end up getting married and not use it anyway     is alive and well  &lt;/s&gt;

Tokenization completed!</code></pre>
</div>
</div>
<div id="cell-101" class="cell" data-outputid="ed14f302-c840-4020-ddad-499a124d4dfb">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.rename_column(<span class="st">"hard_label_task1"</span>, <span class="st">"label"</span>)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data[<span class="st">"train"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset({
    features: ['Unnamed: 0', 'id_EXIST', 'lang', 'tweet', 'label', 'input_ids', 'attention_mask'],
    num_rows: 2870
})</code></pre>
</div>
</div>
<div id="cell-102" class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(output_info: List[np.ndarray]) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, <span class="bu">float</span>]:</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Computes accuracy and macro f1 score.</span></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param output_info: predictions and labels to compute metrics (list)</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - dictionary of metrics (dict)</span></span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>    predictions, labels <span class="op">=</span> output_info</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> np.argmax(predictions, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_pred<span class="op">=</span>predictions, y_true<span class="op">=</span>labels, average<span class="op">=</span><span class="st">'macro'</span>)</span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> accuracy_score(y_pred<span class="op">=</span>predictions, y_true<span class="op">=</span>labels)</span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'f1'</span>: f1, <span class="st">'acc'</span>: acc}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-103" class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"test_dir"</span>,</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>    metric_for_best_model<span class="op">=</span><span class="st">"loss"</span>,</span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>    greater_is_better<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span>best_seed,</span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a>    logging_strategy<span class="op">=</span><span class="st">'epoch'</span></span>
<span id="cb85-16"><a href="#cb85-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-104" class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>data[<span class="st">"train"</span>],</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>data[<span class="st">"validation"</span>],</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>    processing_class<span class="op">=</span>tokenizer,</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[EarlyStoppingCallback(early_stopping_patience<span class="op">=</span><span class="dv">3</span>)]</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Performances before fine-tuning.</p>
<div id="cell-106" class="cell" data-outputid="98b89415-0cdd-4111-9f2b-965de0fb4910">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>test_info <span class="op">=</span> trainer.predict(data[<span class="st">"test"</span>])</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>y_pred_transformer, y_true <span class="op">=</span> test_info.predictions, test_info.label_ids</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>test_metrics <span class="op">=</span> compute_metrics([y_pred_transformer, y_true])</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'Transformer test f1_score </span><span class="sc">{</span>test_metrics[<span class="st">"f1"</span>]<span class="sc">:.4f}</span><span class="ss">, accuracy </span><span class="sc">{</span>test_metrics[<span class="st">"acc"</span>]<span class="sc">:.4f}</span><span class="ss">'</span></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>Transformer test f1_score 0.6234, accuracy 0.6853</code></pre>
</div>
</div>
<ol start="3" type="1">
<li><strong>Train the Model</strong>: Use the <code>Trainer</code> to train the model on your training data.</li>
</ol>
<div id="cell-108" class="cell" data-outputid="fa7759de-5252-4b72-a1ca-d1ff96d13ee2">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="1436" max="3590" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [1436/3590 04:28 &lt; 06:43, 5.34 it/s, Epoch 4/10]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">Model Preparation Time</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Acc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.447400</td>
<td>0.439996</td>
<td>0.003300</td>
<td>0.843920</td>
<td>0.854430</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.316700</td>
<td>0.482837</td>
<td>0.003300</td>
<td>0.851224</td>
<td>0.860759</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.199000</td>
<td>0.715282</td>
<td>0.003300</td>
<td>0.850172</td>
<td>0.860759</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.116600</td>
<td>0.837943</td>
<td>0.003300</td>
<td>0.843920</td>
<td>0.854430</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>TrainOutput(global_step=1436, training_loss=0.26992921908917866, metrics={'train_runtime': 268.9611, 'train_samples_per_second': 106.707, 'train_steps_per_second': 13.348, 'total_flos': 403615442254920.0, 'train_loss': 0.26992921908917866, 'epoch': 4.0})</code></pre>
</div>
</div>
<ol start="4" type="1">
<li><strong>Evaluate the Model on the Test Set</strong> using F1-macro.</li>
</ol>
<div id="cell-110" class="cell" data-outputid="d56adc4b-b40b-4f83-c7cf-4c0f844d9514">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>test_info <span class="op">=</span> trainer.predict(data[<span class="st">"test"</span>])</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>y_pred_transformer, y_true <span class="op">=</span> test_info.predictions, test_info.label_ids</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>test_metrics <span class="op">=</span> compute_metrics([y_pred_transformer, y_true])</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'Transformer test f1_score </span><span class="sc">{</span>test_metrics[<span class="st">"f1"</span>]<span class="sc">:.4f}</span><span class="ss">, accuracy </span><span class="sc">{</span>test_metrics[<span class="st">"acc"</span>]<span class="sc">:.4f}</span><span class="ss">'</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>Transformer test f1_score 0.8451, accuracy 0.8497</code></pre>
</div>
</div>
<p>We decided to freeze all the layers except for the last three layers of the encoder and the final classifier because we noticed that the model tends to overfit from the very early epochs.</p>
<div id="cell-112" class="cell">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"cardiffnlp/twitter-roberta-base-hate"</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_name)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-113" class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="st">'classifier'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'encoder.layer.10'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'encoder.layer.11'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'encoder.layer.9'</span> <span class="kw">in</span> name:</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>    param.requires_grad <span class="op">=</span> <span class="va">True</span></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>    param.requires_grad <span class="op">=</span> <span class="va">False</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-114" class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>data[<span class="st">"train"</span>],</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>data[<span class="st">"validation"</span>],</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>    processing_class<span class="op">=</span>tokenizer,</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[EarlyStoppingCallback(early_stopping_patience<span class="op">=</span><span class="dv">3</span>)]</span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-115" class="cell" data-outputid="f010b3e0-1aae-47e4-d988-d0da0346c552">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="2513" max="3590" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [2513/3590 03:19 &lt; 01:25, 12.60 it/s, Epoch 7/10]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Acc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.433100</td>
<td>0.423892</td>
<td>0.810649</td>
<td>0.822785</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.376400</td>
<td>0.397606</td>
<td>0.830348</td>
<td>0.841772</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.341400</td>
<td>0.408738</td>
<td>0.818027</td>
<td>0.829114</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.309400</td>
<td>0.374536</td>
<td>0.869313</td>
<td>0.873418</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.261800</td>
<td>0.441950</td>
<td>0.883385</td>
<td>0.886076</td>
</tr>
<tr class="even">
<td>6</td>
<td>0.238800</td>
<td>0.555244</td>
<td>0.876130</td>
<td>0.879747</td>
</tr>
<tr class="odd">
<td>7</td>
<td>0.207300</td>
<td>0.587575</td>
<td>0.882905</td>
<td>0.886076</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>TrainOutput(global_step=2513, training_loss=0.30974551230087916, metrics={'train_runtime': 199.3457, 'train_samples_per_second': 143.971, 'train_steps_per_second': 18.009, 'total_flos': 706339100332440.0, 'train_loss': 0.30974551230087916, 'epoch': 7.0})</code></pre>
</div>
</div>
<p>After freezing the lower layers the overfitting is reduced, enabling the model to train for more epochs. Eventually the model has improved a bit on the test set.</p>
<div id="cell-117" class="cell" data-outputid="692b8e40-5f36-439c-afdd-ace0eae71454">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>test_info <span class="op">=</span> trainer.predict(data[<span class="st">"test"</span>])</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>y_pred_transformer, y_true <span class="op">=</span> test_info.predictions, test_info.label_ids</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>test_metrics <span class="op">=</span> compute_metrics([y_pred_transformer, y_true])</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'Transformer test f1_score </span><span class="sc">{</span>test_metrics[<span class="st">"f1"</span>]<span class="sc">:.4f}</span><span class="ss">, accuracy </span><span class="sc">{</span>test_metrics[<span class="st">"acc"</span>]<span class="sc">:.4f}</span><span class="ss">'</span></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>Transformer test f1_score 0.8588, accuracy 0.8601</code></pre>
</div>
</div>
</section>
</section>
<section id="task-7---0.5-points-error-analysis" class="level1">
<h1>[Task 7 - 0.5 points] Error Analysis</h1>
<section id="instructions-6" class="level3">
<h3 class="anchored" data-anchor-id="instructions-6">Instructions</h3>
<p>After evaluating the model, perform a brief error analysis:</p>
<ul>
<li><p>Review the results and identify common errors.</p></li>
<li><p>Summarize your findings regarding the errors and their impact on performance (e.g.&nbsp;but not limited to Out-of-Vocabulary (OOV) words, data imbalance, and performance differences between the custom model and the transformer…)</p></li>
<li><p>Suggest possible solutions to address the identified errors.</p></li>
</ul>
<p><strong>Impact of Seed Initialization on Error Analysis</strong></p>
<p>As a general premise, we noticed that the error analysis is highly dependent on the choice of the initial global seed due to its role in fixing the random vectors associated with UNK tokens. Given the large number of UNK tokens, this heavily influences model performance, causing significant variations in metrics like macro F1 (from about 0.7 to 0.78) and error patterns. With different seeds, entirely different patterns of errors emerge, highlighting the instability caused by small validation and test sets.</p>
<p>To address this a larger dataset could mitigate these issues and provide more reliable insights.</p>
</section>
<section id="performances" class="level2">
<h2 class="anchored" data-anchor-id="performances">Performances</h2>
<div id="cell-121" class="cell" data-outputid="78f93960-071b-4358-dd4a-54aa1f24ee23">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get predictions as probability distributions</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>model_test_preds_soft <span class="op">=</span> best_model.predict(test_sentences)</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>transformer_preds_soft <span class="op">=</span> softmax(torch.tensor(y_pred_transformer), axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a><span class="co"># get predictions as integer labels (0 -&gt; not sexist, 1 -&gt; sexist)</span></span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>model_test_preds_hard <span class="op">=</span> np.argmax(model_test_preds_soft, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>transformer_preds_hard <span class="op">=</span> np.argmax(transformer_preds_soft, axis<span class="op">=-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>9/9 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step</code></pre>
</div>
</div>
<p>Utility function to make plots</p>
<div id="cell-123" class="cell">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cm(y_pred: np.ndarray, y_true: np.ndarray, model_name: <span class="bu">str</span>, axis: np.ndarray) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Plots both confusion matrix and classification report of the given model.</span></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param y_pred: model predictions (np.ndarray)</span></span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a><span class="co">    :param y_true: true labels (np.ndarray)</span></span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_name: name of the model to display (str)</span></span>
<span id="cb102-8"><a href="#cb102-8" aria-hidden="true" tabindex="-1"></a><span class="co">    :param axis: axis to plot on (np.ndarray)</span></span>
<span id="cb102-9"><a href="#cb102-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb102-10"><a href="#cb102-10" aria-hidden="true" tabindex="-1"></a>    cr <span class="op">=</span> classification_report(y_true, y_pred, output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb102-11"><a href="#cb102-11" aria-hidden="true" tabindex="-1"></a>    cr <span class="op">=</span> pd.DataFrame(cr).T</span>
<span id="cb102-12"><a href="#cb102-12" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(cr.iloc[:, :].astype(<span class="bu">float</span>), annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">".2f"</span>,</span>
<span id="cb102-13"><a href="#cb102-13" aria-hidden="true" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">"Blues"</span>, cbar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb102-14"><a href="#cb102-14" aria-hidden="true" tabindex="-1"></a>                xticklabels<span class="op">=</span>cr.columns, yticklabels<span class="op">=</span>cr.index,</span>
<span id="cb102-15"><a href="#cb102-15" aria-hidden="true" tabindex="-1"></a>                linewidths<span class="op">=</span><span class="fl">0.5</span>, linecolor<span class="op">=</span><span class="st">"gray"</span>, ax<span class="op">=</span>axis[<span class="dv">0</span>])</span>
<span id="cb102-16"><a href="#cb102-16" aria-hidden="true" tabindex="-1"></a>    axis[<span class="dv">0</span>].set_facecolor(<span class="st">"white"</span>)</span>
<span id="cb102-17"><a href="#cb102-17" aria-hidden="true" tabindex="-1"></a>    axis[<span class="dv">0</span>].set_title(<span class="ss">f'Classification Report: </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, weight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb102-18"><a href="#cb102-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-19"><a href="#cb102-19" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(y_true, y_pred)</span>
<span id="cb102-20"><a href="#cb102-20" aria-hidden="true" tabindex="-1"></a>    disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm)</span>
<span id="cb102-21"><a href="#cb102-21" aria-hidden="true" tabindex="-1"></a>    disp.plot(cmap<span class="op">=</span><span class="st">"Blues"</span>, colorbar<span class="op">=</span><span class="va">False</span>, ax<span class="op">=</span>axis[<span class="dv">1</span>])</span>
<span id="cb102-22"><a href="#cb102-22" aria-hidden="true" tabindex="-1"></a>    axis[<span class="dv">1</span>].set_facecolor(<span class="st">"white"</span>)</span>
<span id="cb102-23"><a href="#cb102-23" aria-hidden="true" tabindex="-1"></a>    axis[<span class="dv">1</span>].set_title(<span class="ss">f'Confusion Matrix: </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, weight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb102-24"><a href="#cb102-24" aria-hidden="true" tabindex="-1"></a>    axis[<span class="dv">1</span>].set_xlabel(<span class="st">"Predicted Labels"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb102-25"><a href="#cb102-25" aria-hidden="true" tabindex="-1"></a>    axis[<span class="dv">1</span>].set_ylabel(<span class="st">"True Labels"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb102-26"><a href="#cb102-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-27"><a href="#cb102-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ax <span class="kw">in</span> axis:</span>
<span id="cb102-28"><a href="#cb102-28" aria-hidden="true" tabindex="-1"></a>        ax.tick_params(axis<span class="op">=</span><span class="st">'x'</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb102-29"><a href="#cb102-29" aria-hidden="true" tabindex="-1"></a>        ax.tick_params(axis<span class="op">=</span><span class="st">'y'</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb102-30"><a href="#cb102-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-31"><a href="#cb102-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-32"><a href="#cb102-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_precision_recall(y_preds: np.ndarray, y_true: np.ndarray, model_name: <span class="bu">str</span>, ax: matplotlib.axes.Axes) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb102-33"><a href="#cb102-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb102-34"><a href="#cb102-34" aria-hidden="true" tabindex="-1"></a><span class="co">    Plots precison-recall curve of the given model.</span></span>
<span id="cb102-35"><a href="#cb102-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-36"><a href="#cb102-36" aria-hidden="true" tabindex="-1"></a><span class="co">    :param y_preds: model predictions (np.ndarray)</span></span>
<span id="cb102-37"><a href="#cb102-37" aria-hidden="true" tabindex="-1"></a><span class="co">    :param y_true: true labels (np.ndarray)</span></span>
<span id="cb102-38"><a href="#cb102-38" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_name: name of the model to display (str)</span></span>
<span id="cb102-39"><a href="#cb102-39" aria-hidden="true" tabindex="-1"></a><span class="co">    :param ax: axis to plot on (matplotlib.axes.Axes)</span></span>
<span id="cb102-40"><a href="#cb102-40" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb102-41"><a href="#cb102-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Precision recall curve</span></span>
<span id="cb102-42"><a href="#cb102-42" aria-hidden="true" tabindex="-1"></a>    y_preds <span class="op">=</span> y_preds[:,<span class="dv">1</span>]</span>
<span id="cb102-43"><a href="#cb102-43" aria-hidden="true" tabindex="-1"></a>    precision, recall, _ <span class="op">=</span> precision_recall_curve(y_true, y_preds)</span>
<span id="cb102-44"><a href="#cb102-44" aria-hidden="true" tabindex="-1"></a>    prevalence_pos_label <span class="op">=</span> np.<span class="bu">sum</span>(y_true) <span class="op">/</span> <span class="bu">len</span>(y_true)</span>
<span id="cb102-45"><a href="#cb102-45" aria-hidden="true" tabindex="-1"></a>    disp <span class="op">=</span> PrecisionRecallDisplay(precision<span class="op">=</span>precision,recall<span class="op">=</span>recall,prevalence_pos_label<span class="op">=</span>prevalence_pos_label)</span>
<span id="cb102-46"><a href="#cb102-46" aria-hidden="true" tabindex="-1"></a>    auc_score <span class="op">=</span> auc(recall,precision)</span>
<span id="cb102-47"><a href="#cb102-47" aria-hidden="true" tabindex="-1"></a>    disp.plot(ax,name<span class="op">=</span><span class="ss">f'Model (AUC = </span><span class="sc">{</span>auc_score<span class="sc">:.2f}</span><span class="ss">'</span>,plot_chance_level<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb102-48"><a href="#cb102-48" aria-hidden="true" tabindex="-1"></a>    ax.fill_between(recall, precision, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb102-49"><a href="#cb102-49" aria-hidden="true" tabindex="-1"></a>    ax.text(</span>
<span id="cb102-50"><a href="#cb102-50" aria-hidden="true" tabindex="-1"></a>      <span class="fl">0.6</span>,</span>
<span id="cb102-51"><a href="#cb102-51" aria-hidden="true" tabindex="-1"></a>      <span class="fl">0.2</span>,</span>
<span id="cb102-52"><a href="#cb102-52" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"AUC = </span><span class="sc">{</span>auc_score<span class="sc">:.2f}</span><span class="ss">"</span>,</span>
<span id="cb102-53"><a href="#cb102-53" aria-hidden="true" tabindex="-1"></a>      fontsize<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb102-54"><a href="#cb102-54" aria-hidden="true" tabindex="-1"></a>      color<span class="op">=</span><span class="st">"blue"</span>,</span>
<span id="cb102-55"><a href="#cb102-55" aria-hidden="true" tabindex="-1"></a>      bbox<span class="op">=</span><span class="bu">dict</span>(facecolor<span class="op">=</span><span class="st">"white"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>),</span>
<span id="cb102-56"><a href="#cb102-56" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb102-57"><a href="#cb102-57" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">"False Positive Rate (FPR)"</span>,fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb102-58"><a href="#cb102-58" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"True Positive Rate (TPR)"</span>,fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb102-59"><a href="#cb102-59" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> Curve"</span>,fontsize<span class="op">=</span><span class="dv">14</span>, weight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb102-60"><a href="#cb102-60" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As we can see from the classification reports below there’s a performance gap between the Custom Model and the Transformer. The majority of the errors made by the Custom Model occur on label 1, while the Transformer seems to be more balanced as pointed out by the confusion matrices.</p>
<div id="cell-125" class="cell" data-outputid="b52e4ac0-ae08-4313-8a87-9b4949134434">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plots</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">9</span>,<span class="dv">9</span>))</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>plot_cm(model_test_preds_hard, test_labels, <span class="st">"Best_model"</span>,(ax[<span class="dv">0</span>][<span class="dv">0</span>],ax[<span class="dv">1</span>][<span class="dv">0</span>]))</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>plot_cm(transformer_preds_hard, test_labels, <span class="st">"Trasformer"</span>,(ax[<span class="dv">0</span>][<span class="dv">1</span>],ax[<span class="dv">1</span>][<span class="dv">1</span>]))</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-68-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As we can see from the Precision-Recall curves on label 1 the Transformer achieves a higher AUC score (0.88) compared to the Custom Model (0.80), indicating better overall precision and recall balance across thresholds.</p>
<div id="cell-127" class="cell" data-outputid="4720bf6c-a2d0-4632-d70a-71f9efde2f61">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>))</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">'Precision Recall curves'</span>,fontsize<span class="op">=</span><span class="dv">14</span>, weight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>plot_precision_recall(model_test_preds_soft, test_labels, <span class="st">"Best_model"</span>, ax[<span class="dv">0</span>])</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>plot_precision_recall(transformer_preds_soft, test_labels, <span class="st">"Trasformer"</span>, ax[<span class="dv">1</span>])</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-69-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Utility function used for decoding sentences to display.</p>
<div id="cell-129" class="cell">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> custom_decode(sentences: np.ndarray) <span class="op">-&gt;</span> List[List[<span class="bu">str</span>]]:</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Converts back token ids of the custom model to words.</span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param sentences: sentences to decode (np.ndarray)</span></span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :return</span></span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - decoded sentences (list)</span></span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a>    decoded_sentences <span class="op">=</span> []</span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sentence <span class="kw">in</span> sentences:</span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>        decoded_sentence <span class="op">=</span> []</span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> sentence:</span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> word <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a>                decoded_sentence.append(idx_to_word[word])</span>
<span id="cb105-16"><a href="#cb105-16" aria-hidden="true" tabindex="-1"></a>        decoded_sentences.append(decoded_sentence)</span>
<span id="cb105-17"><a href="#cb105-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> decoded_sentences</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-130" class="cell">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>decoded_test <span class="op">=</span> custom_decode(test_sentences)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="dataset-imbalance" class="level2">
<h2 class="anchored" data-anchor-id="dataset-imbalance">Dataset Imbalance</h2>
<p>Let’s show how the labels are distributed across the dataset.</p>
<div id="cell-133" class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_data_distribution(df: pd.DataFrame, ax: matplotlib.axes.Axes, title: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Shows the distribution of a dataset split.</span></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="co">    :param df: split of the dataset (pd.DataFrame)</span></span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a><span class="co">    :param ax: axis to plot on (matplotlib.axes.Axes)</span></span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :param title: title of the plot (str)</span></span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>    label_1 <span class="op">=</span> <span class="bu">len</span>(df[df[<span class="st">"hard_label_task1"</span>] <span class="op">==</span> <span class="dv">1</span>])</span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a>    label_0 <span class="op">=</span> <span class="bu">len</span>(df[df[<span class="st">"hard_label_task1"</span>] <span class="op">==</span> <span class="dv">0</span>])</span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>    bar_colors <span class="op">=</span> [<span class="st">"#6baed6"</span>, <span class="st">"#2171b5"</span>]</span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a>    bars <span class="op">=</span> ax.bar([<span class="st">"label_1"</span>, <span class="st">"label_0"</span>], [label_1, label_0], color<span class="op">=</span>bar_colors)</span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a>    percentages <span class="op">=</span> [(label_1 <span class="op">/</span> <span class="bu">len</span>(df))<span class="op">*</span><span class="dv">100</span>, (label_0 <span class="op">/</span> <span class="bu">len</span>(df))<span class="op">*</span><span class="dv">100</span>]</span>
<span id="cb107-14"><a href="#cb107-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bar, percentage <span class="kw">in</span> <span class="bu">zip</span>(bars, percentages):</span>
<span id="cb107-15"><a href="#cb107-15" aria-hidden="true" tabindex="-1"></a>        ax.text(</span>
<span id="cb107-16"><a href="#cb107-16" aria-hidden="true" tabindex="-1"></a>            bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>,</span>
<span id="cb107-17"><a href="#cb107-17" aria-hidden="true" tabindex="-1"></a>            bar.get_height(),</span>
<span id="cb107-18"><a href="#cb107-18" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"</span><span class="sc">{</span>percentage<span class="sc">:.2f}</span><span class="ss">%"</span>,</span>
<span id="cb107-19"><a href="#cb107-19" aria-hidden="true" tabindex="-1"></a>            ha<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb107-20"><a href="#cb107-20" aria-hidden="true" tabindex="-1"></a>            va<span class="op">=</span><span class="st">"bottom"</span>,</span>
<span id="cb107-21"><a href="#cb107-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb107-22"><a href="#cb107-22" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span>
<span id="cb107-23"><a href="#cb107-23" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"label count"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>All the three splits seem to have similar label distribution, even though the train set is slightly more imbalanced. Perhaps this imbalance could be the reason why the Custom Model tends to have a bias towards non sexism as previously shown by the confusion matrix.</p>
<div id="cell-135" class="cell" data-outputid="029c985b-5094-440e-f904-599f4f3085fa">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>plot_data_distribution(train_df, ax[<span class="dv">0</span>], <span class="st">"train"</span>)</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>plot_data_distribution(validation_df, ax[<span class="dv">1</span>], <span class="st">"validation"</span>)</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>plot_data_distribution(test_df, ax[<span class="dv">2</span>], <span class="st">"test"</span>)</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-73-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="sentence-level-analysis" class="level2">
<h2 class="anchored" data-anchor-id="sentence-level-analysis">Sentence-level analysis</h2>
<p>Let’s now see which are the common errors at sentence level.</p>
<div id="cell-138" class="cell">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_common_errors(model_preds: np.ndarray, transformer_preds: np.ndarray, true_labels: np.ndarray, sentences: List[List[<span class="bu">str</span>]]) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Shows the common errors between the custom model and the transformer.</span></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a><span class="co">  :param model_preds: predictions of the custom model (np.ndarray)</span></span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a><span class="co">  :param transformer_preds: predictions of the transformer (np.ndarray)</span></span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a><span class="co">  :param true_labels: true labels (np.ndarray)</span></span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a><span class="co">  :param sentences: input sentences (list)</span></span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>  common_errors <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"sentence"</span>, <span class="st">"true_label"</span>, <span class="st">"model_prediction"</span>,<span class="st">'transformer_pred'</span>])</span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>  transformer_errors <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"sentence"</span>, <span class="st">"true_label"</span>, <span class="st">"model_prediction"</span>,<span class="st">'transformer_pred'</span>,<span class="st">'diff_pred'</span>])</span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a>  model_errors <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"sentence"</span>, <span class="st">"true_label"</span>, <span class="st">"model_prediction"</span>,<span class="st">'transformer_pred'</span>,<span class="st">'diff_pred'</span>])</span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true" tabindex="-1"></a>  sentences <span class="op">=</span> sentences.<span class="bu">apply</span>(<span class="kw">lambda</span> x: copy.deepcopy(x))</span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-16"><a href="#cb109-16" aria-hidden="true" tabindex="-1"></a>  model_hards <span class="op">=</span> np.argmax(model_preds, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb109-17"><a href="#cb109-17" aria-hidden="true" tabindex="-1"></a>  transformer_hards <span class="op">=</span> np.argmax(transformer_preds, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb109-18"><a href="#cb109-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-19"><a href="#cb109-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(true_labels)):</span>
<span id="cb109-20"><a href="#cb109-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> true_labels[i][<span class="dv">0</span>] <span class="op">!=</span> transformer_hards[i]:</span>
<span id="cb109-21"><a href="#cb109-21" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> model_hards[i] <span class="op">==</span> transformer_hards[i]:</span>
<span id="cb109-22"><a href="#cb109-22" aria-hidden="true" tabindex="-1"></a>        common_errors.loc[<span class="bu">len</span>(common_errors)] <span class="op">=</span> [</span>
<span id="cb109-23"><a href="#cb109-23" aria-hidden="true" tabindex="-1"></a>                  <span class="st">" "</span>.join(sentences[i]),</span>
<span id="cb109-24"><a href="#cb109-24" aria-hidden="true" tabindex="-1"></a>                  true_labels[i][<span class="dv">0</span>],</span>
<span id="cb109-25"><a href="#cb109-25" aria-hidden="true" tabindex="-1"></a>                  model_preds[i][true_labels[i][<span class="dv">0</span>]],</span>
<span id="cb109-26"><a href="#cb109-26" aria-hidden="true" tabindex="-1"></a>                  transformer_preds[i][true_labels[i][<span class="dv">0</span>]],</span>
<span id="cb109-27"><a href="#cb109-27" aria-hidden="true" tabindex="-1"></a>              ]</span>
<span id="cb109-28"><a href="#cb109-28" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>:</span>
<span id="cb109-29"><a href="#cb109-29" aria-hidden="true" tabindex="-1"></a>        transformer_errors.loc[<span class="bu">len</span>(transformer_errors)] <span class="op">=</span> [</span>
<span id="cb109-30"><a href="#cb109-30" aria-hidden="true" tabindex="-1"></a>                  <span class="st">" "</span>.join(sentences[i]),</span>
<span id="cb109-31"><a href="#cb109-31" aria-hidden="true" tabindex="-1"></a>                  true_labels[i][<span class="dv">0</span>],</span>
<span id="cb109-32"><a href="#cb109-32" aria-hidden="true" tabindex="-1"></a>                  model_preds[i][true_labels[i][<span class="dv">0</span>]],</span>
<span id="cb109-33"><a href="#cb109-33" aria-hidden="true" tabindex="-1"></a>                  transformer_preds[i][true_labels[i][<span class="dv">0</span>]],</span>
<span id="cb109-34"><a href="#cb109-34" aria-hidden="true" tabindex="-1"></a>                  <span class="bu">abs</span>(model_preds[i][true_labels[i][<span class="dv">0</span>]] <span class="op">-</span> transformer_preds[i][true_labels[i][<span class="dv">0</span>]]),</span>
<span id="cb109-35"><a href="#cb109-35" aria-hidden="true" tabindex="-1"></a>              ]</span>
<span id="cb109-36"><a href="#cb109-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> model_hards[i] <span class="op">!=</span> transformer_hards[i]:</span>
<span id="cb109-37"><a href="#cb109-37" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(sentences[i])):</span>
<span id="cb109-38"><a href="#cb109-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sentences[i][j] <span class="kw">in</span> oov_terms <span class="kw">or</span> sentences[i][j] <span class="kw">not</span> <span class="kw">in</span> word_listing:</span>
<span id="cb109-39"><a href="#cb109-39" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> sentences[i][j] <span class="kw">in</span> oov_terms:</span>
<span id="cb109-40"><a href="#cb109-40" aria-hidden="true" tabindex="-1"></a>            sentences[i][j] <span class="op">=</span> <span class="ss">f"&lt;span style='color:red'&gt;</span><span class="sc">{</span>sentences[i][j]<span class="sc">}</span><span class="ss">&lt;/span&gt;"</span></span>
<span id="cb109-41"><a href="#cb109-41" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span>:</span>
<span id="cb109-42"><a href="#cb109-42" aria-hidden="true" tabindex="-1"></a>            sentences[i][j] <span class="op">=</span> <span class="ss">f"&lt;span style='color:blue'&gt;</span><span class="sc">{</span>sentences[i][j]<span class="sc">}</span><span class="ss">&lt;/span&gt;"</span></span>
<span id="cb109-43"><a href="#cb109-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-44"><a href="#cb109-44" aria-hidden="true" tabindex="-1"></a>      model_errors.loc[<span class="bu">len</span>(model_errors)] <span class="op">=</span> [</span>
<span id="cb109-45"><a href="#cb109-45" aria-hidden="true" tabindex="-1"></a>                <span class="st">" "</span>.join(sentences[i]),</span>
<span id="cb109-46"><a href="#cb109-46" aria-hidden="true" tabindex="-1"></a>                true_labels[i][<span class="dv">0</span>],</span>
<span id="cb109-47"><a href="#cb109-47" aria-hidden="true" tabindex="-1"></a>                model_preds[i][true_labels[i][<span class="dv">0</span>]],</span>
<span id="cb109-48"><a href="#cb109-48" aria-hidden="true" tabindex="-1"></a>                transformer_preds[i][true_labels[i][<span class="dv">0</span>]],</span>
<span id="cb109-49"><a href="#cb109-49" aria-hidden="true" tabindex="-1"></a>                <span class="bu">abs</span>(model_preds[i][true_labels[i][<span class="dv">0</span>]] <span class="op">-</span> transformer_preds[i][true_labels[i][<span class="dv">0</span>]]),</span>
<span id="cb109-50"><a href="#cb109-50" aria-hidden="true" tabindex="-1"></a>          ]</span>
<span id="cb109-51"><a href="#cb109-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-52"><a href="#cb109-52" aria-hidden="true" tabindex="-1"></a>  common_errors <span class="op">=</span> common_errors.sort_values(by<span class="op">=</span><span class="st">'true_label'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb109-53"><a href="#cb109-53" aria-hidden="true" tabindex="-1"></a>  transformer_errors <span class="op">=</span> transformer_errors.sort_values(by<span class="op">=</span><span class="st">'diff_pred'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb109-54"><a href="#cb109-54" aria-hidden="true" tabindex="-1"></a>  model_errors <span class="op">=</span> model_errors.sort_values(by<span class="op">=</span><span class="st">'diff_pred'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb109-55"><a href="#cb109-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-56"><a href="#cb109-56" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> common_errors, transformer_errors, model_errors</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Below we display the sentences that both the Custom Model and the Tranformer got wrong along with the corresponding prediction values. The prediction value represents the probability that the model assigns to the true label, i.e smaller values imply larger errors made by the model.</p>
<div id="cell-140" class="cell" data-outputid="0fd16df2-4900-495c-8682-b69be762f3b9">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>common_errors, transformer_errors, model_errors <span class="op">=</span> display_common_errors(model_test_preds_soft, transformer_preds_soft, test_labels, test_tokenized)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of common errors between the Custom Model and the Transformer:&nbsp;</span><span class="sc">{</span><span class="bu">len</span>(common_errors)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>common_errors <span class="op">=</span> common_errors.style.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>:<span class="st">'left'</span>})</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>display(common_errors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of common errors between the Custom Model and the Transformer:&nbsp;30</code></pre>
</div>
<div class="cell-output cell-output-display">


<table id="T_22956" class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_22956_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">sentence</th>
<th id="T_22956_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">true_label</th>
<th id="T_22956_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">model_prediction</th>
<th id="T_22956_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">transformer_pred</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_22956_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">1</td>
<td id="T_22956_row0_col0" class="data row0 col0">that gold digger be nice but the picture and set up for them be elite pinwork be like the revealing of the mona lisa always a work of art</td>
<td id="T_22956_row0_col1" class="data row0 col1">1</td>
<td id="T_22956_row0_col2" class="data row0 col2">0.045073</td>
<td id="T_22956_row0_col3" class="data row0 col3">0.109728</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">2</td>
<td id="T_22956_row1_col0" class="data row1 col0">dear fan can we not harass talented actor of color stop be racist douche nozzle this be why we can t have nice thing moses be a badass inquisitor and y all can t handle her badassary</td>
<td id="T_22956_row1_col1" class="data row1 col1">1</td>
<td id="T_22956_row1_col2" class="data row1 col2">0.284516</td>
<td id="T_22956_row1_col3" class="data row1 col3">0.038928</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">4</td>
<td id="T_22956_row2_col0" class="data row2 col0">call to clean up parliament s laddish culture after mp s porn shame via</td>
<td id="T_22956_row2_col1" class="data row2 col1">1</td>
<td id="T_22956_row2_col2" class="data row2 col2">0.271655</td>
<td id="T_22956_row2_col3" class="data row2 col3">0.365000</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">9</td>
<td id="T_22956_row3_col0" class="data row3 col0">i don t need a man to tell me what to stand up for thank you</td>
<td id="T_22956_row3_col1" class="data row3 col1">1</td>
<td id="T_22956_row3_col2" class="data row3 col2">0.314866</td>
<td id="T_22956_row3_col3" class="data row3 col3">0.255073</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">8</td>
<td id="T_22956_row4_col0" class="data row4 col0">go weak rn play the guitar manspreading i be on my knee</td>
<td id="T_22956_row4_col1" class="data row4 col1">1</td>
<td id="T_22956_row4_col2" class="data row4 col2">0.044828</td>
<td id="T_22956_row4_col3" class="data row4 col3">0.229011</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">7</td>
<td id="T_22956_row5_col0" class="data row5 col0">mansplaining the concept of a pee drawer to my partner who want me</td>
<td id="T_22956_row5_col1" class="data row5 col1">1</td>
<td id="T_22956_row5_col2" class="data row5 col2">0.332612</td>
<td id="T_22956_row5_col3" class="data row5 col3">0.196164</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">13</td>
<td id="T_22956_row6_col0" class="data row6 col0">cyborg politics be the struggle for language and the struggle against perfect communication against the one code that translate all mean perfectly the central dogma of phallogocentrism</td>
<td id="T_22956_row6_col1" class="data row6 col1">1</td>
<td id="T_22956_row6_col2" class="data row6 col2">0.018916</td>
<td id="T_22956_row6_col3" class="data row6 col3">0.012902</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">12</td>
<td id="T_22956_row7_col0" class="data row7 col0">have i miss something or have phallocentrism become the late cult</td>
<td id="T_22956_row7_col1" class="data row7 col1">1</td>
<td id="T_22956_row7_col2" class="data row7 col2">0.315829</td>
<td id="T_22956_row7_col3" class="data row7 col3">0.036020</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">10</td>
<td id="T_22956_row8_col0" class="data row8 col0">why bother go to mar if life there be just go to be more of the same toxic sexism racism and bigotry the same horrible oppression unfairness and inequality that make earth a living hell for so many</td>
<td id="T_22956_row8_col1" class="data row8 col1">1</td>
<td id="T_22956_row8_col2" class="data row8 col2">0.058804</td>
<td id="T_22956_row8_col3" class="data row8 col3">0.308408</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">20</td>
<td id="T_22956_row9_col0" class="data row9 col0">i pack my hubby case when we be go to a wedding in england tell him to pop his underpants in get to england he put his kilt outfit on and everyone discover what a true scot doesn t wear under his kilt if i don t do it it doesn t get do men</td>
<td id="T_22956_row9_col1" class="data row9 col1">1</td>
<td id="T_22956_row9_col2" class="data row9 col2">0.056732</td>
<td id="T_22956_row9_col3" class="data row9 col3">0.182320</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">18</td>
<td id="T_22956_row10_col0" class="data row10 col0">bounceeyyyy boobieeeessssss</td>
<td id="T_22956_row10_col1" class="data row10 col1">1</td>
<td id="T_22956_row10_col2" class="data row10 col2">0.392917</td>
<td id="T_22956_row10_col3" class="data row10 col3">0.040618</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">17</td>
<td id="T_22956_row11_col0" class="data row11 col0">but you can enter my heart anytime baby i want u to sodomize me emotionally huhuhu</td>
<td id="T_22956_row11_col1" class="data row11 col1">1</td>
<td id="T_22956_row11_col2" class="data row11 col2">0.482891</td>
<td id="T_22956_row11_col3" class="data row11 col3">0.361583</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row12" class="row_heading level0 row12" data-quarto-table-cell-role="th">16</td>
<td id="T_22956_row12_col0" class="data row12 col0">yea back when i didn t even have one to slap unfortunate</td>
<td id="T_22956_row12_col1" class="data row12 col1">1</td>
<td id="T_22956_row12_col2" class="data row12 col2">0.306543</td>
<td id="T_22956_row12_col3" class="data row12 col3">0.096619</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row13" class="row_heading level0 row13" data-quarto-table-cell-role="th">15</td>
<td id="T_22956_row13_col0" class="data row13 col0">accord to the human right commission in people experience sexual harassment at work we have create an online course provide strategy to prevent and respond should incidents occur start your course at</td>
<td id="T_22956_row13_col1" class="data row13 col1">1</td>
<td id="T_22956_row13_col2" class="data row13 col2">0.093599</td>
<td id="T_22956_row13_col3" class="data row13 col3">0.074334</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row14" class="row_heading level0 row14" data-quarto-table-cell-role="th">29</td>
<td id="T_22956_row14_col0" class="data row14 col0">this genration be no more then selfish cunt more matter how genuine you be you do all the right thing and they still make you look like a cunt it s only get bad too and people ask me why i don t bother with anyone</td>
<td id="T_22956_row14_col1" class="data row14 col1">1</td>
<td id="T_22956_row14_col2" class="data row14 col2">0.081977</td>
<td id="T_22956_row14_col3" class="data row14 col3">0.310637</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row15" class="row_heading level0 row15" data-quarto-table-cell-role="th">11</td>
<td id="T_22956_row15_col0" class="data row15 col0">notice something else tho almost every single one be a man that s such a fucking problem that this be how some men believe they should let out their anger and hatred this society need to do good it do not even benefit the men patriarchy misogyny fail everyone</td>
<td id="T_22956_row15_col1" class="data row15 col1">0</td>
<td id="T_22956_row15_col2" class="data row15 col2">0.455971</td>
<td id="T_22956_row15_col3" class="data row15 col3">0.125236</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row16" class="row_heading level0 row16" data-quarto-table-cell-role="th">3</td>
<td id="T_22956_row16_col0" class="data row16 col0">yup i hate when men rape and kill woman</td>
<td id="T_22956_row16_col1" class="data row16 col1">0</td>
<td id="T_22956_row16_col2" class="data row16 col2">0.054037</td>
<td id="T_22956_row16_col3" class="data row16 col3">0.002256</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row17" class="row_heading level0 row17" data-quarto-table-cell-role="th">5</td>
<td id="T_22956_row17_col0" class="data row17 col0">stop don t lie to these people lady don t let this man trick you out of the great organ of your life cause what</td>
<td id="T_22956_row17_col1" class="data row17 col1">0</td>
<td id="T_22956_row17_col2" class="data row17 col2">0.104192</td>
<td id="T_22956_row17_col3" class="data row17 col3">0.004390</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row18" class="row_heading level0 row18" data-quarto-table-cell-role="th">0</td>
<td id="T_22956_row18_col0" class="data row18 col0">sex a in gender harassment be what they be infer</td>
<td id="T_22956_row18_col1" class="data row18 col1">0</td>
<td id="T_22956_row18_col2" class="data row18 col2">0.215036</td>
<td id="T_22956_row18_col3" class="data row18 col3">0.066964</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row19" class="row_heading level0 row19" data-quarto-table-cell-role="th">6</td>
<td id="T_22956_row19_col0" class="data row19 col0">lady don t have a miscarriage in louisiana if you do in addition to probably have your friend and family sue by some opportunistic yokel you ll be charge with murder</td>
<td id="T_22956_row19_col1" class="data row19 col1">0</td>
<td id="T_22956_row19_col2" class="data row19 col2">0.152081</td>
<td id="T_22956_row19_col3" class="data row19 col3">0.002646</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row20" class="row_heading level0 row20" data-quarto-table-cell-role="th">19</td>
<td id="T_22956_row20_col0" class="data row20 col0">today s woman eye makeup and those nail too</td>
<td id="T_22956_row20_col1" class="data row20 col1">0</td>
<td id="T_22956_row20_col2" class="data row20 col2">0.300865</td>
<td id="T_22956_row20_col3" class="data row20 col3">0.099775</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row21" class="row_heading level0 row21" data-quarto-table-cell-role="th">14</td>
<td id="T_22956_row21_col0" class="data row21 col0">call a man bald be sexual harassment via</td>
<td id="T_22956_row21_col1" class="data row21 col1">0</td>
<td id="T_22956_row21_col2" class="data row21 col2">0.184400</td>
<td id="T_22956_row21_col3" class="data row21 col3">0.059021</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row22" class="row_heading level0 row22" data-quarto-table-cell-role="th">21</td>
<td id="T_22956_row22_col0" class="data row22 col0">oh so now u can t understand woman s word</td>
<td id="T_22956_row22_col1" class="data row22 col1">0</td>
<td id="T_22956_row22_col2" class="data row22 col2">0.060663</td>
<td id="T_22956_row22_col3" class="data row22 col3">0.006125</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row23" class="row_heading level0 row23" data-quarto-table-cell-role="th">22</td>
<td id="T_22956_row23_col0" class="data row23 col0">the question be do i wear the very short skirt that literally show my as with kneehighs or opt out for a short</td>
<td id="T_22956_row23_col1" class="data row23 col1">0</td>
<td id="T_22956_row23_col2" class="data row23 col2">0.441833</td>
<td id="T_22956_row23_col3" class="data row23 col3">0.081327</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row24" class="row_heading level0 row24" data-quarto-table-cell-role="th">24</td>
<td id="T_22956_row24_col0" class="data row24 col0">feminism v womanism hudson weems identifies far difference between womanism and feminism be womanism be family orient and focus on race class and gender while feminism be female orient and strictly focus on biological sex relate issue woman face</td>
<td id="T_22956_row24_col1" class="data row24 col1">0</td>
<td id="T_22956_row24_col2" class="data row24 col2">0.143654</td>
<td id="T_22956_row24_col3" class="data row24 col3">0.187458</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row25" class="row_heading level0 row25" data-quarto-table-cell-role="th">23</td>
<td id="T_22956_row25_col0" class="data row25 col0">my new favorite meme be the pregnant woman drive in the oklahoma hov lane tell the state trooper who pull her over that she be drive with another person</td>
<td id="T_22956_row25_col1" class="data row25 col1">0</td>
<td id="T_22956_row25_col2" class="data row25 col2">0.196056</td>
<td id="T_22956_row25_col3" class="data row25 col3">0.113502</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row26" class="row_heading level0 row26" data-quarto-table-cell-role="th">25</td>
<td id="T_22956_row26_col0" class="data row26 col0">yeah woman be get just a bad i ve notice it anyway i m sorry people be send you stuff like that it can be so gross</td>
<td id="T_22956_row26_col1" class="data row26 col1">0</td>
<td id="T_22956_row26_col2" class="data row26 col2">0.172709</td>
<td id="T_22956_row26_col3" class="data row26 col3">0.012971</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row27" class="row_heading level0 row27" data-quarto-table-cell-role="th">26</td>
<td id="T_22956_row27_col0" class="data row27 col0">a vasectomy be a simple surgery do in an office hospital or clinic hour later recovery be pretty much complete tubal ligation recovery take week longer if it s do follow a c section or childbirth many woman can t afford to take week off work</td>
<td id="T_22956_row27_col1" class="data row27 col1">0</td>
<td id="T_22956_row27_col2" class="data row27 col2">0.247540</td>
<td id="T_22956_row27_col3" class="data row27 col3">0.201829</td>
</tr>
<tr class="odd">
<td id="T_22956_level0_row28" class="row_heading level0 row28" data-quarto-table-cell-role="th">27</td>
<td id="T_22956_row28_col0" class="data row28 col0">woman shouldn t have to share their trauma story for you to feel empathy for the way they re feel today stand with them we deserve a choice junta si podemos</td>
<td id="T_22956_row28_col1" class="data row28 col1">0</td>
<td id="T_22956_row28_col2" class="data row28 col2">0.250281</td>
<td id="T_22956_row28_col3" class="data row28 col3">0.080697</td>
</tr>
<tr class="even">
<td id="T_22956_level0_row29" class="row_heading level0 row29" data-quarto-table-cell-role="th">28</td>
<td id="T_22956_row29_col0" class="data row29 col0">uh they re allow to call this out make you look like a cunt fortunately i ll block you so fast you wont get your screenshot</td>
<td id="T_22956_row29_col1" class="data row29 col1">0</td>
<td id="T_22956_row29_col2" class="data row29 col2">0.418653</td>
<td id="T_22956_row29_col3" class="data row29 col3">0.012207</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Here we display the sentences that <strong>only</strong> the <strong>Transformer</strong> got wrong, along with the absolute differences between prediction values. The sentences are sorted by these differences.</p>
<div id="cell-142" class="cell" data-outputid="517d4c3e-5e53-4e03-91ea-7505e75c9862">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of Transformer-only errors:&nbsp;</span><span class="sc">{</span><span class="bu">len</span>(transformer_errors)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>transformer_errors <span class="op">=</span> transformer_errors.style.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>:<span class="st">'left'</span>})</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>display(transformer_errors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of Transformer-only errors:&nbsp;10</code></pre>
</div>
<div class="cell-output cell-output-display">


<table id="T_beae1" class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_beae1_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">sentence</th>
<th id="T_beae1_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">true_label</th>
<th id="T_beae1_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">model_prediction</th>
<th id="T_beae1_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">transformer_pred</th>
<th id="T_beae1_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">diff_pred</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_beae1_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">5</td>
<td id="T_beae1_row0_col0" class="data row0 col0">dude look like a lady aerosmith</td>
<td id="T_beae1_row0_col1" class="data row0 col1">1</td>
<td id="T_beae1_row0_col2" class="data row0 col2">0.936352</td>
<td id="T_beae1_row0_col3" class="data row0 col3">0.188096</td>
<td id="T_beae1_row0_col4" class="data row0 col4">0.748256</td>
</tr>
<tr class="even">
<td id="T_beae1_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">6</td>
<td id="T_beae1_row1_col0" class="data row1 col0">stay on penis masturbate the penis forever</td>
<td id="T_beae1_row1_col1" class="data row1 col1">0</td>
<td id="T_beae1_row1_col2" class="data row1 col2">0.830019</td>
<td id="T_beae1_row1_col3" class="data row1 col3">0.092392</td>
<td id="T_beae1_row1_col4" class="data row1 col4">0.737627</td>
</tr>
<tr class="odd">
<td id="T_beae1_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">3</td>
<td id="T_beae1_row2_col0" class="data row2 col0">well let me ask for the guy do you ever just grab your testicle because you can</td>
<td id="T_beae1_row2_col1" class="data row2 col1">0</td>
<td id="T_beae1_row2_col2" class="data row2 col2">0.823763</td>
<td id="T_beae1_row2_col3" class="data row2 col3">0.152067</td>
<td id="T_beae1_row2_col4" class="data row2 col4">0.671696</td>
</tr>
<tr class="even">
<td id="T_beae1_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">0</td>
<td id="T_beae1_row3_col0" class="data row3 col0">i mean i do but wouldn t it be fun to get gangbanged together</td>
<td id="T_beae1_row3_col1" class="data row3 col1">0</td>
<td id="T_beae1_row3_col2" class="data row3 col2">0.980279</td>
<td id="T_beae1_row3_col3" class="data row3 col3">0.325955</td>
<td id="T_beae1_row3_col4" class="data row3 col4">0.654325</td>
</tr>
<tr class="odd">
<td id="T_beae1_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">1</td>
<td id="T_beae1_row4_col0" class="data row4 col0">appreciate be include along with on the uvalde gunman s history of cyber gender harassment regrettably unshocking</td>
<td id="T_beae1_row4_col1" class="data row4 col1">0</td>
<td id="T_beae1_row4_col2" class="data row4 col2">0.638995</td>
<td id="T_beae1_row4_col3" class="data row4 col3">0.007495</td>
<td id="T_beae1_row4_col4" class="data row4 col4">0.631501</td>
</tr>
<tr class="even">
<td id="T_beae1_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">7</td>
<td id="T_beae1_row5_col0" class="data row5 col0">it s in the teaxass code book of penis envy idiot that it s gun over everything sad thing be it s spread and the more we try to stop it the faster it spread like the diseased idiot that support it</td>
<td id="T_beae1_row5_col1" class="data row5 col1">0</td>
<td id="T_beae1_row5_col2" class="data row5 col2">0.838803</td>
<td id="T_beae1_row5_col3" class="data row5 col3">0.217703</td>
<td id="T_beae1_row5_col4" class="data row5 col4">0.621100</td>
</tr>
<tr class="odd">
<td id="T_beae1_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">2</td>
<td id="T_beae1_row6_col0" class="data row6 col0">how do we reach a point where blonks be have the audacity to talk about yoongis rap do y all see who you stan be y all ok your girl can t write can t deliver can t come close to bts s lyricism tf be y all get brave for fashion deal</td>
<td id="T_beae1_row6_col1" class="data row6 col1">0</td>
<td id="T_beae1_row6_col2" class="data row6 col2">0.594202</td>
<td id="T_beae1_row6_col3" class="data row6 col3">0.019369</td>
<td id="T_beae1_row6_col4" class="data row6 col4">0.574833</td>
</tr>
<tr class="even">
<td id="T_beae1_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">4</td>
<td id="T_beae1_row7_col0" class="data row7 col0">stop say i say this cu she have short hair some of her gay look come from blonde ponytail era know ur herstory</td>
<td id="T_beae1_row7_col1" class="data row7 col1">1</td>
<td id="T_beae1_row7_col2" class="data row7 col2">0.856455</td>
<td id="T_beae1_row7_col3" class="data row7 col3">0.330240</td>
<td id="T_beae1_row7_col4" class="data row7 col4">0.526215</td>
</tr>
<tr class="odd">
<td id="T_beae1_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_beae1_row8_col0" class="data row8 col0">sharia law in the religion of islam allows abortion before the th montha for rape incest mental physical health or life of mother be at risk after the th month abortion allow only to save the life of the mother</td>
<td id="T_beae1_row8_col1" class="data row8 col1">0</td>
<td id="T_beae1_row8_col2" class="data row8 col2">0.505552</td>
<td id="T_beae1_row8_col3" class="data row8 col3">0.284134</td>
<td id="T_beae1_row8_col4" class="data row8 col4">0.221419</td>
</tr>
<tr class="even">
<td id="T_beae1_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_beae1_row9_col0" class="data row9 col0">isw publish the fake crap of any of the map they be just a front for the u state department they be fake news victoria nuland be the woman directly involve in the armed overthrow of the ukraine government in</td>
<td id="T_beae1_row9_col1" class="data row9 col1">0</td>
<td id="T_beae1_row9_col2" class="data row9 col2">0.538044</td>
<td id="T_beae1_row9_col3" class="data row9 col3">0.371504</td>
<td id="T_beae1_row9_col4" class="data row9 col4">0.166539</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Conversely the sentences below represent the errors made <strong>only</strong> by the <strong>Custom Model</strong>. Additionally we have highlighted the UNK terms in blue and the OOV in red, showing that many of these words are closely related to sexism. Probably such words, which are highly informative for this task, caused the Custom Model to fail on those sentences.</p>
<div id="cell-144" class="cell" data-outputid="a73b9b4e-4dc2-4c9b-96cb-a5642f26555a">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of Custom Model-only errors:&nbsp;</span><span class="sc">{</span><span class="bu">len</span>(model_errors)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>model_errors <span class="op">=</span> model_errors.style.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>:<span class="st">'left'</span>})</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>display(model_errors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of Custom Model-only errors:&nbsp;40</code></pre>
</div>
<div class="cell-output cell-output-display">


<table id="T_2ef2a" class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_2ef2a_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">sentence</th>
<th id="T_2ef2a_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">true_label</th>
<th id="T_2ef2a_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">model_prediction</th>
<th id="T_2ef2a_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">transformer_pred</th>
<th id="T_2ef2a_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">diff_pred</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_2ef2a_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">29</td>
<td id="T_2ef2a_row0_col0" class="data row0 col0">sound like the <span style="color:blue">typa</span> nigga to let his bos sodomize him cause the job come with <span style="color:blue">perk</span> stfu keep that dick in ya mouth nd stay way the fuck out there wherever u nd that ignorant as comment be think of</td>
<td id="T_2ef2a_row0_col1" class="data row0 col1">1</td>
<td id="T_2ef2a_row0_col2" class="data row0 col2">0.073411</td>
<td id="T_2ef2a_row0_col3" class="data row0 col3">0.987215</td>
<td id="T_2ef2a_row0_col4" class="data row0 col4">0.913804</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">9</td>
<td id="T_2ef2a_row1_col0" class="data row1 col0">y all be husband and wife and best friend you guy have so much fun it s awesome you keep each other <span style="color:blue">laughing</span> and smile</td>
<td id="T_2ef2a_row1_col1" class="data row1 col1">0</td>
<td id="T_2ef2a_row1_col2" class="data row1 col2">0.079544</td>
<td id="T_2ef2a_row1_col3" class="data row1 col3">0.990332</td>
<td id="T_2ef2a_row1_col4" class="data row1 col4">0.910788</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">32</td>
<td id="T_2ef2a_row2_col0" class="data row2 col0">never know you all share <span style="color:blue">tits</span> how do we stop be <span style="color:blue">pal</span> again yeah</td>
<td id="T_2ef2a_row2_col1" class="data row2 col1">1</td>
<td id="T_2ef2a_row2_col2" class="data row2 col2">0.079930</td>
<td id="T_2ef2a_row2_col3" class="data row2 col3">0.972010</td>
<td id="T_2ef2a_row2_col4" class="data row2 col4">0.892079</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">28</td>
<td id="T_2ef2a_row3_col0" class="data row3 col0"><span style="color:blue">der</span> i literally take it last night <span style="color:red">slutbag</span></td>
<td id="T_2ef2a_row3_col1" class="data row3 col1">1</td>
<td id="T_2ef2a_row3_col2" class="data row3 col2">0.059965</td>
<td id="T_2ef2a_row3_col3" class="data row3 col3">0.949125</td>
<td id="T_2ef2a_row3_col4" class="data row3 col4">0.889161</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">10</td>
<td id="T_2ef2a_row4_col0" class="data row4 col0">wait till ur husband mess up u gon na love the <span style="color:blue">scouser</span> death threat</td>
<td id="T_2ef2a_row4_col1" class="data row4 col1">1</td>
<td id="T_2ef2a_row4_col2" class="data row4 col2">0.086108</td>
<td id="T_2ef2a_row4_col3" class="data row4 col3">0.975064</td>
<td id="T_2ef2a_row4_col4" class="data row4 col4">0.888955</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">21</td>
<td id="T_2ef2a_row5_col0" class="data row5 col0">eat out both hole and then slide my dick in you and pound you till you <span style="color:blue">squirt</span></td>
<td id="T_2ef2a_row5_col1" class="data row5 col1">1</td>
<td id="T_2ef2a_row5_col2" class="data row5 col2">0.118759</td>
<td id="T_2ef2a_row5_col3" class="data row5 col3">0.984013</td>
<td id="T_2ef2a_row5_col4" class="data row5 col4">0.865254</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">1</td>
<td id="T_2ef2a_row6_col0" class="data row6 col0"><span style="color:blue">suika</span> get <span style="color:red">gangbanged</span> to death</td>
<td id="T_2ef2a_row6_col1" class="data row6 col1">1</td>
<td id="T_2ef2a_row6_col2" class="data row6 col2">0.113801</td>
<td id="T_2ef2a_row6_col3" class="data row6 col3">0.971719</td>
<td id="T_2ef2a_row6_col4" class="data row6 col4">0.857918</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">38</td>
<td id="T_2ef2a_row7_col0" class="data row7 col0">yo i swear <span style="color:blue">sagittarius</span> men and woman be the funny</td>
<td id="T_2ef2a_row7_col1" class="data row7 col1">0</td>
<td id="T_2ef2a_row7_col2" class="data row7 col2">0.089753</td>
<td id="T_2ef2a_row7_col3" class="data row7 col3">0.922790</td>
<td id="T_2ef2a_row7_col4" class="data row7 col4">0.833037</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">4</td>
<td id="T_2ef2a_row8_col0" class="data row8 col0">the violent <span style="color:blue">antifeminism</span> of a far right movement that see <span style="color:blue">principally</span> a vessel for breed a new white generation express itself in a <span style="color:blue">fixation</span> on a return to traditional gender role worth every minute to read take min out of your sun</td>
<td id="T_2ef2a_row8_col1" class="data row8 col1">1</td>
<td id="T_2ef2a_row8_col2" class="data row8 col2">0.050172</td>
<td id="T_2ef2a_row8_col3" class="data row8 col3">0.864687</td>
<td id="T_2ef2a_row8_col4" class="data row8 col4">0.814515</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">37</td>
<td id="T_2ef2a_row9_col0" class="data row9 col0">you don t know who <span style="color:blue">invent</span> womanism huh okay risk skin cancer i guess best of luck to you</td>
<td id="T_2ef2a_row9_col1" class="data row9 col1">1</td>
<td id="T_2ef2a_row9_col2" class="data row9 col2">0.201679</td>
<td id="T_2ef2a_row9_col3" class="data row9 col3">0.990023</td>
<td id="T_2ef2a_row9_col4" class="data row9 col4">0.788343</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">5</td>
<td id="T_2ef2a_row10_col0" class="data row10 col0"><span style="color:blue">isa</span> hot girl summer now pop yall shit</td>
<td id="T_2ef2a_row10_col1" class="data row10 col1">0</td>
<td id="T_2ef2a_row10_col2" class="data row10 col2">0.198477</td>
<td id="T_2ef2a_row10_col3" class="data row10 col3">0.983003</td>
<td id="T_2ef2a_row10_col4" class="data row10 col4">0.784526</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">15</td>
<td id="T_2ef2a_row11_col0" class="data row11 col0">can you confront your misogyny misandry be hardly a problem in the world by comparison and if it exist it a reaction to abuse</td>
<td id="T_2ef2a_row11_col1" class="data row11 col1">1</td>
<td id="T_2ef2a_row11_col2" class="data row11 col2">0.196442</td>
<td id="T_2ef2a_row11_col3" class="data row11 col3">0.971214</td>
<td id="T_2ef2a_row11_col4" class="data row11 col4">0.774772</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row12" class="row_heading level0 row12" data-quarto-table-cell-role="th">22</td>
<td id="T_2ef2a_row12_col0" class="data row12 col0">it s ironic that the majority of the people happy about this in the comment be people who can t get pregnant</td>
<td id="T_2ef2a_row12_col1" class="data row12 col1">1</td>
<td id="T_2ef2a_row12_col2" class="data row12 col2">0.167558</td>
<td id="T_2ef2a_row12_col3" class="data row12 col3">0.917408</td>
<td id="T_2ef2a_row12_col4" class="data row12 col4">0.749850</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row13" class="row_heading level0 row13" data-quarto-table-cell-role="th">14</td>
<td id="T_2ef2a_row13_col0" class="data row13 col0">why do you feel unsafe share a bathroom with a <span style="color:blue">transwoman</span> seem like some bigotry you need to <span style="color:blue">unpack</span> yourself not far marginalize an already marginalize group</td>
<td id="T_2ef2a_row13_col1" class="data row13 col1">1</td>
<td id="T_2ef2a_row13_col2" class="data row13 col2">0.076321</td>
<td id="T_2ef2a_row13_col3" class="data row13 col3">0.824592</td>
<td id="T_2ef2a_row13_col4" class="data row13 col4">0.748271</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row14" class="row_heading level0 row14" data-quarto-table-cell-role="th">11</td>
<td id="T_2ef2a_row14_col0" class="data row14 col0"><span style="color:blue">aughhh</span> i still get an exam tomorrow i hate woman</td>
<td id="T_2ef2a_row14_col1" class="data row14 col1">1</td>
<td id="T_2ef2a_row14_col2" class="data row14 col2">0.159302</td>
<td id="T_2ef2a_row14_col3" class="data row14 col3">0.905700</td>
<td id="T_2ef2a_row14_col4" class="data row14 col4">0.746397</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row15" class="row_heading level0 row15" data-quarto-table-cell-role="th">25</td>
<td id="T_2ef2a_row15_col0" class="data row15 col0">it just show how money rule the world i m so <span style="color:blue">disappointed</span> that <span style="color:blue">ripley</span> s would even allow it out of the building and to let that reality skank get it be an incredible insult i be wait for an sub full of <span style="color:blue">armed</span> <span style="color:blue">robber</span> to <span style="color:blue">overtake</span> her in the end <span style="color:blue">khloe</span> look well</td>
<td id="T_2ef2a_row15_col1" class="data row15 col1">1</td>
<td id="T_2ef2a_row15_col2" class="data row15 col2">0.254709</td>
<td id="T_2ef2a_row15_col3" class="data row15 col3">0.936507</td>
<td id="T_2ef2a_row15_col4" class="data row15 col4">0.681798</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row16" class="row_heading level0 row16" data-quarto-table-cell-role="th">23</td>
<td id="T_2ef2a_row16_col0" class="data row16 col0">have a dream that i be at a party with my friend and bill gate show up and i say to my friend look at his pregnant as <span style="color:blue">belly</span></td>
<td id="T_2ef2a_row16_col1" class="data row16 col1">0</td>
<td id="T_2ef2a_row16_col2" class="data row16 col2">0.304590</td>
<td id="T_2ef2a_row16_col3" class="data row16 col3">0.986050</td>
<td id="T_2ef2a_row16_col4" class="data row16 col4">0.681460</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row17" class="row_heading level0 row17" data-quarto-table-cell-role="th">17</td>
<td id="T_2ef2a_row17_col0" class="data row17 col0">on the audio from when his finger be cut off even the people that be there say she do it she say she s totally against cocaine but do cocaine try to say the nurse be basically lie in her note about her do drug everyone be lie but her</td>
<td id="T_2ef2a_row17_col1" class="data row17 col1">0</td>
<td id="T_2ef2a_row17_col2" class="data row17 col2">0.266323</td>
<td id="T_2ef2a_row17_col3" class="data row17 col3">0.945932</td>
<td id="T_2ef2a_row17_col4" class="data row17 col4">0.679609</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row18" class="row_heading level0 row18" data-quarto-table-cell-role="th">12</td>
<td id="T_2ef2a_row18_col0" class="data row18 col0">they tell u we re <span style="color:blue">brood</span> <span style="color:blue">mare</span> amp must die so cell clump can live carry our rapist baby amp want u to protest <span style="color:blue">civilly</span> yes he s <span style="color:red">mansplaining</span> protest <span style="color:blue">nicely</span> while we be move toward enslavement <span style="color:blue">polite</span> little ladies no</td>
<td id="T_2ef2a_row18_col1" class="data row18 col1">1</td>
<td id="T_2ef2a_row18_col2" class="data row18 col2">0.323620</td>
<td id="T_2ef2a_row18_col3" class="data row18 col3">0.964314</td>
<td id="T_2ef2a_row18_col4" class="data row18 col4">0.640694</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row19" class="row_heading level0 row19" data-quarto-table-cell-role="th">27</td>
<td id="T_2ef2a_row19_col0" class="data row19 col0">jealous <span style="color:blue">plss</span> talk about his new album u <span style="color:blue">wrinkly</span> <span style="color:red">slutbag</span></td>
<td id="T_2ef2a_row19_col1" class="data row19 col1">1</td>
<td id="T_2ef2a_row19_col2" class="data row19 col2">0.042669</td>
<td id="T_2ef2a_row19_col3" class="data row19 col3">0.682589</td>
<td id="T_2ef2a_row19_col4" class="data row19 col4">0.639920</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row20" class="row_heading level0 row20" data-quarto-table-cell-role="th">39</td>
<td id="T_2ef2a_row20_col0" class="data row20 col0">little woman <span style="color:blue">atlanta</span> star m juicy reveal health struggle after have a <span style="color:blue">stroke</span></td>
<td id="T_2ef2a_row20_col1" class="data row20 col1">0</td>
<td id="T_2ef2a_row20_col2" class="data row20 col2">0.376461</td>
<td id="T_2ef2a_row20_col3" class="data row20 col3">0.991794</td>
<td id="T_2ef2a_row20_col4" class="data row20 col4">0.615333</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row21" class="row_heading level0 row21" data-quarto-table-cell-role="th">2</td>
<td id="T_2ef2a_row21_col0" class="data row21 col0">maybe something involve her get <span style="color:red">gangbanged</span></td>
<td id="T_2ef2a_row21_col1" class="data row21 col1">1</td>
<td id="T_2ef2a_row21_col2" class="data row21 col2">0.381396</td>
<td id="T_2ef2a_row21_col3" class="data row21 col3">0.995329</td>
<td id="T_2ef2a_row21_col4" class="data row21 col4">0.613932</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row22" class="row_heading level0 row22" data-quarto-table-cell-role="th">30</td>
<td id="T_2ef2a_row22_col0" class="data row22 col0">so you stereotype someone base on their appearance be what make you some form of <span style="color:blue">enlightened</span> individual a oppose to a <span style="color:blue">throwback</span> racist cretin get it judge people by the race and appearance accord to this guy</td>
<td id="T_2ef2a_row22_col1" class="data row22 col1">0</td>
<td id="T_2ef2a_row22_col2" class="data row22 col2">0.363724</td>
<td id="T_2ef2a_row22_col3" class="data row22 col3">0.967839</td>
<td id="T_2ef2a_row22_col4" class="data row22 col4">0.604115</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row23" class="row_heading level0 row23" data-quarto-table-cell-role="th">33</td>
<td id="T_2ef2a_row23_col0" class="data row23 col0">should focus on money freedom and not retirement today s woman may still think about a not have to work read why gt</td>
<td id="T_2ef2a_row23_col1" class="data row23 col1">1</td>
<td id="T_2ef2a_row23_col2" class="data row23 col2">0.341708</td>
<td id="T_2ef2a_row23_col3" class="data row23 col3">0.938272</td>
<td id="T_2ef2a_row23_col4" class="data row23 col4">0.596564</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row24" class="row_heading level0 row24" data-quarto-table-cell-role="th">0</td>
<td id="T_2ef2a_row24_col0" class="data row24 col0">st day at the pool on a beautiful sunday in ny too bad few dare to go in due to the frigid water temp we last min and figure we prove our point</td>
<td id="T_2ef2a_row24_col1" class="data row24 col1">0</td>
<td id="T_2ef2a_row24_col2" class="data row24 col2">0.422451</td>
<td id="T_2ef2a_row24_col3" class="data row24 col3">0.995615</td>
<td id="T_2ef2a_row24_col4" class="data row24 col4">0.573164</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row25" class="row_heading level0 row25" data-quarto-table-cell-role="th">8</td>
<td id="T_2ef2a_row25_col0" class="data row25 col0">best way to do that be from behind her with your hand on her hip</td>
<td id="T_2ef2a_row25_col1" class="data row25 col1">1</td>
<td id="T_2ef2a_row25_col2" class="data row25 col2">0.442914</td>
<td id="T_2ef2a_row25_col3" class="data row25 col3">0.988667</td>
<td id="T_2ef2a_row25_col4" class="data row25 col4">0.545753</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row26" class="row_heading level0 row26" data-quarto-table-cell-role="th">16</td>
<td id="T_2ef2a_row26_col0" class="data row26 col0">most woman who don t like bath go to girls school</td>
<td id="T_2ef2a_row26_col1" class="data row26 col1">1</td>
<td id="T_2ef2a_row26_col2" class="data row26 col2">0.443296</td>
<td id="T_2ef2a_row26_col3" class="data row26 col3">0.989010</td>
<td id="T_2ef2a_row26_col4" class="data row26 col4">0.545713</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row27" class="row_heading level0 row27" data-quarto-table-cell-role="th">19</td>
<td id="T_2ef2a_row27_col0" class="data row27 col0">ah here she be work hard to promote the patriarchy <span style="color:blue">exploit</span> the light music club girl like porn victim by make them drink tea eat cake and occasionally play cute song or something also trick young woman into like the show how dare she</td>
<td id="T_2ef2a_row27_col1" class="data row27 col1">1</td>
<td id="T_2ef2a_row27_col2" class="data row27 col2">0.452815</td>
<td id="T_2ef2a_row27_col3" class="data row27 col3">0.996730</td>
<td id="T_2ef2a_row27_col4" class="data row27 col4">0.543915</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row28" class="row_heading level0 row28" data-quarto-table-cell-role="th">3</td>
<td id="T_2ef2a_row28_col0" class="data row28 col0">kabul islamic <span style="color:blue">emirate</span> of afghanistan have announce the end of co education in the country cite gender harassment female student will attend university on <span style="color:blue">monday</span> wednesday and saturday while tuesday thursday and sunday be fix for male</td>
<td id="T_2ef2a_row28_col1" class="data row28 col1">1</td>
<td id="T_2ef2a_row28_col2" class="data row28 col2">0.453141</td>
<td id="T_2ef2a_row28_col3" class="data row28 col3">0.977071</td>
<td id="T_2ef2a_row28_col4" class="data row28 col4">0.523930</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row29" class="row_heading level0 row29" data-quarto-table-cell-role="th">6</td>
<td id="T_2ef2a_row29_col0" class="data row29 col0">my baby call me <span style="color:blue">mommy</span> sha for the first time today twice y all don t understand how <span style="color:blue">hype</span> that make me baby girl have autism and get her to talk without be prompt have be a challenge she s come so far</td>
<td id="T_2ef2a_row29_col1" class="data row29 col1">0</td>
<td id="T_2ef2a_row29_col2" class="data row29 col2">0.469968</td>
<td id="T_2ef2a_row29_col3" class="data row29 col3">0.990878</td>
<td id="T_2ef2a_row29_col4" class="data row29 col4">0.520910</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row30" class="row_heading level0 row30" data-quarto-table-cell-role="th">26</td>
<td id="T_2ef2a_row30_col0" class="data row30 col0">i kinda get her point but a slag be too far off for me</td>
<td id="T_2ef2a_row30_col1" class="data row30 col1">1</td>
<td id="T_2ef2a_row30_col2" class="data row30 col2">0.395405</td>
<td id="T_2ef2a_row30_col3" class="data row30 col3">0.897156</td>
<td id="T_2ef2a_row30_col4" class="data row30 col4">0.501750</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row31" class="row_heading level0 row31" data-quarto-table-cell-role="th">36</td>
<td id="T_2ef2a_row31_col0" class="data row31 col0">so why tf ya call it <span style="color:blue">femism</span> shouldn t it be womanism if that s the case</td>
<td id="T_2ef2a_row31_col1" class="data row31 col1">1</td>
<td id="T_2ef2a_row31_col2" class="data row31 col2">0.486762</td>
<td id="T_2ef2a_row31_col3" class="data row31 col3">0.988478</td>
<td id="T_2ef2a_row31_col4" class="data row31 col4">0.501716</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row32" class="row_heading level0 row32" data-quarto-table-cell-role="th">20</td>
<td id="T_2ef2a_row32_col0" class="data row32 col0">fuck s sake be it possible to have a furry space that s not explicitly content <span style="color:blue">restrict</span> and doesn t immediately become yet another showcase for size queen <span style="color:red">phallocentrism</span></td>
<td id="T_2ef2a_row32_col1" class="data row32 col1">1</td>
<td id="T_2ef2a_row32_col2" class="data row32 col2">0.179012</td>
<td id="T_2ef2a_row32_col3" class="data row32 col3">0.665819</td>
<td id="T_2ef2a_row32_col4" class="data row32 col4">0.486806</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row33" class="row_heading level0 row33" data-quarto-table-cell-role="th">34</td>
<td id="T_2ef2a_row33_col0" class="data row33 col0">an <span style="color:blue">unarmed</span> black woman drive a car with a broken tail light be more dangerous than a white supremacist terrorist who murder people</td>
<td id="T_2ef2a_row33_col1" class="data row33 col1">1</td>
<td id="T_2ef2a_row33_col2" class="data row33 col2">0.280515</td>
<td id="T_2ef2a_row33_col3" class="data row33 col3">0.694021</td>
<td id="T_2ef2a_row33_col4" class="data row33 col4">0.413506</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row34" class="row_heading level0 row34" data-quarto-table-cell-role="th">31</td>
<td id="T_2ef2a_row34_col0" class="data row34 col0">superwoman syndrome it s all too real and <span style="color:blue">debilitate</span> for this gal</td>
<td id="T_2ef2a_row34_col1" class="data row34 col1">1</td>
<td id="T_2ef2a_row34_col2" class="data row34 col2">0.458902</td>
<td id="T_2ef2a_row34_col3" class="data row34 col3">0.816766</td>
<td id="T_2ef2a_row34_col4" class="data row34 col4">0.357864</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row35" class="row_heading level0 row35" data-quarto-table-cell-role="th">7</td>
<td id="T_2ef2a_row35_col0" class="data row35 col0">he try to expose this gold digger but it <span style="color:blue">backfire</span> day fianc e b via</td>
<td id="T_2ef2a_row35_col1" class="data row35 col1">0</td>
<td id="T_2ef2a_row35_col2" class="data row35 col2">0.264883</td>
<td id="T_2ef2a_row35_col3" class="data row35 col3">0.560497</td>
<td id="T_2ef2a_row35_col4" class="data row35 col4">0.295614</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row36" class="row_heading level0 row36" data-quarto-table-cell-role="th">13</td>
<td id="T_2ef2a_row36_col0" class="data row36 col0"><span style="color:blue">wonwoo</span> cross legs amp jun <span style="color:red">manspreading</span></td>
<td id="T_2ef2a_row36_col1" class="data row36 col1">1</td>
<td id="T_2ef2a_row36_col2" class="data row36 col2">0.374546</td>
<td id="T_2ef2a_row36_col3" class="data row36 col3">0.648841</td>
<td id="T_2ef2a_row36_col4" class="data row36 col4">0.274295</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row37" class="row_heading level0 row37" data-quarto-table-cell-role="th">24</td>
<td id="T_2ef2a_row37_col0" class="data row37 col0">i don t care what gender race religion sexual orientation a person be as long a they be qualify for that position that be say be she qualify base on experience education or be she choose solely because she be black and gay to please progressive wake just say</td>
<td id="T_2ef2a_row37_col1" class="data row37 col1">1</td>
<td id="T_2ef2a_row37_col2" class="data row37 col2">0.320049</td>
<td id="T_2ef2a_row37_col3" class="data row37 col3">0.591192</td>
<td id="T_2ef2a_row37_col4" class="data row37 col4">0.271143</td>
</tr>
<tr class="odd">
<td id="T_2ef2a_level0_row38" class="row_heading level0 row38" data-quarto-table-cell-role="th">18</td>
<td id="T_2ef2a_row38_col0" class="data row38 col0">a a <span style="color:blue">diverse</span> and <span style="color:blue">pluralistic</span> country america s law should not be base on a distorted and patriarchal interpretation of christianity <span style="color:blue">furthermore</span> the government should have no role <span style="color:blue">whatsoever</span> in a woman s private healthcare decision</td>
<td id="T_2ef2a_row38_col1" class="data row38 col1">0</td>
<td id="T_2ef2a_row38_col2" class="data row38 col2">0.329812</td>
<td id="T_2ef2a_row38_col3" class="data row38 col3">0.504869</td>
<td id="T_2ef2a_row38_col4" class="data row38 col4">0.175056</td>
</tr>
<tr class="even">
<td id="T_2ef2a_level0_row39" class="row_heading level0 row39" data-quarto-table-cell-role="th">35</td>
<td id="T_2ef2a_row39_col0" class="data row39 col0">i be non binary and also lean into my femininity most of the time i be content with be <span style="color:blue">afab</span> amp be see a a woman amp embrace it other time i simply want to be a <span style="color:blue">genderless</span> thing that exist</td>
<td id="T_2ef2a_row39_col1" class="data row39 col1">0</td>
<td id="T_2ef2a_row39_col2" class="data row39 col2">0.344296</td>
<td id="T_2ef2a_row39_col3" class="data row39 col3">0.512631</td>
<td id="T_2ef2a_row39_col4" class="data row39 col4">0.168335</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Let’s now analyze potential patterns of error in the model’s predictions. We will start by plotting the length of the sentences that were incorrectly classified, this analysis can help us identify whether the model struggles with sentences of specific lengths.</p>
<div id="cell-146" class="cell">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_len_sentences(</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>    model_predictions: np.ndarray,</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>    true_labels: np.ndarray,</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>    sentences: List[List[<span class="bu">str</span>]],</span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>    model_name: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Plots the length of the wrong classified sentences for each label and calculates correlation.</span></span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_predictions: predictions of the model (np.ndarray)</span></span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a><span class="co">    :param true_labels: true labels (np.ndarray)</span></span>
<span id="cb116-11"><a href="#cb116-11" aria-hidden="true" tabindex="-1"></a><span class="co">    :param sentences: input sentences (list)</span></span>
<span id="cb116-12"><a href="#cb116-12" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_name: name of the model for the plot title (str)</span></span>
<span id="cb116-13"><a href="#cb116-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb116-14"><a href="#cb116-14" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame({<span class="st">"sentences"</span>: <span class="bu">list</span>(sentences)})</span>
<span id="cb116-15"><a href="#cb116-15" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">"true_label"</span>] <span class="op">=</span> true_labels</span>
<span id="cb116-16"><a href="#cb116-16" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">"pred_label"</span>] <span class="op">=</span> model_predictions.astype(<span class="bu">int</span>)</span>
<span id="cb116-17"><a href="#cb116-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-18"><a href="#cb116-18" aria-hidden="true" tabindex="-1"></a>    df_wrong <span class="op">=</span> df[df[<span class="st">"true_label"</span>] <span class="op">!=</span> df[<span class="st">"pred_label"</span>]]</span>
<span id="cb116-19"><a href="#cb116-19" aria-hidden="true" tabindex="-1"></a>    len_sentences_wrong <span class="op">=</span> Counter([<span class="bu">len</span>(row) <span class="cf">for</span> row <span class="kw">in</span> df_wrong[<span class="st">"sentences"</span>]])</span>
<span id="cb116-20"><a href="#cb116-20" aria-hidden="true" tabindex="-1"></a>    len_sentences <span class="op">=</span> Counter([<span class="bu">len</span>(row) <span class="cf">for</span> row <span class="kw">in</span> df[<span class="st">"sentences"</span>]])</span>
<span id="cb116-21"><a href="#cb116-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-22"><a href="#cb116-22" aria-hidden="true" tabindex="-1"></a>    all_lengths, all_counts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>len_sentences.items())</span>
<span id="cb116-23"><a href="#cb116-23" aria-hidden="true" tabindex="-1"></a>    wrong_lengths, wrong_counts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>len_sentences_wrong.items())</span>
<span id="cb116-24"><a href="#cb116-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-25"><a href="#cb116-25" aria-hidden="true" tabindex="-1"></a>    plt.bar(wrong_lengths, wrong_counts, color<span class="op">=</span><span class="st">"tab:blue"</span>, label<span class="op">=</span><span class="st">"Wrong Sentences"</span>)</span>
<span id="cb116-26"><a href="#cb116-26" aria-hidden="true" tabindex="-1"></a>    plt.bar(all_lengths, all_counts, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">"tab:blue"</span>, label<span class="op">=</span><span class="st">"All Sentences"</span>)</span>
<span id="cb116-27"><a href="#cb116-27" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Length of </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> wrong sentences"</span>)</span>
<span id="cb116-28"><a href="#cb116-28" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Sentence Length"</span>)</span>
<span id="cb116-29"><a href="#cb116-29" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Count"</span>)</span>
<span id="cb116-30"><a href="#cb116-30" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb116-31"><a href="#cb116-31" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb116-32"><a href="#cb116-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-33"><a href="#cb116-33" aria-hidden="true" tabindex="-1"></a>    wrong_dict <span class="op">=</span> <span class="bu">dict</span>(len_sentences_wrong)</span>
<span id="cb116-34"><a href="#cb116-34" aria-hidden="true" tabindex="-1"></a>    all_dict <span class="op">=</span> <span class="bu">dict</span>(len_sentences)</span>
<span id="cb116-35"><a href="#cb116-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-36"><a href="#cb116-36" aria-hidden="true" tabindex="-1"></a>    lengths <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>(all_dict.keys()).union(<span class="bu">set</span>(wrong_dict.keys())))</span>
<span id="cb116-37"><a href="#cb116-37" aria-hidden="true" tabindex="-1"></a>    wrong_counts_aligned <span class="op">=</span> [wrong_dict.get(length, <span class="dv">0</span>) <span class="cf">for</span> length <span class="kw">in</span> lengths]</span>
<span id="cb116-38"><a href="#cb116-38" aria-hidden="true" tabindex="-1"></a>    all_counts_aligned <span class="op">=</span> [all_dict.get(length, <span class="dv">0</span>) <span class="cf">for</span> length <span class="kw">in</span> lengths]</span>
<span id="cb116-39"><a href="#cb116-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-40"><a href="#cb116-40" aria-hidden="true" tabindex="-1"></a>    correlation <span class="op">=</span> np.corrcoef(wrong_counts_aligned, all_counts_aligned)[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb116-41"><a href="#cb116-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Correlation between wrong sentence lengths and total lengths: </span><span class="sc">{</span>correlation<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Comparing the length distribution of the missclassified sentences with that of all sentences we noticed a quite high correlation between the two. This means that sentence length does not significantly influence the predictions of either the Custom Model or the Transformer.</p>
<div id="cell-148" class="cell" data-outputid="fe761341-413a-41d3-ff52-e871beb9b9d2">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>plot_len_sentences(model_test_preds_hard, test_labels, decoded_test, <span class="st">'Custom Model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-79-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Correlation between wrong sentence lengths and total lengths: 0.71</code></pre>
</div>
</div>
<div id="cell-149" class="cell" data-outputid="fc9b0872-2aaf-4259-cc56-3a803db0cb51">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>plot_len_sentences(transformer_preds_hard, test_labels, decoded_test, <span class="st">'Transformer'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-80-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Correlation between wrong sentence lengths and total lengths: 0.50</code></pre>
</div>
</div>
</section>
<section id="word-level-analysis" class="level2">
<h2 class="anchored" data-anchor-id="word-level-analysis">Word-level analysis</h2>
<p>Since it looks like there are no clear error patterns at sentence level, we will delve into a more fine-grained analysis: a word-level analysis. This analysis will help us understand whether certain types of words systematically affect the model’s predictions.</p>
<div id="cell-152" class="cell">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_unk_stats(model_predictions: np.ndarray,</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>                   true_labels: np.ndarray,</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>                   sentences: List[List[<span class="bu">str</span>]]) <span class="op">-&gt;</span> Tuple[List[<span class="bu">str</span>],List[<span class="bu">str</span>]]:</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">'''</span></span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Displays the statistic releated to the UNK token.</span></span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a><span class="co">  :param model_predictions: predictions of the model (np.ndarray)</span></span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a><span class="co">  :param true_labels: true labels (np.ndarray)</span></span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a><span class="co">  :param sentences: input sentences (list)</span></span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a><span class="co">  '''</span></span>
<span id="cb121-11"><a href="#cb121-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-12"><a href="#cb121-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> update_stats(df:pd.DataFrame) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb121-13"><a href="#cb121-13" aria-hidden="true" tabindex="-1"></a>    all_words <span class="op">=</span> Counter(</span>
<span id="cb121-14"><a href="#cb121-14" aria-hidden="true" tabindex="-1"></a>      word <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> oov_terms <span class="cf">else</span> <span class="st">'OOV'</span> <span class="cf">for</span> row <span class="kw">in</span> df[<span class="st">"sentences"</span>] <span class="cf">for</span> word <span class="kw">in</span> row</span>
<span id="cb121-15"><a href="#cb121-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb121-16"><a href="#cb121-16" aria-hidden="true" tabindex="-1"></a>    df_wrong <span class="op">=</span> df[df[<span class="st">'true_label'</span>] <span class="op">!=</span> df[<span class="st">'pred_label'</span>]]</span>
<span id="cb121-17"><a href="#cb121-17" aria-hidden="true" tabindex="-1"></a>    wrongest_words <span class="op">=</span> Counter(</span>
<span id="cb121-18"><a href="#cb121-18" aria-hidden="true" tabindex="-1"></a>      word <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> oov_terms <span class="cf">else</span> <span class="st">'OOV'</span> <span class="cf">for</span> row <span class="kw">in</span> df_wrong[<span class="st">"sentences"</span>] <span class="cf">for</span> word <span class="kw">in</span> row</span>
<span id="cb121-19"><a href="#cb121-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb121-20"><a href="#cb121-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-21"><a href="#cb121-21" aria-hidden="true" tabindex="-1"></a>    count_total_unk, count_total_oov <span class="op">=</span> all_words[<span class="st">'UNK'</span>], all_words[<span class="st">'OOV'</span>]</span>
<span id="cb121-22"><a href="#cb121-22" aria-hidden="true" tabindex="-1"></a>    count_wrong_unk, count_wrong_oov <span class="op">=</span> wrongest_words[<span class="st">'UNK'</span>], wrongest_words[<span class="st">'OOV'</span>]</span>
<span id="cb121-23"><a href="#cb121-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-24"><a href="#cb121-24" aria-hidden="true" tabindex="-1"></a>    unk_per_sentences <span class="op">=</span> np.mean([<span class="bu">sum</span>([<span class="dv">1</span> <span class="cf">for</span> word <span class="kw">in</span> sentence <span class="cf">if</span> word<span class="op">==</span><span class="st">'UNK'</span>]) <span class="cf">for</span> sentence <span class="kw">in</span> df[<span class="st">"sentences"</span>]])</span>
<span id="cb121-25"><a href="#cb121-25" aria-hidden="true" tabindex="-1"></a>    unk_per_wrong_sentences <span class="op">=</span> np.mean([<span class="bu">sum</span>([<span class="dv">1</span> <span class="cf">for</span> word <span class="kw">in</span> sentence <span class="cf">if</span> word<span class="op">==</span><span class="st">'UNK'</span>]) <span class="cf">for</span> sentence <span class="kw">in</span> df_wrong[<span class="st">"sentences"</span>]])</span>
<span id="cb121-26"><a href="#cb121-26" aria-hidden="true" tabindex="-1"></a>    unk_stats.loc[<span class="bu">len</span>(unk_stats)] <span class="op">=</span> [<span class="bu">len</span>(df), <span class="bu">len</span>(df_wrong), count_total_unk, count_wrong_unk, count_total_oov, count_wrong_oov]</span>
<span id="cb121-27"><a href="#cb121-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-28"><a href="#cb121-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-29"><a href="#cb121-29" aria-hidden="true" tabindex="-1"></a>  column_names <span class="op">=</span> pd.MultiIndex.from_product([[<span class="st">'Sentences'</span>, <span class="st">'UNK'</span>, <span class="st">'OOV'</span>], [<span class="st">'Total'</span>, <span class="st">'Wrong'</span>]])</span>
<span id="cb121-30"><a href="#cb121-30" aria-hidden="true" tabindex="-1"></a>  unk_stats <span class="op">=</span> pd.DataFrame(columns <span class="op">=</span> column_names, dtype <span class="op">=</span> <span class="bu">int</span>)</span>
<span id="cb121-31"><a href="#cb121-31" aria-hidden="true" tabindex="-1"></a>  df <span class="op">=</span> pd.DataFrame({<span class="st">"sentences"</span>: <span class="bu">list</span>(sentences)})</span>
<span id="cb121-32"><a href="#cb121-32" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">"true_label"</span>] <span class="op">=</span> true_labels</span>
<span id="cb121-33"><a href="#cb121-33" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">"pred_label"</span>] <span class="op">=</span> model_predictions</span>
<span id="cb121-34"><a href="#cb121-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-35"><a href="#cb121-35" aria-hidden="true" tabindex="-1"></a>  df_0 <span class="op">=</span> df[df[<span class="st">"true_label"</span>] <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb121-36"><a href="#cb121-36" aria-hidden="true" tabindex="-1"></a>  df_1 <span class="op">=</span> df[df[<span class="st">"true_label"</span>] <span class="op">==</span> <span class="dv">1</span>]</span>
<span id="cb121-37"><a href="#cb121-37" aria-hidden="true" tabindex="-1"></a>  update_stats(df_0)</span>
<span id="cb121-38"><a href="#cb121-38" aria-hidden="true" tabindex="-1"></a>  update_stats(df_1)</span>
<span id="cb121-39"><a href="#cb121-39" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">'Statistics of UNK and OOV terms of Custom Model</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb121-40"><a href="#cb121-40" aria-hidden="true" tabindex="-1"></a>  display(unk_stats)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The table below shows statistics related to the presence of <strong>UNK</strong> and <strong>OOV</strong> tokens in the sentences, distinguishing between all sentences (total) and those incorrectly classified. Although there are differences in the counts, the proportion of <strong>UNK</strong> and <strong>OOV</strong> tokens in wrong predictions does not suggest a strong influence on the Custom Model’s errors. Specifically:</p>
<ul>
<li><p><strong>UNK</strong> tokens appear frequently in both total and wrong sentences, but their distribution does not seem to correlate with misclassifications.</p></li>
<li><p><strong>OOV</strong> tokens are relatively rare overall, but a large number of them (11 out of 20) appear in misclassified sentences with label 1. Indeed, as we have seen in the earlier analysis section, these terms are closely related to sexism and are important for the task.</p></li>
</ul>
<div id="cell-154" class="cell" data-outputid="4c00dc65-e919-4169-e184-7c79459fc025">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>plot_unk_stats(model_test_preds_hard, test_labels, decoded_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Statistics of UNK and OOV terms of Custom Model
</code></pre>
</div>
<div class="cell-output cell-output-display">

  <div id="df-fd8d523a-992b-4fd0-8931-7d3ceef85fcc" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">Sentences</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">UNK</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">OOV</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Total</th>
<th data-quarto-table-cell-role="th">Wrong</th>
<th data-quarto-table-cell-role="th">Total</th>
<th data-quarto-table-cell-role="th">Wrong</th>
<th data-quarto-table-cell-role="th">Total</th>
<th data-quarto-table-cell-role="th">Wrong</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>160</td>
<td>27</td>
<td>340</td>
<td>35</td>
<td>10</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>126</td>
<td>43</td>
<td>218</td>
<td>60</td>
<td>20</td>
<td>11</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-fd8d523a-992b-4fd0-8931-7d3ceef85fcc')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-fd8d523a-992b-4fd0-8931-7d3ceef85fcc button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-fd8d523a-992b-4fd0-8931-7d3ceef85fcc');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-de4a64aa-80d9-4b1e-85d2-efef98ab551a">
  <button class="colab-df-quickchart" onclick="quickchart('df-de4a64aa-80d9-4b1e-85d2-efef98ab551a')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-de4a64aa-80d9-4b1e-85d2-efef98ab551a button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<p>Since UNK terms do not appear to be correlated with the Custom Model’s errors, we will now focus on analyzing the frequency of the most common terms, including OOV terms. This analysis aims to identify the words most strongly correlated with the model’s misclassifications.</p>
<div id="cell-156" class="cell">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_wrong_word(model_predictions: np.ndarray,</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>                    true_labels: np.ndarray,</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>                    sentences: List[List[<span class="bu">str</span>]],</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>                    model_name: <span class="bu">str</span>,</span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>                    top_wrongest: <span class="bu">int</span> <span class="op">=</span> <span class="dv">20</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Shows the most frequent words in wrong classified sentences.</span></span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-9"><a href="#cb124-9" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_predictions: predictions of the model (np.ndarray)</span></span>
<span id="cb124-10"><a href="#cb124-10" aria-hidden="true" tabindex="-1"></a><span class="co">    :param true_labels: true labels (np.ndarray)</span></span>
<span id="cb124-11"><a href="#cb124-11" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_name: name of the model for the plot title (str)</span></span>
<span id="cb124-12"><a href="#cb124-12" aria-hidden="true" tabindex="-1"></a><span class="co">    :param sentences: input sentences (list)</span></span>
<span id="cb124-13"><a href="#cb124-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb124-14"><a href="#cb124-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> find_wrongest(df: pd.DataFrame, label: <span class="bu">int</span>, ax: matplotlib.axes.Axes) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb124-15"><a href="#cb124-15" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> df[df[<span class="st">"true_label"</span>] <span class="op">==</span> label]</span>
<span id="cb124-16"><a href="#cb124-16" aria-hidden="true" tabindex="-1"></a>        all_words <span class="op">=</span> Counter(</span>
<span id="cb124-17"><a href="#cb124-17" aria-hidden="true" tabindex="-1"></a>            word <span class="cf">for</span> row <span class="kw">in</span> df[<span class="st">"sentences"</span>] <span class="cf">for</span> word <span class="kw">in</span> row <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stop_words</span>
<span id="cb124-18"><a href="#cb124-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb124-19"><a href="#cb124-19" aria-hidden="true" tabindex="-1"></a>        df_wrong <span class="op">=</span> df[df[<span class="st">'true_label'</span>] <span class="op">!=</span> df[<span class="st">'pred_label'</span>]]</span>
<span id="cb124-20"><a href="#cb124-20" aria-hidden="true" tabindex="-1"></a>        wrongest_words <span class="op">=</span> Counter(</span>
<span id="cb124-21"><a href="#cb124-21" aria-hidden="true" tabindex="-1"></a>            word <span class="cf">for</span> row <span class="kw">in</span> df_wrong[<span class="st">"sentences"</span>] <span class="cf">for</span> word <span class="kw">in</span> row <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stop_words</span>
<span id="cb124-22"><a href="#cb124-22" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb124-23"><a href="#cb124-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-24"><a href="#cb124-24" aria-hidden="true" tabindex="-1"></a>        wr_words, wr_counts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>wrongest_words.most_common(top_wrongest)[:<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb124-25"><a href="#cb124-25" aria-hidden="true" tabindex="-1"></a>        ax.barh(wr_words, wr_counts, color<span class="op">=</span><span class="st">"skyblue"</span>, label<span class="op">=</span><span class="st">'Wrong Sentences'</span>)</span>
<span id="cb124-26"><a href="#cb124-26" aria-hidden="true" tabindex="-1"></a>        counts <span class="op">=</span> [all_words[word] <span class="cf">for</span> word <span class="kw">in</span> wr_words]</span>
<span id="cb124-27"><a href="#cb124-27" aria-hidden="true" tabindex="-1"></a>        ax.barh(wr_words, counts, color<span class="op">=</span><span class="st">"skyblue"</span>,alpha<span class="op">=</span><span class="fl">0.4</span>, label<span class="op">=</span><span class="st">'All Sentences'</span>)</span>
<span id="cb124-28"><a href="#cb124-28" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f"Wrongest words in label </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb124-29"><a href="#cb124-29" aria-hidden="true" tabindex="-1"></a>        ax.xaxis.set_major_locator(MaxNLocator(integer<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb124-30"><a href="#cb124-30" aria-hidden="true" tabindex="-1"></a>        ax.legend()</span>
<span id="cb124-31"><a href="#cb124-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-32"><a href="#cb124-32" aria-hidden="true" tabindex="-1"></a>    stop_words <span class="op">=</span> <span class="bu">list</span>(stopwords.words(<span class="st">"english"</span>)) <span class="op">+</span> <span class="bu">list</span>(stopwords.words(<span class="st">"spanish"</span>)) <span class="op">+</span> [<span class="st">'n'</span>, <span class="st">'ser'</span>]</span>
<span id="cb124-33"><a href="#cb124-33" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame({<span class="st">"sentences"</span>: <span class="bu">list</span>(sentences)})</span>
<span id="cb124-34"><a href="#cb124-34" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">"true_label"</span>] <span class="op">=</span> true_labels</span>
<span id="cb124-35"><a href="#cb124-35" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">"pred_label"</span>] <span class="op">=</span> model_predictions.astype(<span class="bu">int</span>)</span>
<span id="cb124-36"><a href="#cb124-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-37"><a href="#cb124-37" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb124-38"><a href="#cb124-38" aria-hidden="true" tabindex="-1"></a>    fig.suptitle(<span class="ss">f'</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> charts'</span>, weight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb124-39"><a href="#cb124-39" aria-hidden="true" tabindex="-1"></a>    find_wrongest(df, <span class="dv">0</span>, axs[<span class="dv">0</span>])</span>
<span id="cb124-40"><a href="#cb124-40" aria-hidden="true" tabindex="-1"></a>    find_wrongest(df, <span class="dv">1</span>, axs[<span class="dv">1</span>])</span>
<span id="cb124-41"><a href="#cb124-41" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb124-42"><a href="#cb124-42" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Each of the following chart highlights the top words that contributed to the model’s errors for the respective label. Common stop words (e.g., “the”, “and”, “is”) are removed to focus on more meaningful terms that might influence the model’s predictions.</p>
<p>For each word, the chart shows: * Darker Bars: Frequency of the word in misclassified sentences. * Lighter Bars (Transparent): Overall frequency of the word in all sentences of the given label.</p>
<p>Here are the key findings from the <strong>Custom Model</strong> charts:</p>
<ul>
<li><p><strong>Label 0</strong>: As shown in the left chart, most of the words are closely related to sexism (e.g., ‘<strong>woman</strong>’, ‘<strong>sex</strong>’, ‘<strong>feminism</strong>’, ‘<strong>harassment</strong>’). In particular, the word ‘<strong>woman</strong>’ is not only the most frequently misclassified word but also the one with the highest misclassification rate compared to its overall occurrence in sentences.</p></li>
<li><p><strong>Label 1</strong>: As shown in the right chart, there is no single word particularly correlated with misclassifications for label 1, for instance ‘woman’ is by far the most frequent word in all sentences, it has a relatively low proportion of misclassifications compared to its total occurrences.</p></li>
</ul>
<p><strong>Final observations:</strong></p>
<p>This analysis suggests that the model may exhibit a bias, associating the word ‘<strong>woman</strong>’ strongly with sexism, regardless of the actual context. This bias could be influencing the model’s overall performance.</p>
<div id="cell-159" class="cell" data-outputid="aaca92bd-9430-40bc-f11e-e9e31f610add">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>plot_wrong_word(model_test_preds_hard, test_labels, decoded_test, <span class="st">'Custom Model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-84-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here are the key findings from the <strong>Transformer</strong> charts:</p>
<p><strong>Label 0</strong>: Similar to the Custom Model, most of the words are closely related to sexism. However, in the Transformer Model, the word ‘<strong>woman</strong>’ is again the most frequently misclassified word but with a slightly lower misclassification rate compared to its overall occurrence in sentences, suggesting the Transformer may handle this word marginally better than the Custom Model.</p>
<p><strong>Label 1</strong>: Unlike Label 0, there is no clear word strongly correlated with misclassifications. Words such as ‘<strong>like</strong>’, ‘<strong>look</strong>’, ‘<strong>get</strong>’ contribute the most to errors, but they are general-purpose words rather than terms specifically related to sexism. This indicates that, for label 1, the Transformer’s errors are not driven by any specific thematic words. The word ‘<strong>woman</strong>’ does not appear in the chart for label 1, meaning that it does not play an important role in the misclassifications for this label.</p>
<p><strong>Final Observations:</strong></p>
<p>This analysis reveals that the Transformer exhibits the same bias as the Custom Model, associating the word ‘woman’ strongly with sexism, regardless of the actual context.</p>
<div id="cell-161" class="cell" data-outputid="0ac7bf70-47c3-4bb1-d7bb-744a0ee9338d">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>plot_wrong_word(transformer_preds_hard, test_labels, decoded_test, <span class="st">'Transformer'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-85-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This consistent pattern across both models suggests that the bias may not originate from the models themselves but rather from the dataset.</p>
<p>If the dataset overrepresents the word ‘<strong>woman</strong>’ in contexts related to sexism, the models are likely to learn an inaccurate association between the word and sexist content. This imbalance might cause the models to incorrectly classify sentences containing ‘<strong>woman</strong>’, even when the context is neutral.</p>
<section id="correlation-analysis-woman-oov-and-unk-tokens" class="level3">
<h3 class="anchored" data-anchor-id="correlation-analysis-woman-oov-and-unk-tokens">Correlation Analysis: Woman, OOV and UNK tokens</h3>
<p>After identifying error patterns involving the word <strong>‘woman’</strong>, <strong>OOV tokens</strong>, and <strong>UNK tokens</strong>, we aim to test their significance by calculating their correlation with misclassification errors. This analysis will help determine whether these factors are strongly associated with errors or if their impact is less meaningful. Understanding these correlations is crucial for validating the observed patterns.</p>
<div id="cell-164" class="cell">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_correlation(</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>                     labels: np.ndarray,</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>                     predictions: np.ndarray,</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>                     sentences: List[List[<span class="bu">str</span>]],</span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>                     model_name: <span class="bu">str</span>,</span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a>                     oov_terms: List[<span class="bu">str</span>] <span class="op">=</span> []) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true" tabindex="-1"></a><span class="co">  Computes and plots correlations to highlight relevant patterns.</span></span>
<span id="cb127-9"><a href="#cb127-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-10"><a href="#cb127-10" aria-hidden="true" tabindex="-1"></a><span class="co">  :param labels: true labels (np.ndarray)</span></span>
<span id="cb127-11"><a href="#cb127-11" aria-hidden="true" tabindex="-1"></a><span class="co">  :param predictions: predictions of the model (np.ndarray)</span></span>
<span id="cb127-12"><a href="#cb127-12" aria-hidden="true" tabindex="-1"></a><span class="co">  :param sentences: input sentences (list)</span></span>
<span id="cb127-13"><a href="#cb127-13" aria-hidden="true" tabindex="-1"></a><span class="co">  :param model_name: name of the model for the plot title (str)</span></span>
<span id="cb127-14"><a href="#cb127-14" aria-hidden="true" tabindex="-1"></a><span class="co">  :param oov_terms: list of OOV terms (list)</span></span>
<span id="cb127-15"><a href="#cb127-15" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb127-16"><a href="#cb127-16" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> compute_correlation(label: <span class="bu">int</span>, ax: matplotlib.axes.Axes) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb127-17"><a href="#cb127-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-18"><a href="#cb127-18" aria-hidden="true" tabindex="-1"></a>    report <span class="op">=</span> pd.DataFrame(</span>
<span id="cb127-19"><a href="#cb127-19" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[</span>
<span id="cb127-20"><a href="#cb127-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"woman"</span>,</span>
<span id="cb127-21"><a href="#cb127-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"oov"</span>,</span>
<span id="cb127-22"><a href="#cb127-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"unk"</span>,</span>
<span id="cb127-23"><a href="#cb127-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"is_wrong"</span>,</span>
<span id="cb127-24"><a href="#cb127-24" aria-hidden="true" tabindex="-1"></a>      ]</span>
<span id="cb127-25"><a href="#cb127-25" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb127-26"><a href="#cb127-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-27"><a href="#cb127-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> enum, sentence <span class="kw">in</span> <span class="bu">enumerate</span>(sentences):</span>
<span id="cb127-28"><a href="#cb127-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-29"><a href="#cb127-29" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> labels[enum] <span class="op">==</span> label:</span>
<span id="cb127-30"><a href="#cb127-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-31"><a href="#cb127-31" aria-hidden="true" tabindex="-1"></a>        unk_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb127-32"><a href="#cb127-32" aria-hidden="true" tabindex="-1"></a>        oov_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb127-33"><a href="#cb127-33" aria-hidden="true" tabindex="-1"></a>        woman_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb127-34"><a href="#cb127-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-35"><a href="#cb127-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> sentence:</span>
<span id="cb127-36"><a href="#cb127-36" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> word <span class="op">==</span> <span class="st">"UNK"</span>:</span>
<span id="cb127-37"><a href="#cb127-37" aria-hidden="true" tabindex="-1"></a>              unk_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb127-38"><a href="#cb127-38" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> word <span class="kw">in</span> oov_terms:</span>
<span id="cb127-39"><a href="#cb127-39" aria-hidden="true" tabindex="-1"></a>              oov_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb127-40"><a href="#cb127-40" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> word <span class="op">==</span> <span class="st">'woman'</span>:</span>
<span id="cb127-41"><a href="#cb127-41" aria-hidden="true" tabindex="-1"></a>              woman_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb127-42"><a href="#cb127-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-43"><a href="#cb127-43" aria-hidden="true" tabindex="-1"></a>        is_wrong <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb127-44"><a href="#cb127-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> labels[enum] <span class="op">==</span> predictions[enum]:</span>
<span id="cb127-45"><a href="#cb127-45" aria-hidden="true" tabindex="-1"></a>          is_wrong <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb127-46"><a href="#cb127-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-47"><a href="#cb127-47" aria-hidden="true" tabindex="-1"></a>        report.loc[<span class="bu">len</span>(report)] <span class="op">=</span> [</span>
<span id="cb127-48"><a href="#cb127-48" aria-hidden="true" tabindex="-1"></a>            woman_count,</span>
<span id="cb127-49"><a href="#cb127-49" aria-hidden="true" tabindex="-1"></a>            oov_count,</span>
<span id="cb127-50"><a href="#cb127-50" aria-hidden="true" tabindex="-1"></a>            unk_count,</span>
<span id="cb127-51"><a href="#cb127-51" aria-hidden="true" tabindex="-1"></a>            is_wrong,</span>
<span id="cb127-52"><a href="#cb127-52" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb127-53"><a href="#cb127-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-54"><a href="#cb127-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">'Transformer'</span>:</span>
<span id="cb127-55"><a href="#cb127-55" aria-hidden="true" tabindex="-1"></a>      report <span class="op">=</span> report[[<span class="st">'woman'</span>,<span class="st">'is_wrong'</span>]]</span>
<span id="cb127-56"><a href="#cb127-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-57"><a href="#cb127-57" aria-hidden="true" tabindex="-1"></a>    corr <span class="op">=</span> report.corr()</span>
<span id="cb127-58"><a href="#cb127-58" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(corr, cmap<span class="op">=</span><span class="st">"Blues"</span>, annot<span class="op">=</span><span class="va">True</span>, ax <span class="op">=</span> ax,vmin<span class="op">=</span><span class="dv">0</span>,vmax<span class="op">=</span><span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb127-59"><a href="#cb127-59" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'Label </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb127-60"><a href="#cb127-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-61"><a href="#cb127-61" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb127-62"><a href="#cb127-62" aria-hidden="true" tabindex="-1"></a>  fig.suptitle(<span class="ss">f'</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> Correlation Matrices'</span>, weight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb127-63"><a href="#cb127-63" aria-hidden="true" tabindex="-1"></a>  compute_correlation(<span class="dv">0</span>, ax[<span class="dv">0</span>])</span>
<span id="cb127-64"><a href="#cb127-64" aria-hidden="true" tabindex="-1"></a>  compute_correlation(<span class="dv">1</span>, ax[<span class="dv">1</span>])</span>
<span id="cb127-65"><a href="#cb127-65" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The correlation matrix confirms the pattern seen earlier: the word ‘<strong>woman</strong>’ is positively correlated with errors in label 0 and negatively correlated with errors in label 1. This shows that the Custom Model tends to associate ‘<strong>woman</strong>’ with sexism in label 0 and is less likely to misclassify sentences with <strong>‘woman’</strong> in label 1.</p>
<p>On the other hand, UNK and OOV terms show no significant correlation with errors.</p>
<div id="cell-166" class="cell" data-outputid="9618a2b9-1ee7-4efa-eb27-90651b7c329f">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>plot_correlation(test_labels, model_test_preds_hard, decoded_test,<span class="st">'Custom Model'</span>, oov_terms)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-87-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The correlation matrix for the Transformer shows similar results to the Custom Model, with a slightly lower positive correlation with errors in label 0.</p>
<p>It does not include UNK and OOV terms because the Transformer model processes the input directly using its own tokenization. This structural difference simplifies the analysis, focusing only on the word ‘woman’ and its correlation with errors.</p>
<div id="cell-168" class="cell" data-outputid="d8e311bb-3338-4bab-b426-347c45c8ff75">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>plot_correlation(test_labels, transformer_preds_hard, decoded_test, <span class="st">'Transformer'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-88-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-169" class="cell" data-outputid="a2b2b92c-0825-4b0b-f101-dc1b6a4de4d5">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get OOV terms in wrong sentences of label 1</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>wrong_oov_1 <span class="op">=</span> [word  <span class="cf">for</span> i, sentence <span class="kw">in</span> <span class="bu">enumerate</span>(decoded_test) <span class="cf">for</span> word <span class="kw">in</span> sentence <span class="cf">if</span> test_labels[i] <span class="op">!=</span> model_test_preds_hard[i] <span class="kw">and</span> test_labels[i] <span class="op">==</span> <span class="dv">1</span> <span class="kw">and</span> word <span class="kw">in</span> oov_terms]</span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'OOV terms in misclassified sentences of label 1: </span><span class="sc">{</span><span class="bu">set</span>(wrong_oov_1)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>OOV terms in misclassified sentences of label 1: {'slutbag', 'gangbanged', 'phallogocentrism', 'phallocentrism', 'manspreading', 'mansplaining'}</code></pre>
</div>
</div>
<p>Actually we think that the weak correlation between OOV terms and misclassified sentences on label 1 is due to the fact that, as we have seen from the previous analyses, the most informative OOV terms were exclusively found in the misclassified sentences of label 1. So we will try to recompute the correlation focusing only on those terms (the ones in the list above).</p>
<div id="cell-171" class="cell" data-outputid="5d2a6081-cf5e-404d-e774-c15182eea04a">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>plot_correlation(test_labels, model_test_preds_hard, decoded_test,<span class="st">'Custom Model'</span>, wrong_oov_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-90-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As expected the correlation between OOV terms and misclassified sentences has increased, meaning that these terms are a source of error for label 1 sentences.</p>
<p>Given the two main error patterns identified in the previous analyses, we propose the following solutions:</p>
<ul>
<li><strong>‘woman’ pattern</strong>: addressing this issue would require refining the dataset, providing more diverse contextual examples, and/or applying bias mitigation strategies during training.</li>
<li><strong>OOV pattern</strong>: a possible solution could be trying to assign to these terms an embedding close to semantically similar words already present in our vocabulary, or implementing subword tokenization techniques.</li>
</ul>
</section>
</section>
<section id="mulitilingual-model" class="level2">
<h2 class="anchored" data-anchor-id="mulitilingual-model">Mulitilingual Model</h2>
<p>This section explores Spanish tweets using three different models: the two previously discussed models and a multilingual transformer. Since the test split of the dataset does not include Spanish tweets, we decided to evaluate performance on the validation set.</p>
<section id="custom-model" class="level3">
<h3 class="anchored" data-anchor-id="custom-model">Custom Model</h3>
<div id="cell-177" class="cell">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/main/2024-2025/Assignment%201/data/"</span></span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.read_json(url <span class="op">+</span> <span class="st">"training.json"</span>).T</span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>validation_df <span class="op">=</span> pd.read_json(url <span class="op">+</span> <span class="st">"validation.json"</span>).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-178" class="cell">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> corpus(train_df,multilingual<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>validation_df <span class="op">=</span> corpus(validation_df,multilingual<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-179" class="cell" data-outputid="8e4e9903-c359-4a8d-a41a-ac5c70de0148">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>validation_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">

  <div id="df-7923aa20-4bac-480e-b0a1-8e6bafa7bba2" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id_EXIST</th>
<th data-quarto-table-cell-role="th">lang</th>
<th data-quarto-table-cell-role="th">tweet</th>
<th data-quarto-table-cell-role="th">hard_label_task1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>300002</td>
<td>es</td>
<td>@anacaotica88 @MordorLivin No me acuerdo de lo...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>300003</td>
<td>es</td>
<td>@cosmicJunkBot lo digo cada pocos dias y lo re...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>300004</td>
<td>es</td>
<td>Also mientras les decia eso la señalaba y deci...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>300005</td>
<td>es</td>
<td>And all people killed, attacked, harassed by ...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>300006</td>
<td>es</td>
<td>On this #WorldPressFreedomDay I’m thinking of ...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">643</td>
<td>400172</td>
<td>en</td>
<td>@leesu44 @elishabroadway @markbann57 @SeaeyesT...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">644</td>
<td>400174</td>
<td>en</td>
<td>It is is impossible for a man to become a woma...</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">645</td>
<td>400175</td>
<td>en</td>
<td>If Gaga decided to sing 18 versions of Free Wo...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">646</td>
<td>400176</td>
<td>en</td>
<td>This is your reminder that you can be child-fr...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">647</td>
<td>400177</td>
<td>en</td>
<td>just completed my last final, i’m officially a...</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>648 rows × 4 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-7923aa20-4bac-480e-b0a1-8e6bafa7bba2')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-7923aa20-4bac-480e-b0a1-8e6bafa7bba2 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-7923aa20-4bac-480e-b0a1-8e6bafa7bba2');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-9997ef93-8653-4d24-b133-b6abfc1f5312">
  <button class="colab-df-quickchart" onclick="quickchart('df-9997ef93-8653-4d24-b133-b6abfc1f5312')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-9997ef93-8653-4d24-b133-b6abfc1f5312 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_2c9e2d0e-1e7c-4366-8410-e0dad5f84506">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('validation_df')" title="Generate code using this dataframe." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"></path>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_2c9e2d0e-1e7c-4366-8410-e0dad5f84506 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('validation_df');
      }
      })();
    </script>
  </div>

    </div>
  </div>
</div>
</div>
<p>Once we introduced Spanish tweets into the dataset, the labels became more balanced than before, especially in the validation set.</p>
<div id="cell-181" class="cell" data-outputid="beccfd5b-a709-443d-e67c-388646aee896">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>plot_data_distribution(train_df, ax[<span class="dv">0</span>], <span class="st">"train"</span>)</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>plot_data_distribution(validation_df, ax[<span class="dv">1</span>], <span class="st">"validation"</span>)</span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-94-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-182" class="cell" data-outputid="e0009d41-ddce-4266-fd4e-0d788ee7adfa">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of english tweet in train set: </span><span class="sc">{</span><span class="bu">len</span>(train_df[train_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"en"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of spanish tweet in train set: </span><span class="sc">{</span><span class="bu">len</span>(train_df[train_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"es"</span>])<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb137-3"><a href="#cb137-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb137-4"><a href="#cb137-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of english tweet in validation set: </span><span class="sc">{</span><span class="bu">len</span>(validation_df[validation_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"en"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb137-5"><a href="#cb137-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of spanish tweet in validation set: </span><span class="sc">{</span><span class="bu">len</span>(validation_df[validation_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"es"</span>])<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of english tweet in train set: 2870
Number of spanish tweet in train set: 3194

Number of english tweet in validation set: 158
Number of spanish tweet in validation set: 490</code></pre>
</div>
</div>
<div id="cell-183" class="cell">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>PREPROCESSING_PIPELINE <span class="op">=</span> [</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>    remove_emojis,</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>    remove_hashtags,</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>    remove_mentions,</span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>    remove_urls,</span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a>    remove_special_chars,</span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a>    lower,</span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"tweet"</span>] <span class="op">=</span> train_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> txt: text_prepare(txt))</span>
<span id="cb139-10"><a href="#cb139-10" aria-hidden="true" tabindex="-1"></a>validation_df[<span class="st">"tweet"</span>] <span class="op">=</span> validation_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> txt: text_prepare(txt))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-184" class="cell">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>train_df.to_csv(<span class="st">'train_multilingual.csv'</span>)</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>validation_df.to_csv(<span class="st">'validation_multilingual.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For the lemmatization part, we could not use the WordNet Lemmatizer as it is designed exclusively for English. Therefore, we decided to adopt the <strong>Spacy Lemmatizer</strong>, which supports both English and Spanish sentences.</p>
<div id="cell-186" class="cell">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>nlp_en <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>)</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>nlp_es <span class="op">=</span> spacy.load(<span class="st">"es_core_news_sm"</span>)</span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-4"><a href="#cb141-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_tweet(row: pd.Series) <span class="op">-&gt;</span> pd.Series:</span>
<span id="cb141-5"><a href="#cb141-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb141-6"><a href="#cb141-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Tokenizes and lemmatizes the given tweet based on the specified language.</span></span>
<span id="cb141-7"><a href="#cb141-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-8"><a href="#cb141-8" aria-hidden="true" tabindex="-1"></a><span class="co">    :param row: row of a DataFrame (pd.Series)</span></span>
<span id="cb141-9"><a href="#cb141-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-10"><a href="#cb141-10" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: tokenized and lemmatized tweet (List[str])</span></span>
<span id="cb141-11"><a href="#cb141-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb141-12"><a href="#cb141-12" aria-hidden="true" tabindex="-1"></a>    nlp <span class="op">=</span> nlp_en <span class="cf">if</span> row[<span class="st">'lang'</span>] <span class="op">==</span> <span class="st">"en"</span> <span class="cf">else</span> nlp_es</span>
<span id="cb141-13"><a href="#cb141-13" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> nlp(row[<span class="st">'tweet'</span>])</span>
<span id="cb141-14"><a href="#cb141-14" aria-hidden="true" tabindex="-1"></a>    row[<span class="st">'tweet'</span>] <span class="op">=</span> [token.lemma_ <span class="cf">for</span> token <span class="kw">in</span> doc <span class="cf">if</span> <span class="kw">not</span> token.is_space]</span>
<span id="cb141-15"><a href="#cb141-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> row</span>
<span id="cb141-16"><a href="#cb141-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-17"><a href="#cb141-17" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> train_df.<span class="bu">apply</span>(tokenize_tweet,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb141-18"><a href="#cb141-18" aria-hidden="true" tabindex="-1"></a>validation_df <span class="op">=</span> validation_df.<span class="bu">apply</span>(tokenize_tweet,axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-187" class="cell" data-outputid="deeae046-fe08-44d3-e18a-6c80afffeaa2">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>idx_to_word, word_to_idx, word_listing <span class="op">=</span> build_vocabulary(train_df)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">[Debug] Index -&gt; Word vocabulary size: </span><span class="sc">{</span><span class="bu">len</span>(idx_to_word)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[Debug] Word -&gt; Index vocabulary size: </span><span class="sc">{</span><span class="bu">len</span>(word_to_idx)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[Debug] Some words: </span><span class="sc">{</span>[(idx_to_word[idx], idx) <span class="cf">for</span> idx <span class="kw">in</span> np.arange(<span class="dv">20</span>)]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 6064/6064 [00:00&lt;00:00, 118996.81it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
[Debug] Index -&gt; Word vocabulary size: 19132
[Debug] Word -&gt; Index vocabulary size: 19132
[Debug] Some words: [('PAD', 0), ('UNK', 1), ('ignorar', 2), ('al', 3), ('otro', 4), ('ser', 5), ('uno', 6), ('capullo', 7), ('el', 8), ('problema', 9), ('con', 10), ('este', 11), ('youtuber', 12), ('denunciar', 13), ('acoso', 14), ('cuando', 15), ('no', 16), ('afectar', 17), ('a', 18), ('gente', 19)]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<p>We decided to use <strong>GloVe-Twitter</strong>, a specialized version of GloVe, because it includes a larger vocabulary compared to the previously used version, particularly providing embeddings for many Spanish words.</p>
<div id="cell-189" class="cell">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>embedding_dimension <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> gloader.load(<span class="ss">f"glove-twitter-</span><span class="sc">{</span>embedding_dimension<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-190" class="cell" data-outputid="63774915-9160-4e67-9fd6-3bad454a9a22">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>embedding_matrix <span class="op">=</span> build_embedding_matrix(</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>    embedding_model, embedding_dimension, word_to_idx, <span class="bu">len</span>(word_to_idx)</span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Embedding matrix shape: </span><span class="sc">{</span>embedding_matrix<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 19132/19132 [00:00&lt;00:00, 130848.23it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Embedding matrix shape: (19132, 200)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<div id="cell-191" class="cell" data-outputid="ff97e6d5-c779-423d-b07b-46a29798c05f">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>oov_terms <span class="op">=</span> check_OOV_terms(embedding_model, word_listing)</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>oov_percentage <span class="op">=</span> <span class="bu">float</span>(<span class="bu">len</span>(oov_terms)) <span class="op">*</span> <span class="dv">100</span> <span class="op">/</span> <span class="bu">len</span>(word_listing)</span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total OOV terms: </span><span class="sc">{</span><span class="bu">len</span>(oov_terms)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>oov_percentage<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total OOV terms: 3495 (18.27%)</code></pre>
</div>
</div>
<div id="cell-192" class="cell">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>validation_df[<span class="st">"tweet"</span>] <span class="op">=</span> validation_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(put_unk)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-193" class="cell" data-outputid="925b8e9e-a83a-4a14-dbb7-fbaabf8bf440">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>max_train_length <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(tweet) <span class="cf">for</span> tweet <span class="kw">in</span> train_df[<span class="st">"tweet"</span>])</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>max_validation_length <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(tweet) <span class="cf">for</span> tweet <span class="kw">in</span> validation_df[<span class="st">"tweet"</span>])</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>max_sequence_lenght <span class="op">=</span> <span class="bu">max</span>(max_train_length, max_validation_length)</span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max sequence lenght in train set: </span><span class="sc">{</span>max_train_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max sequence lenght in validation set: </span><span class="sc">{</span>max_validation_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max sequence lenght: </span><span class="sc">{</span>max_sequence_lenght<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Max sequence lenght in train set: 62
Max sequence lenght in validation set: 61
Max sequence lenght: 62</code></pre>
</div>
</div>
<div id="cell-194" class="cell">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"tweet"</span>] <span class="op">=</span> train_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(pad_tweet)</span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>validation_df[<span class="st">"tweet"</span>] <span class="op">=</span> validation_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(pad_tweet)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-195" class="cell">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"tweet"</span>] <span class="op">=</span> train_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(word_to_num)</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>validation_df[<span class="st">"tweet"</span>] <span class="op">=</span> validation_df[<span class="st">"tweet"</span>].<span class="bu">apply</span>(word_to_num)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-196" class="cell">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>train_sentences, train_labels <span class="op">=</span> format_data(</span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a>    train_df[<span class="st">"tweet"</span>], train_df[<span class="st">"hard_label_task1"</span>]</span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb158-4"><a href="#cb158-4" aria-hidden="true" tabindex="-1"></a>validation_sentences, validation_labels <span class="op">=</span> format_data(</span>
<span id="cb158-5"><a href="#cb158-5" aria-hidden="true" tabindex="-1"></a>    validation_df[<span class="st">"tweet"</span>], validation_df[<span class="st">"hard_label_task1"</span>]</span>
<span id="cb158-6"><a href="#cb158-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-197" class="cell">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>categorical_train_labels <span class="op">=</span> tf.keras.utils.to_categorical(train_labels, num_classes<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>categorical_validation_labels <span class="op">=</span> tf.keras.utils.to_categorical(</span>
<span id="cb159-3"><a href="#cb159-3" aria-hidden="true" tabindex="-1"></a>    validation_labels, num_classes<span class="op">=</span><span class="dv">2</span></span>
<span id="cb159-4"><a href="#cb159-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-198" class="cell">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>best_seed <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> get_model(add_lstm<span class="op">=</span><span class="va">False</span>, vocab_size<span class="op">=</span><span class="bu">len</span>(word_listing))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-199" class="cell">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>set_reproducibility(best_seed)</span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_model.name <span class="op">==</span> <span class="st">"Baseline"</span>:</span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>    multilingual_model <span class="op">=</span> get_model(add_lstm<span class="op">=</span><span class="va">False</span>, vocab_size<span class="op">=</span><span class="bu">len</span>(word_listing))</span>
<span id="cb161-5"><a href="#cb161-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb161-6"><a href="#cb161-6" aria-hidden="true" tabindex="-1"></a>    multilingual_model <span class="op">=</span> get_model(add_lstm<span class="op">=</span><span class="va">True</span>, vocab_size<span class="op">=</span><span class="bu">len</span>(word_listing))</span>
<span id="cb161-7"><a href="#cb161-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb161-8"><a href="#cb161-8" aria-hidden="true" tabindex="-1"></a>multilingual_model, _, _, _, _<span class="op">=</span> train_loop(multilingual_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-200" class="cell" data-outputid="e83409ed-d8d1-4c08-d569-1ff9ae72169c">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>validation_preds <span class="op">=</span> np.argmax(multilingual_model(validation_sentences), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(validation_labels, validation_preds, digits<span class="op">=</span><span class="dv">3</span>))</span>
<span id="cb162-3"><a href="#cb162-3" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(validation_labels, validation_preds)</span>
<span id="cb162-4"><a href="#cb162-4" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(cm)</span>
<span id="cb162-5"><a href="#cb162-5" aria-hidden="true" tabindex="-1"></a>disp.plot()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0      0.718     0.806     0.759       319
           1      0.786     0.693     0.737       329

    accuracy                          0.748       648
   macro avg      0.752     0.749     0.748       648
weighted avg      0.753     0.748     0.748       648
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-111-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-201" class="cell" data-outputid="48c43c52-023b-4fbd-8322-8d7035772112">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_misclassified_sentences(df: pd.DataFrame, preds: List[<span class="bu">int</span>],labels: List[<span class="bu">int</span>]) <span class="op">-&gt;</span> Tuple[<span class="bu">int</span>, <span class="bu">int</span>, <span class="bu">int</span>]:</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a>  count_total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a>  count_en <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a>  count_es <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, pred <span class="kw">in</span> <span class="bu">enumerate</span>(preds):</span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pred <span class="op">!=</span> labels[i]:</span>
<span id="cb164-8"><a href="#cb164-8" aria-hidden="true" tabindex="-1"></a>      count_total <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb164-9"><a href="#cb164-9" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> df.iloc[i][<span class="st">'lang'</span>] <span class="op">==</span> <span class="st">'en'</span>:</span>
<span id="cb164-10"><a href="#cb164-10" aria-hidden="true" tabindex="-1"></a>        count_en <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb164-11"><a href="#cb164-11" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>:</span>
<span id="cb164-12"><a href="#cb164-12" aria-hidden="true" tabindex="-1"></a>        count_es <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb164-13"><a href="#cb164-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> count_total, count_en, count_es</span>
<span id="cb164-14"><a href="#cb164-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-15"><a href="#cb164-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-16"><a href="#cb164-16" aria-hidden="true" tabindex="-1"></a>count_total, count_en, count_es <span class="op">=</span> count_misclassified_sentences(validation_df,validation_preds,validation_labels)</span>
<span id="cb164-17"><a href="#cb164-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Total misclassified sentences: </span><span class="sc">{</span>count_total<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb164-18"><a href="#cb164-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Misclassified sentences in English: </span><span class="sc">{</span>count_en<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb164-19"><a href="#cb164-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Misclassified sentences in Spanish: </span><span class="sc">{</span>count_es<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total misclassified sentences: 163
Misclassified sentences in English: 28
Misclassified sentences in Spanish: 135</code></pre>
</div>
</div>
<div id="cell-202" class="cell" data-outputid="546dcb06-91dc-4a9a-c225-6a0eeaba4405">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>decoded_validation <span class="op">=</span> custom_decode(validation_sentences)</span>
<span id="cb166-2"><a href="#cb166-2" aria-hidden="true" tabindex="-1"></a>plot_unk_stats(validation_preds, validation_labels, decoded_validation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Statistics of UNK and OOV terms of Custom Model
</code></pre>
</div>
<div class="cell-output cell-output-display">

  <div id="df-5fd4cd51-f913-455e-95c9-1e7e57b5eeac" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">Sentences</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">UNK</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">OOV</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Total</th>
<th data-quarto-table-cell-role="th">Wrong</th>
<th data-quarto-table-cell-role="th">Total</th>
<th data-quarto-table-cell-role="th">Wrong</th>
<th data-quarto-table-cell-role="th">Total</th>
<th data-quarto-table-cell-role="th">Wrong</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>319</td>
<td>62</td>
<td>735</td>
<td>149</td>
<td>204</td>
<td>37</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>329</td>
<td>101</td>
<td>648</td>
<td>228</td>
<td>212</td>
<td>64</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-5fd4cd51-f913-455e-95c9-1e7e57b5eeac')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-5fd4cd51-f913-455e-95c9-1e7e57b5eeac button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-5fd4cd51-f913-455e-95c9-1e7e57b5eeac');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-4e306d03-80d4-4bd0-a00b-52aeeb1edfb5">
  <button class="colab-df-quickchart" onclick="quickchart('df-4e306d03-80d4-4bd0-a00b-52aeeb1edfb5')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-4e306d03-80d4-4bd0-a00b-52aeeb1edfb5 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<p>As we can see, the most common words in the misclassified sentences are predominantly Spanish, due to the fact that Spanish sentences are more prevalent than English ones in the validation split. Moreover, we observe a similar pattern to the previous error analysis with the word <strong>‘woman’</strong>. Specifically, the Spanish equivalent, <strong>‘mujer’</strong>, is the most frequent word in misclassified sentences with label 0 and, while it is the overall most frequent word in label 1, it appears rarely in misclassified sentences for that label.</p>
<div id="cell-204" class="cell" data-outputid="76022549-45e2-4215-fd0f-1b08edb5ab85">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>plot_wrong_word(validation_preds, validation_labels, decoded_validation, <span class="st">'Custom Model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-114-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="transformer" class="level3">
<h3 class="anchored" data-anchor-id="transformer">Transformer</h3>
<p>Now we will fine-tune the same transformer architecture used earlier in the monolingual section, adopting the same preprocessing procedure and training hyperparameters. As expected, the performance on the validation set dropped slightly, likely because this architecture was mostly pretrained on English text.</p>
<div id="cell-207" class="cell">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"cardiffnlp/twitter-roberta-base-hate"</span></span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb169-3"><a href="#cb169-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb169-4"><a href="#cb169-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb169-5"><a href="#cb169-5" aria-hidden="true" tabindex="-1"></a>    model_name, ignore_mismatched_sizes<span class="op">=</span><span class="va">True</span></span>
<span id="cb169-6"><a href="#cb169-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-208" class="cell" data-outputid="ccbdf625-7264-4e61-c734-844392a97c4e">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> datasets.load_dataset(</span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"csv"</span>,</span>
<span id="cb170-3"><a href="#cb170-3" aria-hidden="true" tabindex="-1"></a>    data_files<span class="op">=</span>{</span>
<span id="cb170-4"><a href="#cb170-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train"</span>: <span class="st">"train_multilingual.csv"</span>,</span>
<span id="cb170-5"><a href="#cb170-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"validation"</span>: <span class="st">"validation_multilingual.csv"</span>,</span>
<span id="cb170-6"><a href="#cb170-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb170-7"><a href="#cb170-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb170-8"><a href="#cb170-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.<span class="bu">map</span>(preprocess_text, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb170-9"><a href="#cb170-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.rename_column(<span class="st">"hard_label_task1"</span>, <span class="st">"label"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a4aec7edd10144aea955313f4eecef51","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ecc5a753fca84b1da7842869a2f11c5b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8c331900e99445009e36a249d2461122","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f4666e88f0614a85ba5c8ba52c235a09","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div id="cell-209" class="cell">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="st">'classifier'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'encoder.layer.10'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'encoder.layer.11'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'encoder.layer.9'</span> <span class="kw">in</span> name:</span>
<span id="cb172-3"><a href="#cb172-3" aria-hidden="true" tabindex="-1"></a>    param.requires_grad <span class="op">=</span> <span class="va">True</span></span>
<span id="cb172-4"><a href="#cb172-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb172-5"><a href="#cb172-5" aria-hidden="true" tabindex="-1"></a>    param.requires_grad <span class="op">=</span> <span class="va">False</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-210" class="cell">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"test_dir"</span>,</span>
<span id="cb173-3"><a href="#cb173-3" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="cb173-4"><a href="#cb173-4" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb173-5"><a href="#cb173-5" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb173-6"><a href="#cb173-6" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb173-7"><a href="#cb173-7" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb173-8"><a href="#cb173-8" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb173-9"><a href="#cb173-9" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb173-10"><a href="#cb173-10" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb173-11"><a href="#cb173-11" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb173-12"><a href="#cb173-12" aria-hidden="true" tabindex="-1"></a>    metric_for_best_model<span class="op">=</span><span class="st">"loss"</span>,</span>
<span id="cb173-13"><a href="#cb173-13" aria-hidden="true" tabindex="-1"></a>    greater_is_better<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb173-14"><a href="#cb173-14" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span>best_seed,</span>
<span id="cb173-15"><a href="#cb173-15" aria-hidden="true" tabindex="-1"></a>    logging_strategy<span class="op">=</span><span class="st">'epoch'</span></span>
<span id="cb173-16"><a href="#cb173-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-211" class="cell">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb174-4"><a href="#cb174-4" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb174-5"><a href="#cb174-5" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb174-6"><a href="#cb174-6" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>data[<span class="st">"train"</span>],</span>
<span id="cb174-7"><a href="#cb174-7" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>data[<span class="st">"validation"</span>],</span>
<span id="cb174-8"><a href="#cb174-8" aria-hidden="true" tabindex="-1"></a>    processing_class<span class="op">=</span>tokenizer,</span>
<span id="cb174-9"><a href="#cb174-9" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,</span>
<span id="cb174-10"><a href="#cb174-10" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb174-11"><a href="#cb174-11" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[EarlyStoppingCallback(early_stopping_patience<span class="op">=</span><span class="dv">3</span>)]</span>
<span id="cb174-12"><a href="#cb174-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-212" class="cell" data-outputid="13d4c6f9-0129-44d7-d30c-2cd8233225a2">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>validation_info <span class="op">=</span> trainer.predict(data[<span class="st">"validation"</span>])</span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>y_pred_transformer, y_true <span class="op">=</span> validation_info.predictions, validation_info.label_ids</span>
<span id="cb175-3"><a href="#cb175-3" aria-hidden="true" tabindex="-1"></a>validation_metrics <span class="op">=</span> compute_metrics([y_pred_transformer, y_true])</span>
<span id="cb175-4"><a href="#cb175-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb175-5"><a href="#cb175-5" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'Transformer pre-finetuning validation f1_score </span><span class="sc">{</span>validation_metrics[<span class="st">"f1"</span>]<span class="sc">:.4f}</span><span class="ss">, accuracy </span><span class="sc">{</span>validation_metrics[<span class="st">"acc"</span>]<span class="sc">:.4f}</span><span class="ss">'</span></span>
<span id="cb175-6"><a href="#cb175-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>Transformer pre-finetuning validation f1_score 0.3731, accuracy 0.5093</code></pre>
</div>
</div>
<div id="cell-213" class="cell" data-outputid="f45e6d76-7f8c-490a-b8e0-536752ca1994">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>validation_pred_transformer <span class="op">=</span> np.argmax(softmax(y_pred_transformer,axis<span class="op">=</span><span class="dv">1</span>),axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb177-3"><a href="#cb177-3" aria-hidden="true" tabindex="-1"></a>count_total, count_en, count_es <span class="op">=</span> count_misclassified_sentences(validation_df,validation_pred_transformer,y_true)</span>
<span id="cb177-4"><a href="#cb177-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Total misclassified sentences: </span><span class="sc">{</span>count_total<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb177-5"><a href="#cb177-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Misclassified sentences in English: </span><span class="sc">{</span>count_en<span class="sc">}</span><span class="ss"> out of </span><span class="sc">{</span><span class="bu">len</span>(validation_df[validation_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"en"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb177-6"><a href="#cb177-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Misclassified sentences in Spanish: </span><span class="sc">{</span>count_es<span class="sc">}</span><span class="ss"> out of </span><span class="sc">{</span><span class="bu">len</span>(validation_df[validation_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"es"</span>])<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total misclassified sentences: 318
Misclassified sentences in English: 58 out of 158
Misclassified sentences in Spanish: 260 out of 490</code></pre>
</div>
</div>
<div id="cell-214" class="cell" data-outputid="b0eda168-fdbb-4b6e-ed1d-bf558ab32d27">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="4548" max="7580" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [4548/7580 08:09 &lt; 05:26, 9.29 it/s, Epoch 6/10]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">Model Preparation Time</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Acc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.524200</td>
<td>0.501840</td>
<td>0.003700</td>
<td>0.760674</td>
<td>0.760802</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.455300</td>
<td>0.508893</td>
<td>0.003700</td>
<td>0.760426</td>
<td>0.762346</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.422200</td>
<td>0.486943</td>
<td>0.003700</td>
<td>0.808525</td>
<td>0.808642</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.379600</td>
<td>0.500273</td>
<td>0.003700</td>
<td>0.795968</td>
<td>0.796296</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.346000</td>
<td>0.551903</td>
<td>0.003700</td>
<td>0.817899</td>
<td>0.817901</td>
</tr>
<tr class="even">
<td>6</td>
<td>0.311200</td>
<td>0.662030</td>
<td>0.003700</td>
<td>0.802401</td>
<td>0.802469</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="123">
<pre><code>TrainOutput(global_step=4548, training_loss=0.40640132303497933, metrics={'train_runtime': 489.5987, 'train_samples_per_second': 123.857, 'train_steps_per_second': 15.482, 'total_flos': 1693760974439040.0, 'train_loss': 0.40640132303497933, 'epoch': 6.0})</code></pre>
</div>
</div>
<div id="cell-215" class="cell" data-outputid="910707e0-f50e-4615-aa99-d078b1c2ba6f">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>validation_info <span class="op">=</span> trainer.predict(data[<span class="st">"validation"</span>])</span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>y_pred_transformer, y_true <span class="op">=</span> validation_info.predictions, validation_info.label_ids</span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a>validation_metrics <span class="op">=</span> compute_metrics([y_pred_transformer, y_true])</span>
<span id="cb181-4"><a href="#cb181-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb181-5"><a href="#cb181-5" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'Transformer best validation f1_score </span><span class="sc">{</span>validation_metrics[<span class="st">"f1"</span>]<span class="sc">:.4f}</span><span class="ss">, accuracy </span><span class="sc">{</span>validation_metrics[<span class="st">"acc"</span>]<span class="sc">:.4f}</span><span class="ss">'</span></span>
<span id="cb181-6"><a href="#cb181-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>Transformer best validation f1_score 0.8085, accuracy 0.8086</code></pre>
</div>
</div>
<div id="cell-216" class="cell" data-outputid="637a65ad-1224-4ed5-fdc7-4ec7e9284e6c">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>validation_pred_transformer <span class="op">=</span> np.argmax(softmax(y_pred_transformer,axis<span class="op">=</span><span class="dv">1</span>),axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-3"><a href="#cb183-3" aria-hidden="true" tabindex="-1"></a>count_total, count_en, count_es <span class="op">=</span> count_misclassified_sentences(validation_df,validation_pred_transformer,y_true)</span>
<span id="cb183-4"><a href="#cb183-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Total misclassified sentences: </span><span class="sc">{</span>count_total<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb183-5"><a href="#cb183-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Misclassified sentences in English: </span><span class="sc">{</span>count_en<span class="sc">}</span><span class="ss"> out of </span><span class="sc">{</span><span class="bu">len</span>(validation_df[validation_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"en"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb183-6"><a href="#cb183-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Misclassified sentences in Spanish: </span><span class="sc">{</span>count_es<span class="sc">}</span><span class="ss"> out of </span><span class="sc">{</span><span class="bu">len</span>(validation_df[validation_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"es"</span>])<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total misclassified sentences: 124
Misclassified sentences in English: 17 out of 158
Misclassified sentences in Spanish: 107 out of 490</code></pre>
</div>
</div>
<div id="cell-217" class="cell" data-outputid="32875744-4b6a-4a0a-fe4c-e399266da502">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(validation_labels, validation_pred_transformer, digits<span class="op">=</span><span class="dv">3</span>))</span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(validation_labels, validation_pred_transformer)</span>
<span id="cb185-3"><a href="#cb185-3" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(cm)</span>
<span id="cb185-4"><a href="#cb185-4" aria-hidden="true" tabindex="-1"></a>disp.plot()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0      0.812     0.796     0.804       319
           1      0.806     0.821     0.813       329

    accuracy                          0.809       648
   macro avg      0.809     0.808     0.809       648
weighted avg      0.809     0.809     0.809       648
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-125-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In the chart below we observe the same pattern previously identified in the custom model regarding the word <strong>‘mujer’</strong>. In this case <strong>‘mujer’</strong> does not appear in the right chart, indicating that it is rarely misclassified in label 1 sentences.</p>
<div id="cell-219" class="cell" data-outputid="b0961951-ec99-421c-ce4b-1c6cef297468">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>plot_wrong_word(validation_pred_transformer, validation_labels, decoded_validation, <span class="st">'Transformer'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-126-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="transformer-multilingual" class="level3">
<h3 class="anchored" data-anchor-id="transformer-multilingual">Transformer Multilingual</h3>
<p>Now we will compare the previous models with the following one, which is also a Transformer-based architecture but pretrained on <strong>multilingual</strong> corpora. Since this model was originally trained for multiclass classification (3 labels), we replaced and fine-tuned the final classification head to adapt it to our binary classification task.</p>
<div id="cell-222" class="cell" data-outputid="b410ccaa-fabf-4984-b3d2-d97038edb5fa">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual"</span></span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb188-4"><a href="#cb188-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb188-5"><a href="#cb188-5" aria-hidden="true" tabindex="-1"></a>    model_name, num_labels<span class="op">=</span><span class="dv">2</span>, ignore_mismatched_sizes<span class="op">=</span><span class="va">True</span></span>
<span id="cb188-6"><a href="#cb188-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual and are newly initialized because the shapes did not match:
- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated
- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<div id="cell-223" class="cell" data-outputid="0681df97-31d9-4907-90ab-4869d6d90424">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> datasets.load_dataset(</span>
<span id="cb190-2"><a href="#cb190-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"csv"</span>,</span>
<span id="cb190-3"><a href="#cb190-3" aria-hidden="true" tabindex="-1"></a>    data_files<span class="op">=</span>{</span>
<span id="cb190-4"><a href="#cb190-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train"</span>: <span class="st">"train_multilingual.csv"</span>,</span>
<span id="cb190-5"><a href="#cb190-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"validation"</span>: <span class="st">"validation_multilingual.csv"</span>,</span>
<span id="cb190-6"><a href="#cb190-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb190-7"><a href="#cb190-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb190-8"><a href="#cb190-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.<span class="bu">map</span>(preprocess_text, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb190-9"><a href="#cb190-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.rename_column(<span class="st">"hard_label_task1"</span>, <span class="st">"label"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"259f99b80e224dda81009b8ddf39b9fb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6f6796b65baf49f39ed06893eb691c06","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div id="cell-224" class="cell">
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb192-2"><a href="#cb192-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb192-3"><a href="#cb192-3" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb192-4"><a href="#cb192-4" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb192-5"><a href="#cb192-5" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb192-6"><a href="#cb192-6" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>data[<span class="st">"train"</span>],</span>
<span id="cb192-7"><a href="#cb192-7" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>data[<span class="st">"validation"</span>],</span>
<span id="cb192-8"><a href="#cb192-8" aria-hidden="true" tabindex="-1"></a>    processing_class<span class="op">=</span>tokenizer,</span>
<span id="cb192-9"><a href="#cb192-9" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,</span>
<span id="cb192-10"><a href="#cb192-10" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb192-11"><a href="#cb192-11" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[EarlyStoppingCallback(early_stopping_patience<span class="op">=</span><span class="dv">3</span>)]</span>
<span id="cb192-12"><a href="#cb192-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-225" class="cell" data-outputid="90590545-5969-4942-ed9b-04c54f0a2436">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="3032" max="7580" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [3032/7580 13:42 &lt; 20:34, 3.68 it/s, Epoch 4/10]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Acc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.472000</td>
<td>0.404488</td>
<td>0.856193</td>
<td>0.856481</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.366600</td>
<td>0.599462</td>
<td>0.825397</td>
<td>0.825617</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.270100</td>
<td>0.573474</td>
<td>0.836418</td>
<td>0.836420</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.156300</td>
<td>1.179024</td>
<td>0.801351</td>
<td>0.804012</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="131">
<pre><code>TrainOutput(global_step=3032, training_loss=0.31624828731164456, metrics={'train_runtime': 822.6802, 'train_samples_per_second': 73.71, 'train_steps_per_second': 9.214, 'total_flos': 779186946007680.0, 'train_loss': 0.31624828731164456, 'epoch': 4.0})</code></pre>
</div>
</div>
<div id="cell-226" class="cell" data-outputid="35a12eb1-7bed-437a-bc29-b4799c8e7718">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>validation_info <span class="op">=</span> trainer.predict(data[<span class="st">"validation"</span>])</span>
<span id="cb195-2"><a href="#cb195-2" aria-hidden="true" tabindex="-1"></a>y_pred_transformer, y_true <span class="op">=</span> validation_info.predictions, validation_info.label_ids</span>
<span id="cb195-3"><a href="#cb195-3" aria-hidden="true" tabindex="-1"></a>validation_metrics <span class="op">=</span> compute_metrics([y_pred_transformer, y_true])</span>
<span id="cb195-4"><a href="#cb195-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb195-5"><a href="#cb195-5" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'Transformer validation f1_score </span><span class="sc">{</span>validation_metrics[<span class="st">"f1"</span>]<span class="sc">:.4f}</span><span class="ss">, accuracy </span><span class="sc">{</span>validation_metrics[<span class="st">"acc"</span>]<span class="sc">:.4f}</span><span class="ss">'</span></span>
<span id="cb195-6"><a href="#cb195-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>Transformer validation f1_score 0.8562, accuracy 0.8565</code></pre>
</div>
</div>
<div id="cell-227" class="cell" data-outputid="a2992262-7b74-4a67-c47b-82ff8346be1a">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>validation_pred_transformer <span class="op">=</span> np.argmax(softmax(y_pred_transformer,axis<span class="op">=</span><span class="dv">1</span>),axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb197-3"><a href="#cb197-3" aria-hidden="true" tabindex="-1"></a>count_total, count_en, count_es <span class="op">=</span> count_misclassified_sentences(validation_df,validation_pred_transformer,y_true)</span>
<span id="cb197-4"><a href="#cb197-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Total misclassified sentences: </span><span class="sc">{</span>count_total<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb197-5"><a href="#cb197-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Misclassified sentences in English: </span><span class="sc">{</span>count_en<span class="sc">}</span><span class="ss"> out of </span><span class="sc">{</span><span class="bu">len</span>(validation_df[validation_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"en"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb197-6"><a href="#cb197-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Misclassified sentences in Spanish: </span><span class="sc">{</span>count_es<span class="sc">}</span><span class="ss"> out of </span><span class="sc">{</span><span class="bu">len</span>(validation_df[validation_df[<span class="st">"lang"</span>] <span class="op">==</span> <span class="st">"es"</span>])<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total misclassified sentences: 93
Misclassified sentences in English: 21 out of 158
Misclassified sentences in Spanish: 72 out of 490</code></pre>
</div>
</div>
<div id="cell-228" class="cell" data-outputid="cb3a03a5-2687-4627-8257-b8f3d6f7b05a">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(validation_labels, validation_pred_transformer, digits<span class="op">=</span><span class="dv">3</span>))</span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(validation_labels, validation_pred_transformer)</span>
<span id="cb199-3"><a href="#cb199-3" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(cm)</span>
<span id="cb199-4"><a href="#cb199-4" aria-hidden="true" tabindex="-1"></a>disp.plot()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0      0.877     0.824     0.850       319
           1      0.839     0.888     0.863       329

    accuracy                          0.856       648
   macro avg      0.858     0.856     0.856       648
weighted avg      0.858     0.856     0.856       648
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-133-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-229" class="cell" data-outputid="9442a3ef-f7ab-4123-df2c-ae6fa2b11be6">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>plot_wrong_word(validation_pred_transformer, validation_labels, decoded_validation, <span class="st">'Transformer'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="assignment_1_baiocchi_dibuo_petrilli_files/figure-html/cell-134-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As previously shown, the model’s performance is <strong>significantly better</strong> than that of the two previous models. Additionally, unlike the other models, the ratio of misclassified sentences is consistent across languages. Lastly we observe the same ‘mujer’ error pattern in the charts above.</p>
</section>
</section>
</section>
<section id="task-8---0.5-points-report" class="level1">
<h1>[Task 8 - 0.5 points] Report</h1>
<p>Wrap up your experiment in a short report (up to 2 pages).</p>
<section id="instructions-7" class="level3">
<h3 class="anchored" data-anchor-id="instructions-7">Instructions</h3>
<ul>
<li>Use the NLP course report template.</li>
<li>Summarize each task in the report following the provided template.</li>
</ul>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<p>The report is not a copy-paste of graphs, tables, and command outputs.</p>
<ul>
<li>Summarize classification performance in Table format.</li>
<li><strong>Do not</strong> report command outputs or screenshots.</li>
<li>Report learning curves in Figure format.</li>
<li>The error analysis section should summarize your findings.</li>
</ul>
</section>
</section>
<section id="submission" class="level1">
<h1>Submission</h1>
<ul>
<li><strong>Submit</strong> your report in PDF format.</li>
<li><strong>Submit</strong> your python notebook.</li>
<li>Make sure your notebook is <strong>well organized</strong>, with no temporary code, commented sections, tests, etc…</li>
<li>You can upload <strong>model weights</strong> in a cloud repository and report the link in the report.</li>
</ul>
</section>
<section id="faq" class="level1">
<h1>FAQ</h1>
<p>Please check this frequently asked questions before contacting us</p>
<section id="execution-order" class="level3">
<h3 class="anchored" data-anchor-id="execution-order">Execution Order</h3>
<p>You are <strong>free</strong> to address tasks in any order (if multiple orderings are available).</p>
</section>
<section id="trainable-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="trainable-embeddings">Trainable Embeddings</h3>
<p>You are <strong>free</strong> to define a trainable or non-trainable Embedding layer to load the GloVe embeddings.</p>
</section>
<section id="model-architecture" class="level3">
<h3 class="anchored" data-anchor-id="model-architecture">Model architecture</h3>
<p>You <strong>should not</strong> change the architecture of a model (i.e., its layers). However, you are <strong>free</strong> to play with their hyper-parameters.</p>
</section>
<section id="neural-libraries" class="level3">
<h3 class="anchored" data-anchor-id="neural-libraries">Neural Libraries</h3>
<p>You are <strong>free</strong> to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc…)</p>
</section>
<section id="keras-timedistributed-dense-layer" class="level3">
<h3 class="anchored" data-anchor-id="keras-timedistributed-dense-layer">Keras TimeDistributed Dense layer</h3>
<p>If you are using Keras, we recommend wrapping the final Dense layer with <code>TimeDistributed</code>.</p>
</section>
<section id="robust-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="robust-evaluation">Robust Evaluation</h3>
<p>Each model is trained with at least 3 random seeds.</p>
<p>Task 4 requires you to compute the average performance over the 3 seeds and its corresponding standard deviation.</p>
</section>
<section id="model-selection-for-analysis" class="level3">
<h3 class="anchored" data-anchor-id="model-selection-for-analysis">Model Selection for Analysis</h3>
<p>To carry out the error analysis you are <strong>free</strong> to either</p>
<ul>
<li>Pick examples or perform comparisons with an individual seed run model (e.g., Baseline seed 1337)</li>
<li>Perform ensembling via, for instance, majority voting to obtain a single model.</li>
</ul>
</section>
<section id="error-analysis" class="level3">
<h3 class="anchored" data-anchor-id="error-analysis">Error Analysis</h3>
<p>Some topics for discussion include: * Precision/Recall curves. * Confusion matrices. * Specific misclassified samples.</p>
</section>
<section id="bonus-points" class="level3">
<h3 class="anchored" data-anchor-id="bonus-points">Bonus Points</h3>
<p>Bonus points are arbitrarily assigned based on significant contributions such as: - Outstanding error analysis - Masterclass code organization - Suitable extensions Note that bonus points are only assigned if all task points are attributed (i.e., 6/6).</p>
<p><strong>Possible Extensions/Explorations for Bonus Points:</strong> - <strong>Try other preprocessing strategies</strong>: e.g., but not limited to, explore techniques tailored specifically for tweets or methods that are common in social media text. - <strong>Experiment with other custom architectures or models from HuggingFace</strong> - <strong>Explore Spanish tweets</strong>: e.g., but not limited to, leverage multilingual models to process Spanish tweets and assess their performance compared to monolingual models.</p>
</section>
</section>
<section id="the-end" class="level1">
<h1>The End</h1>


</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"01b945b540364db5b2a1b894bc2d0eb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01ff189b72a24b52bba93f7eb0c204fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04a785db28a24f24beb9ed7513f0e0cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"065514f7f81b45499da43f2ec5a4b16c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac2b862e17f24b2e85dbdc763ca0a0f7","max":6064,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e182ef834814504a217eca8080706ce","value":6064}},"0991ce20ba8f4ec783686cf0ccdadef2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_486fef48622b4eeabcbadf76fb751ac6","placeholder":"​","style":"IPY_MODEL_04a785db28a24f24beb9ed7513f0e0cf","value":" 648/0 [00:00&lt;00:00, 12287.67 examples/s]"}},"0c27e09be3c049b2bbd91aa9c21c4ceb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e182ef834814504a217eca8080706ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11794cb4efd342b6ac1e8cb13d33afed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16646c383f5848d998a93a765a7ddba9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aadbcd7e92a46dfba27ef538857bd10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f67dbcf3a6244dd8b0c12898089e4d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ff49e2637e5493b86a73aa5faf957a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_242b793608a140be9e840257618f49c0","max":286,"min":0,"orientation":"horizontal","style":"IPY_MODEL_afb5c0c11f94431c96a575e3db0e0d28","value":286}},"235aed8e3f20412dab9f9ee619bfbf4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"242b793608a140be9e840257618f49c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25632821819b423488cc5e75cc4049a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"259f99b80e224dda81009b8ddf39b9fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ae4726de7414a7dbdead4e24ba7baea","IPY_MODEL_065514f7f81b45499da43f2ec5a4b16c","IPY_MODEL_c97defebadad47089a6912746a44b6ae"],"layout":"IPY_MODEL_bcb2640fa54b4de5a7276c5f3413a225"}},"25be9d5b82874039970f76768424470a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2710637671d844698080dd87082e33f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"284f544f9aa14a42b9fc35b093f0c500":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bde53bf15154f219366b0504bb01c31","IPY_MODEL_b8c9ca9c6101468993585e7eb0d392db","IPY_MODEL_fdb7795f210644da94adf3bf3f4fcc23"],"layout":"IPY_MODEL_2f83bc104e3c422aa0a410d0490c4aa1"}},"296704c87ac14139a5607430c7159755":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f83bc104e3c422aa0a410d0490c4aa1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31f02a08ea424a2cb81d4549ebf6dce8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9df5ef4a14334ef7aab0439467548a34","IPY_MODEL_98b4766cabd64b8c8172cdc90094dbf1","IPY_MODEL_467eced9188b401aa9de69b8da65eec7"],"layout":"IPY_MODEL_494a7bfb44704d94b8c1493a79f9d535"}},"35e26fcee47447b08a6ac5a950e50344":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36629e7b1c8b47589d832c2fd0586a89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad52072628414f5ba581897264b50da3","placeholder":"​","style":"IPY_MODEL_a4ed4c2389994db3ae9dc16b7347b3b3","value":"Map: 100%"}},"39abd37b716143bb817c056a50d8a206":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ae4726de7414a7dbdead4e24ba7baea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b95bc955b1384e2dbfdbd03b85c37db4","placeholder":"​","style":"IPY_MODEL_ceaec1e97e6a491db95d7864d3b2df32","value":"Map: 100%"}},"3bf1aeb5cf4d4b8eab0a4dc81378c72d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c43e10e535f4c6fac3a3209ee6cfed5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62ecc809a8cf45eab1b7e9eaccf577fb","placeholder":"​","style":"IPY_MODEL_61e96bbbfbcd4a7097143d81a072e4a4","value":" 648/648 [00:00&lt;00:00, 4951.66 examples/s]"}},"3ccbf2855233416eabcd3af43d30f11a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e73004c787d45b1b1d8f47408b5e9fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7351010a72534af78c404b0d15472736","placeholder":"​","style":"IPY_MODEL_25632821819b423488cc5e75cc4049a2","value":"Map: 100%"}},"4425ddb92f5c4b629bb3b5329bf93b46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46293abedc1b4252bf863a5c557094ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"464ce2c6a47146998479c8581d3b81f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"467eced9188b401aa9de69b8da65eec7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39abd37b716143bb817c056a50d8a206","placeholder":"​","style":"IPY_MODEL_f5ca4c6fc02348bbb76ff0400ff665c2","value":" 158/158 [00:00&lt;00:00, 2080.72 examples/s]"}},"46d75b1e4ea44cb1bde0822a61cbf6a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"486fef48622b4eeabcbadf76fb751ac6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"494a7bfb44704d94b8c1493a79f9d535":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"496ace0897b7495a970bb74543656c9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_692a25f771e24be0a3dd20680e4a8059","IPY_MODEL_5a37c9957dbc49c882a8b350c02e53ce","IPY_MODEL_ca91081c461f4c6b9f8e317838a4dac7"],"layout":"IPY_MODEL_6480831af55c4944940575a2b3b826c2"}},"4bf4f6f897ad45168f14b083cb1477e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a37c9957dbc49c882a8b350c02e53ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a9f5e18a23d48a1b2f071d43704d036","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68f5dc104bef4dbf9f56ded7e3ce3b30","value":1}},"5c64fd8e2600431888672bec6ce8cd46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d5a82839ff6454a9cce880043f57dc8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c64fd8e2600431888672bec6ce8cd46","placeholder":"​","style":"IPY_MODEL_1aadbcd7e92a46dfba27ef538857bd10","value":"Generating validation split: "}},"5f0c942ec18d454aa9fde21c0fbb8c09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61e96bbbfbcd4a7097143d81a072e4a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62ecc809a8cf45eab1b7e9eaccf577fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63c7df2bb1864f08bfe9e7a2a164ab4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63c8f80656764ef8b4a498bed795a1ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c884f20694f4cd5a32a1fbe54853993","placeholder":"​","style":"IPY_MODEL_81909ad85558475db0e98d1c3e670a87","value":"Generating train split: "}},"6480831af55c4944940575a2b3b826c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67ef5c0f05504d0f978acd469ed10e34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb84a57ab1ae42a7a0133522465557cb","placeholder":"​","style":"IPY_MODEL_16646c383f5848d998a93a765a7ddba9","value":"Map: 100%"}},"68f5dc104bef4dbf9f56ded7e3ce3b30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"692a25f771e24be0a3dd20680e4a8059":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e852b1e43e05410fbb408ccd9f149fbb","placeholder":"​","style":"IPY_MODEL_63c7df2bb1864f08bfe9e7a2a164ab4c","value":"Generating train split: "}},"6983fb45564c47a58886c4dca0c9cb6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ddc77f609ed4119a26814427b2d7fdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e77d9c8a1f84009a77e308161855786":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf60662c410d4934b17672de26ccdde7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7edcf8e3dc64a4392fc20b2bd0f2793","value":1}},"6f6796b65baf49f39ed06893eb691c06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e73004c787d45b1b1d8f47408b5e9fd","IPY_MODEL_794bed42f49a495d9386c4a89dc9dcf9","IPY_MODEL_3c43e10e535f4c6fac3a3209ee6cfed5"],"layout":"IPY_MODEL_4bf4f6f897ad45168f14b083cb1477e7"}},"7351010a72534af78c404b0d15472736":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75391d503d8b462db8238be8f1c55c4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7750e529b6be46debee551bb6c3b2e44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"794bed42f49a495d9386c4a89dc9dcf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8f5d2daf9334f76948c9923009faac6","max":648,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3cffc4a7eb64851a483e2238d17f146","value":648}},"79b4f19e29194f29a1c7e366859bdcde":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a18c3bc54904aa5ad6095dcd49c859b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a9f5e18a23d48a1b2f071d43704d036":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7fec0c17e4c0487aa3196352d0673cf8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81909ad85558475db0e98d1c3e670a87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8866436b5e6b43689e8c03b628862d28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdc76ae9184b49668d738fa4edf7d2f9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ddc77f609ed4119a26814427b2d7fdc","value":1}},"8bde53bf15154f219366b0504bb01c31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46d75b1e4ea44cb1bde0822a61cbf6a4","placeholder":"​","style":"IPY_MODEL_296704c87ac14139a5607430c7159755","value":"Generating validation split: "}},"8c331900e99445009e36a249d2461122":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36629e7b1c8b47589d832c2fd0586a89","IPY_MODEL_b044cbeb39464440b3d46373354487e3","IPY_MODEL_b9c0da42dc0c4b64ab6f22be9f07cd37"],"layout":"IPY_MODEL_25be9d5b82874039970f76768424470a"}},"8ce0cd773e7846a0983e22c468388a69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dd86c365a04464ba1497cc330f82324":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fd9b2b88a7540f4be9080a5509077e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f67dbcf3a6244dd8b0c12898089e4d9","placeholder":"​","style":"IPY_MODEL_8dd86c365a04464ba1497cc330f82324","value":" 6064/0 [00:00&lt;00:00, 73084.64 examples/s]"}},"90fc2134c7aa4e54824b232afe67775f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98082d5717bc4ed798acd9df246ffd49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98b4766cabd64b8c8172cdc90094dbf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7f72ddb6e454089ae2a9574908709a2","max":158,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98082d5717bc4ed798acd9df246ffd49","value":158}},"9c884f20694f4cd5a32a1fbe54853993":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9df5ef4a14334ef7aab0439467548a34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2710637671d844698080dd87082e33f4","placeholder":"​","style":"IPY_MODEL_cd85706d957b4d01b808e873e9fe8077","value":"Map: 100%"}},"a2bfbb18e3ae4c8daff141143e4b1185":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7d52016a35048dcb3a9ad24b4b30c84","placeholder":"​","style":"IPY_MODEL_35e26fcee47447b08a6ac5a950e50344","value":"Map: 100%"}},"a4aec7edd10144aea955313f4eecef51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63c8f80656764ef8b4a498bed795a1ea","IPY_MODEL_e5f342943759452f8c73a4dcb5eaf5f2","IPY_MODEL_8fd9b2b88a7540f4be9080a5509077e0"],"layout":"IPY_MODEL_a6eae1fe9f9b44f1b1c412010ffcdbe2"}},"a4ed4c2389994db3ae9dc16b7347b3b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a698f576bd574c6588eee1363b14a564":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_464ce2c6a47146998479c8581d3b81f4","placeholder":"​","style":"IPY_MODEL_11794cb4efd342b6ac1e8cb13d33afed","value":"Map: 100%"}},"a6e7a388568b4d79826108925992d5d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c27e09be3c049b2bbd91aa9c21c4ceb","max":648,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2d06e653a03483ebc9f1c7bd98a3986","value":648}},"a6eae1fe9f9b44f1b1c412010ffcdbe2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab0faa609b2d46f7b65ac18744806e7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac2b862e17f24b2e85dbdc763ca0a0f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad52072628414f5ba581897264b50da3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afb5c0c11f94431c96a575e3db0e0d28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b044cbeb39464440b3d46373354487e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ce0cd773e7846a0983e22c468388a69","max":6064,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46293abedc1b4252bf863a5c557094ce","value":6064}},"b0921f61b52d468ea3a653a9ec048352":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b275b3744a4f498aa0a0d552b6d7eb88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f0c942ec18d454aa9fde21c0fbb8c09","placeholder":"​","style":"IPY_MODEL_cfe3552fefa448f1b2b5865cc9848fe1","value":" 286/0 [00:00&lt;00:00, 8646.18 examples/s]"}},"b2d06e653a03483ebc9f1c7bd98a3986":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3cffc4a7eb64851a483e2238d17f146":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6248663ef59420c817576dc744a6769":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7f72ddb6e454089ae2a9574908709a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8c9ca9c6101468993585e7eb0d392db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_235aed8e3f20412dab9f9ee619bfbf4d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4425ddb92f5c4b629bb3b5329bf93b46","value":1}},"b95bc955b1384e2dbfdbd03b85c37db4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9c0da42dc0c4b64ab6f22be9f07cd37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bf1aeb5cf4d4b8eab0a4dc81378c72d","placeholder":"​","style":"IPY_MODEL_6983fb45564c47a58886c4dca0c9cb6b","value":" 6064/6064 [00:01&lt;00:00, 5799.45 examples/s]"}},"b9d2f4d2121041e08747bf9c11bd693f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb4c953418a24b98b0d0125f0ae88684":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb84a57ab1ae42a7a0133522465557cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcb2640fa54b4de5a7276c5f3413a225":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf0dcbd9368c4aa2a5121b824b99cf1f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf60662c410d4934b17672de26ccdde7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bfc57d08720342d3b095c5c096d9977d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd20d9900c484aefbed5e4fd807825ff","placeholder":"​","style":"IPY_MODEL_3ccbf2855233416eabcd3af43d30f11a","value":"Generating test split: "}},"c085debcd0c84d0e9549b82697b7a575":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c35e1978847d475fa734f0056b2ec707":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01b945b540364db5b2a1b894bc2d0eb2","placeholder":"​","style":"IPY_MODEL_ab0faa609b2d46f7b65ac18744806e7f","value":" 286/286 [00:00&lt;00:00, 3343.22 examples/s]"}},"c62713f3b4854efb86791f0a8ede099a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9e8e5a0df4c4906ba3f1b15bf9ce48f","max":2870,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01ff189b72a24b52bba93f7eb0c204fb","value":2870}},"c685c36754f849c9a1f7abbe033d115d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c767cd22070d48308ef34ca8448779d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfc57d08720342d3b095c5c096d9977d","IPY_MODEL_8866436b5e6b43689e8c03b628862d28","IPY_MODEL_b275b3744a4f498aa0a0d552b6d7eb88"],"layout":"IPY_MODEL_f96dce6aa3c54780a4b402059a1ce6d6"}},"c7edcf8e3dc64a4392fc20b2bd0f2793":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c97defebadad47089a6912746a44b6ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0921f61b52d468ea3a653a9ec048352","placeholder":"​","style":"IPY_MODEL_cc98e3cab66c44539be6b74d53c2cdff","value":" 6064/6064 [00:01&lt;00:00, 6015.82 examples/s]"}},"ca91081c461f4c6b9f8e317838a4dac7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9d2f4d2121041e08747bf9c11bd693f","placeholder":"​","style":"IPY_MODEL_7750e529b6be46debee551bb6c3b2e44","value":" 2870/0 [00:00&lt;00:00, 48582.80 examples/s]"}},"caeb783bd72a4392a6bbcb4378ab812d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc98e3cab66c44539be6b74d53c2cdff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd394c99ffc34984b38d1e7fb32d4b80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a698f576bd574c6588eee1363b14a564","IPY_MODEL_1ff49e2637e5493b86a73aa5faf957a6","IPY_MODEL_c35e1978847d475fa734f0056b2ec707"],"layout":"IPY_MODEL_caeb783bd72a4392a6bbcb4378ab812d"}},"cd85706d957b4d01b808e873e9fe8077":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ceaec1e97e6a491db95d7864d3b2df32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfe3552fefa448f1b2b5865cc9848fe1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d822445bbbee452ea93224ac03d45a92":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75391d503d8b462db8238be8f1c55c4d","placeholder":"​","style":"IPY_MODEL_b6248663ef59420c817576dc744a6769","value":" 2870/2870 [00:00&lt;00:00, 7154.16 examples/s]"}},"dce9a66cc113483997ccb21052af2f53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2bfbb18e3ae4c8daff141143e4b1185","IPY_MODEL_c62713f3b4854efb86791f0a8ede099a","IPY_MODEL_d822445bbbee452ea93224ac03d45a92"],"layout":"IPY_MODEL_7a18c3bc54904aa5ad6095dcd49c859b"}},"e5f342943759452f8c73a4dcb5eaf5f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f642b14203fb49298307b684f35a0870","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90fc2134c7aa4e54824b232afe67775f","value":1}},"e852b1e43e05410fbb408ccd9f149fbb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9e8e5a0df4c4906ba3f1b15bf9ce48f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecc5a753fca84b1da7842869a2f11c5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d5a82839ff6454a9cce880043f57dc8","IPY_MODEL_6e77d9c8a1f84009a77e308161855786","IPY_MODEL_0991ce20ba8f4ec783686cf0ccdadef2"],"layout":"IPY_MODEL_bb4c953418a24b98b0d0125f0ae88684"}},"f4666e88f0614a85ba5c8ba52c235a09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67ef5c0f05504d0f978acd469ed10e34","IPY_MODEL_a6e7a388568b4d79826108925992d5d5","IPY_MODEL_f9d32805b1dc43c1ab6216019386b93a"],"layout":"IPY_MODEL_bf0dcbd9368c4aa2a5121b824b99cf1f"}},"f5ca4c6fc02348bbb76ff0400ff665c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f642b14203fb49298307b684f35a0870":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f7d52016a35048dcb3a9ad24b4b30c84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8f5d2daf9334f76948c9923009faac6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f96dce6aa3c54780a4b402059a1ce6d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9d32805b1dc43c1ab6216019386b93a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fec0c17e4c0487aa3196352d0673cf8","placeholder":"​","style":"IPY_MODEL_c085debcd0c84d0e9549b82697b7a575","value":" 648/648 [00:00&lt;00:00, 5698.89 examples/s]"}},"fd20d9900c484aefbed5e4fd807825ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdb7795f210644da94adf3bf3f4fcc23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79b4f19e29194f29a1c7e366859bdcde","placeholder":"​","style":"IPY_MODEL_c685c36754f849c9a1f7abbe033d115d","value":" 158/0 [00:00&lt;00:00, 4869.32 examples/s]"}},"fdc76ae9184b49668d738fa4edf7d2f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>